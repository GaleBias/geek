<audio title="加餐福利 _ 课后思考题答案合集" src="https://static001.geekbang.org/resource/audio/61/f1/61f34e746b673b086b17bdd71a76e5f1.mp3" controls="controls"></audio> 
<p>你好，我是程远，好久不见。</p><p>距离我们的专栏更新结束，已经过去了不少时间。我仍然会在工作之余，到这门课的留言区转一转，回答同学的问题。大部分的疑问，我都通过留言做了回复。</p><p>除了紧跟更新的第一批同学，也很开心有更多新朋友加入到这个专栏的学习中。那课程的思考题呢，为了给你留足思考和研究的时间，我选择用加餐的方式，给你提供参考答案。</p><p>这里我想和你说明的是，我这里给你提供的参考答案，都是我能够直接给你特定答案的问题。至于操作类的题目，有的我引用了同学回复的答案。</p><p>另外一类操作题，是为了帮你巩固课程内容知识的，相信你可以从课程正文里找到答案。我还是建议你自己动手实战，这样你的收获会更大。</p><h2>必学部分思考题</h2><p><a href="https://time.geekbang.org/column/article/309423">第2讲</a></p><p>Q：对于这一讲的最开始，有这样一个C语言的init进程，它没有注册任何信号的handler。如果我们从Host Namespace向它发送SIGTERM，会发生什么情况呢？</p><p>A：即使在宿主机上向容器1号进程发送SIGTERM，在1号进程没有注册handler的情况下，这个进程也不能被杀死。</p><p>这个问题的原因是这样的：开始要看内核里的那段代码，“ !(force &amp;&amp; sig_kernel_only(sig))”，</p><p>虽然由不同的namespace发送信号， 虽然force是1了，但是sig_kernel_only(sig)对于SIGTERM来说还是0，这里是个&amp;&amp;, 那么 !(1 &amp;&amp; 0) = 1。</p><!-- [[[read_end]]] --><pre><code class="language-shell">#define sig_kernel_only(sig) siginmask(sig, SIG_KERNEL_ONLY_MASK)
#define SIG_KERNEL_ONLY_MASK (\
        rt_sigmask(SIGKILL) | rt_sigmask(SIGSTOP))
</code></pre><p><a href="https://time.geekbang.org/column/article/310060">第3讲</a></p><p>Q：如果容器的init进程创建了子进程B，B又创建了自己的子进程C。如果C运行完之后，退出成了僵尸进程，B进程还在运行，而容器的init进程还在不断地调用waitpid()，那C这个僵尸进程可以被回收吗？</p><p>A：这道题可以参考下面两位同学的回答。</p><p>Geek2014用户的回答：</p><blockquote>
<p>这时C是不会被回收的，只有等到B也被杀死，C这个僵尸进程也会变成孤儿进程，被init进程收养，进而被init的wait机制清理掉。</p>
</blockquote><p>莫名同学的回答：</p><blockquote>
<p>C应该不会被回收，waitpid仅等待直接children的状态变化。</p>
</blockquote><blockquote>
<p>为什么先进入僵尸状态而不是直接消失？觉得是留给父进程一次机会，查看子进程的PID、终止状态（退出码、终止原因，比如是信号终止还是正常退出等）、资源使用信息。如果子进程直接消失，那么父进程没有机会掌握子进程的具体终止情况。</p>
</blockquote><blockquote>
<p>一般情况下，程序逻辑可能会依据子进程的终止情况做出进一步处理：比如 Nginx Master 进程获知 Worker 进程异常退出，则重新拉起来一个Worker进程。</p>
</blockquote><p><a href="https://time.geekbang.org/column/article/310804">第4讲</a></p><p>Q：请你回顾一下基本概念中最后的这段代码，你可以想一想，在不做编译运行的情况下，它的输出是什么？</p><pre><code class="language-shell">#include &lt;stdio.h&gt;
#include &lt;signal.h&gt;

typedef void (*sighandler_t)(int);

void sig_handler(int signo)
{
        if (signo == SIGTERM) {
                printf("received SIGTERM\n\n");
                // Set SIGTERM handler to default
                signal(SIGTERM, SIG_DFL);
        }
}

int main(int argc, char *argv[])
{
        //Ignore SIGTERM, and send SIGTERM
        // to process itself.

        signal(SIGTERM, SIG_IGN);
        printf("Ignore SIGTERM\n\n");
        kill(0, SIGTERM);

        //Catch SIGERM, and send SIGTERM
        // to process itself.
        signal(SIGTERM, sig_handler);
        printf("Catch SIGTERM\n");
        kill(0, SIGTERM);

 
        //Default SIGTERM. In sig_handler, it sets
        //SIGTERM handler back to default one.
        printf("Default SIGTERM\n");
        kill(0, SIGTERM);

        return 0;
}
</code></pre><p>A：可以参考用户geek 2014同学的答案。输出结果如下：</p><p>Ignore SIGTERM<br>
Catch SIGTERM<br>
received SIGTERM<br>
Default SIGTERM</p><p><a href="https://time.geekbang.org/column/article/311054">第5讲</a></p><p>Q：我们还是按照文档中定义的控制组目录层次结构图，然后按序执行这几个脚本：</p><ul>
<li><a href="https://github.com/chengyli/training/blob/main/cpu/cgroup_cpu/create_groups.sh">create_groups.sh</a></li>
<li><a href="https://github.com/chengyli/training/blob/main/cpu/cgroup_cpu/update_group1.sh">update_group1.sh</a></li>
<li><a href="https://github.com/chengyli/training/blob/main/cpu/cgroup_cpu/update_group4.sh">update_group4.sh</a></li>
<li><a href="https://github.com/chengyli/training/blob/main/cpu/cgroup_cpu/update_group3.sh">update_group3.sh</a></li>
</ul><p>那么，在一个4个CPU的节点上，group1/group3/group4里的进程，分别会被分配到多少CPU呢?</p><p>A：分配比例是: 2 : 0.5 : 1.5</p><p><strong>可以参考geek 2014的答案：</strong></p><blockquote>
<p>group1 的shares为1024，quota 3.5，尝试使用4，</p>
</blockquote><blockquote>
<p>group2的shares默认为1024，quota设置为-1，不受限制，也即是，如果CPU上只有group2的话，那么group2可以使用完所有的CPU（实际上根据group3和group4，group2最多也就能用到1.5+3.5 core）</p>
</blockquote><blockquote>
<p>故而，group1和group2各分配到2。把group2分到的2CPU，看作总量，再次分析group3和group4。group3和group3尝试使用的总量超过2，所以按照shares比例分配，group3使用1/(1+3) * 2 = 0.5，group4使用3/(1+3) * 2 = 1.5</p>
</blockquote><p><a href="https://time.geekbang.org/column/article/313255">第6讲</a></p><p>Q：写一个小程序，在容器中执行，它可以显示当前容器中所有进程总的CPU使用率。</p><p>A：上邪忘川的回答可以作为一个参考。</p><pre><code class="language-shell">#!/bin/bash
cpuinfo1=$(cat /sys/fs/cgroup/cpu,cpuacct/cpuacct.stat)
utime1=$(echo $cpuinfo1|awk '{print $2}')
stime1=$(echo $cpuinfo1|awk '{print $4}')
sleep 1
cpuinfo2=$(cat /sys/fs/cgroup/cpu,cpuacct/cpuacct.stat)
utime2=$(echo $cpuinfo2|awk '{print $2}')
stime2=$(echo $cpuinfo2|awk '{print $4}')
cpus=$((utime2+stime2-utime1-stime1))
echo "${cpus}%"
</code></pre><p><a href="https://time.geekbang.org/column/article/315468">第8讲</a></p><p>Q：在我们的例子<a href="https://github.com/chengyli/training/blob/main/memory/oom/start_container.sh">脚本</a>基础上，你可以修改一下，在容器刚一启动，就在容器对应的Memory Cgroup中禁止OOM，看看接下来会发生什么？</p><p>A：通过“<strong>memory.oom_control</strong>”禁止OOM后，在容器中的进程不会发生OOM，但是也无法申请出超过“memory.limit_in_bytes”内存。</p><pre><code class="language-shell"># cat start_container.sh
#!/bin/bash
docker stop mem_alloc;docker rm mem_alloc

docker run -d --name mem_alloc registry/mem_alloc:v1

sleep 2
CONTAINER_ID=$(sudo docker ps --format "{{.ID}}\t{{.Names}}" | grep -i mem_alloc | awk '{print $1}')
echo $CONTAINER_ID

CGROUP_CONTAINER_PATH=$(find /sys/fs/cgroup/memory/ -name "*$CONTAINER_ID*")
echo $CGROUP_CONTAINER_PATH

echo 536870912 &gt; $CGROUP_CONTAINER_PATH/memory.limit_in_bytes
echo 1 &gt; $CGROUP_CONTAINER_PATH/memory.oom_control
cat $CGROUP_CONTAINER_PATH/memory.limit_in_bytes
</code></pre><p><a href="https://time.geekbang.org/column/article/317216">第10讲</a></p><p>Q：在一个有Swap分区的节点上用Docker启动一个容器，对它的Memory Cgroup控制组设置一个内存上限N，并且将memory.swappiness设置为0。这时，如果在容器中启动一个不断读写文件的程序，同时这个程序再申请1/2N的内存，请你判断一下，Swap分区中会有数据写入吗？</p><p>A：Memory Cgroup参数memory.swappiness起到局部控制的作用，因为已经设置了memory.swappiness参数，全局参数swappiness参数失效，那么容器里就不能使用swap了。</p><p><a href="https://time.geekbang.org/column/article/318173">第11讲</a></p><p>Q：在这一讲OverlayFS的<a href="https://github.com/chengyli/training/blob/main/filesystem/overlayfs/test_overlayfs.sh">例子</a>的基础上，建立2个lowerdir的目录，并且在目录中建立相同文件名的文件，然后一起做一个overlay mount，看看会发生什么？</p><p>A：这里引用上邪忘川同学的实验结果。</p><p>实验过程如下，结果是lower1目录中的文件覆盖了lower2中同名的文件, 第一个挂载的目录优先级比较高</p><pre><code class="language-shell">[[root@localhost ~]# cat overlay.sh
#!/bin/bash

umount ./merged
rm upper lower1 lower2 merged work -r

mkdir upper lower1 lower2 merged work
echo "I'm from lower1!" &gt; lower1/in_lower.txt
echo "I'm from lower2!" &gt; lower2/in_lower.txt
echo "I'm from upper!" &gt; upper/in_upper.txt
# `in_both` is in both directories
echo "I'm from lower1!" &gt; lower1/in_both.txt
echo "I'm from lower2!" &gt; lower2/in_both.txt
echo "I'm from upper!" &gt; upper/in_both.txt

sudo mount -t overlay overlay \
 -o lowerdir=./lower1:./lower2,upperdir=./upper,workdir=./work \
 ./merged
[root@localhost ~]# sh overlay.sh
[root@localhost ~]# cat merged/in_lower.txt
I'm from lower1!
</code></pre><p><a href="https://time.geekbang.org/column/article/318978">第12讲</a></p><p>Q：在正文知识详解的部分，我们使用"xfs_quota"给目录打了project ID并且限制了文件写入的数据量。那么在做完限制之后，我们是否能用xfs_quota命令，查询到被限制目录的project ID和限制的数据量呢？</p><p>A：xfs_quota不能直接得到一个目录的quota大小的限制，只可以看到project ID上的quota限制，不过我们可以用<a href="https://github.com/chengyli/training/blob/main/filesystem/quota/get_projectid.c">这段程序</a>来获得目录对应的project ID。</p><pre><code class="language-shell"># xfs_quota -x -c 'report -h /'
...
Project ID   Used   Soft   Hard Warn/Grace
---------- ---------------------------------
#0         105.6G      0      0  00 [------]
#101            0      0    10M  00 [------]

# ./get_proj /tmp/xfs_prjquota
Dir: /tmp/xfs_prjquota projectid is 101
</code></pre><p><a href="https://time.geekbang.org/column/article/320123">第13讲</a></p><p>Q：这是一道操作题，通过这个操作你可以再理解一下 blkio Cgroup与 Buffered I/O的关系。</p><p>在Cgroup V1的环境里，我们在blkio Cgroup V1的例子基础上，把fio中“-direct=1”参数去除之后，再运行fio，同时运行iostat查看实际写入磁盘的速率，确认Cgroup V1 blkio无法对Buffered I/O限速。</p><p>A: 这是通过iostat看到磁盘的写入速率，是可以突破cgroup V1 blkio中的限制值的。</p><p><a href="https://time.geekbang.org/column/article/324122">第17讲</a></p><p>Q：在这节课的最后，我提到“由于ipvlan/macvlan网络接口直接挂载在物理网络接口上，对于需要使用iptables规则的容器，比如Kubernetes里使用service的容器，就不能工作了”，请你思考一下这个判断背后的具体原因。</p><p>A：ipvlan/macvlan工作在网络2层，而iptables工作在网络3层。所以用ipvlan/macvlan为容器提供网络接口，那么基于iptables的service服务就不工作了。</p><p><a href="https://time.geekbang.org/column/article/324357">第18讲</a></p><p>Q：在这一讲中，我们提到了Linux内核中的tcp_force_fast_retransmit()函数，那么你可以想想看，这个函数中的tp-&gt;recording和内核参数 /proc/sys/net/ipv4/tcp_reordering是什么关系？它们对数据包的重传会带来什么影响？</p><pre><code class="language-shell">static bool tcp_force_fast_retransmit(struct sock *sk)
{
        struct tcp_sock *tp = tcp_sk(sk);
 
        return after(tcp_highest_sack_seq(tp),
                     tp-&gt;snd_una + tp-&gt;reordering * tp-&gt;mss_cache);
}
</code></pre><p>A: 在TCP链接建立的时候，tp-&gt;reordering默认值是从/proc/sys/net/ipv4/tcp_reordering（默认值为3）获取的。之后根据网络的乱序情况，进行动态调整，最大可以增长到/proc/sys/net/ipv4/tcp_max_reordering (默认值为300)的大小。</p><p><a href="https://time.geekbang.org/column/article/327107">第20讲</a></p><p>Q：我在这一讲里提到了rootless container，不过对于rootless container的支持，还存在着不少的难点，比如容器网络的配置、Cgroup的配置，你可以去查阅一些资料，看看podman是怎么解决这些问题的。</p><p>A：可以阅读一下<a href="https://github.com/containers/podman/blob/master/rootless.md">这篇文档</a>。</p><h2>专题加餐</h2><p><a href="https://time.geekbang.org/column/article/340142">专题03</a></p><p>Q：我们讲ftrace实现机制时，说过内核中的“inline函数”不能被ftrace到，你知道这是为什么吗？那么内核中的“static函数”可以被ftrace追踪到吗？</p><p>A：inline函数在编译的时候被展开了，所以不能被ftrace到。而static函数需要看情况，如果加了编译优化参数“-finline-functions-called-once”，对于只被调用到一次的static函数也会当成inline函数处理，那么也不能被ftrace追踪到了。</p><p><a href="https://time.geekbang.org/column/article/340934">专题04</a></p><p>Q：想想看，当我们用kprobe为一个内核函数注册了probe之后，怎样能看到对应内核函数的第一条指令被替换了呢？</p><p>A：<strong>首先可以参考莫名同学的答案：</strong></p><blockquote>
<p>关于思考题，想到一个比较笨拙的方法：gdb+qemu调试内核。先进入虚拟机在某个内核函数上注册一个kprobe，然后gdb远程调试内核，查看该内核函数的汇编指令（disass）是否被替换。应该有更简单的方法，这方面了解不深。</p>
</blockquote><p>另外，我们用gdb远程调试内核看也可以。还可以通过 /proc/kallsyms找到函数的地址，然后写个kernel module把从这个地址开始后面的几个字节dump出来，比较一下probe函数注册前后的值。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1e/b6/d6/3b1fbf9b.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>2018</span>
  </div>
  <div class="_2_QraFYR_0">强</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-09-22 23:18:43</div>
  </div>
</div>
</div>
</li>
</ul>