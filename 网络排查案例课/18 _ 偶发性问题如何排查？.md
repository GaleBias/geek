<audio title="18 _ 偶发性问题如何排查？" src="https://static001.geekbang.org/resource/audio/5c/50/5ce15c61989ddb2bbf0e61474e2de850.mp3" controls="controls"></audio> 
<p>你好，我是胜辉。</p><p>在开始今天的课之前，我先问你一个问题：你在工作中没有遇到过那种“神出鬼没”的故障？就是说大部分时候情况都是正常的，但偶尔会来一下故障的那种。我猜有99%的可能你遇到过。</p><p>这种问题挺麻烦，经常是我们准备排查的时候，现场就没有了。那么，没有第一手的详细数据，我们还能查到问题的根因吗？</p><p>在我以往的实践当中，我发现不少人在对这个问题的认识上，会有两个常见的误区。</p><p><strong>误区1：没有现场，也没有抓包，但只要我们有历史记录，就能通过它查到根因。</strong></p><p>这里说的历史记录，是指应用日志、性能指标等。的确，很多问题通过查看历史记录，就可以解决。但还有一些问题场景，单靠历史记录是无法查到根因的。</p><p>比如这样一个场景：用户访问页面时偶尔遇到HTTP 503错误。而LB日志里，记录的其实也是一次HTTP 503，以及“后端服务不可用”这类信息。但是如果我们继续追问：为什么当时后端服务不可用呢？当时网络上有什么问题导致这种不可用呢？</p><p>日志并不能告诉我们这些问题的答案。这是它本身的局限性导致的，即它的视角是应用层，并不是网络层，所以天生就无法了解底层网络到底发生了什么。这种时候，你是不是有一种“隔靴搔痒”的感觉？</p><p>事实上，这类问题的排查，需要在<strong>重现</strong>（reproduce）问题时做全面的排查工作（比如抓包），拿到最真实全面的信息后，才能真正彻底完成。</p><!-- [[[read_end]]] --><p><strong>误区2：为了任何时候都能有现场数据，就一直抓包，一旦有问题就直接看抓包文件。</strong></p><p>这样做，理论上确实保留了现场，但是现实中却并不可行。主要有两大原因：</p><ul>
<li>第一，<strong>抓包数据量太大</strong>。以一个平均流量在1Gbps的服务为例，1天就有10TB的网络报文数据。现在一个企业有几十个、上百个服务的情况也很常见，10TB再乘以10或者100这种系数，数据量就又上了几个数量级，这对存储、读取来说，都是极大的压力。</li>
<li>第二，<strong>常态的抓包对系统性能的影响不能低估</strong>。因为抓包本身也占用内存和CPU资源，这会对已经有问题的系统产生“叠加伤害”，有可能会出现“不抓包的时候只有老问题，而抓包之后，除了老问题，还出现了新问题”。所以，常态化的抓包工作，既不可行，也没必要。</li>
</ul><p>因此，在这个大背景下，我们如何抓包、抓多久，就很有讲究了。</p><p>那么今天，我们就通过一个实际的案例，一起来探讨下在面临偶发性问题时，我们都可以采取哪些有效的排查手段，来解决这种“想查的时候问题不来，问题来的时候没在查”的困境。</p><p>在这个过程中，你可以观察下整个重现和排查的方法论，并重点关注我<strong>对大量报文进行某个指标分析</strong>的技巧。这样，当你在日后遇到偶发性问题时，就可以参考今天所讲的内容，把问题真正地解决。</p><h2>我们可以采用怎样的重现+排查策略？</h2><p>我们先来了解下需要采用什么样的重现和排查策略。事实上，网络排查是一个更偏重实践的领域，所以只要能解决问题，我觉得都是合适的办法。针对偶发性问题的重现和排查，我个人会选择如下的策略。</p><h4>1.初步估计问题出现的时间跨度，对于问题何时重现有个预期</h4><p>通过对用户反馈、应用日志，以及监控仪表盘（Dashboard）的异常事件做初步统计，了解到问题是多久出现一次，这样就决定了我们在观察和抓包上需要投入的时间成本是多少。</p><p>举个例子，一个偶发性问题是几分钟出现一次，另外一个偶发性问题是几天才出现一次。如果你对后者只观察几分钟，显然是无效的。反过来，对前一个问题用好几天的时间去观察和抓包，则远超实际需求，虽然有效，却很低效。</p><blockquote>
<p>另外，在这里我还要做个提醒。针对频率一会儿密集一会儿稀疏的问题，最好选取稀疏频率，也就是做保守估计。比如，某个问题在第一个小时出现了10次（平均6分钟一次），第二个小时却一次也没有，到第三个小时才又出现一次，那么我们认为其时间跨度是2小时（即第二和第三小时），而不是6分钟。</p>
</blockquote><h4>2.在问题机器上发起抓包，根据预估的时间跨度，指定抓包方式。</h4><p>基于前一点的分析，我们知道了问题重现的大致时间跨度，由此也确定了做监控和抓包的时间跨度。无论是我们在监控上花的时间长短，还是抓包文件占用磁盘的大小，这些都是需要控制的成本。</p><p>这里面还有个矛盾：tcpdump抓包抓久了文件太大，抓短了又可能错过问题现场。那么，<strong>如何做到既可以抓取到期待的报文，同时抓包文件也不至于特别大呢？</strong>给你分享两个技巧。</p><p><strong>技巧一：利用tcpdump里跟循环抓包相关的几个参数。</strong></p><ul>
<li>-W 个数：生成的循环文件数量，生成到最大数量后，新的报文数据会覆盖写入第一个文件，以此类推。</li>
<li>-C 尺寸：每个文件的大小，单位是MB。</li>
<li>-G 间隔时间：每次新生成文件的间隔时间，单位是分钟。</li>
</ul><p>下面这个例子，就是每100MB或者60分钟（满足任一条件即可）就生成一个文件，一共10个文件：</p><pre><code class="language-plain">tcpdump -i eth0 -w file.pcap -W 10 -C 100 -G 60
</code></pre><p><strong>技巧二：在循环抓包的基础上，再利用tcpdump的-s参数可以大幅减小抓包文件的大小。</strong></p><p>比如：</p><ul>
<li>tcpdump -s 54：抓取到从二层到四层的报文头部（不带TCP Options）了。</li>
<li>tcpdump -s 74：可以抓取到所有TCP Options，对排查TCP行为足够用。</li>
</ul><p>如果要对应用层的头部（比如HTTP头部）也进行抓取，那可以设置更大的-s参数值。整体来说，这样的抓包文件，要比抓满的情况（1514字节）小很多。</p><blockquote>
<p>补充：1514字节是网络层MTU的1500字节，加上帧头的14字节。所以一般不指定-s参数的抓包文件，其满载的帧大小是1514字节。</p>
</blockquote><h4>3.定时观察，在问题重现时停止抓包。</h4><p>这里又分成两种不同的做法：</p><ul>
<li><strong>直接人工观察应用日志或者仪表盘</strong>，比如每隔几分钟就刷新一次，直到问题重现。在问题出现频率相对高的场景下，这样做最为简单。这种做法类似软件设计里的轮询机制。</li>
<li><strong>设定自动告警机制</strong>，当通过邮箱或者手机短信等途径收到相应告警时，就知道问题重现了。这样做的好处是，抓取的问题时间点更准确。现在有告警通知功能的监控系统很多，比如Prometheus + Grafana。这种做法类似软件设计里的事件通知机制。</li>
</ul><h4>4.导出抓包文件，结合应用日志展开分析。</h4><p>这就是我们前面提到的“问题现场”详情了，在抓包文件里，所有的网络行为都会被记录下来。我们把报文情况跟应用层的报错情况做对比，就能极大地推动根因排查工作。</p><p>我把这个方法论整理成了一个简单的流程图，供你参考：</p><p><img src="https://static001.geekbang.org/resource/image/5c/71/5c0ea3757e87b3d2df8d04c6eb9d3171.jpg?wh=2000x528" alt=""></p><p>下面，我们就进入实际案例。</p><h2>实战案例：网站偶尔会变慢？</h2><p>曾经有个客户向我们报告了这样一个情况：他们的网站偶尔会变慢，比如正常1秒内就能完成的请求，可能会变成5秒钟或者更长。</p><p>但是这个情况不是每次必现，客户还做了功课，他们发现，问题出现的频率大约是几百次里面有一次。客户怀疑，是不是网络有丢包或者什么问题，导致了有时候HTTP请求或者响应没有被及时传输呢？所以就委托我们查清楚原因。</p><h3>预估：如何预估问题的出现频率和周期？</h3><p>按照前面的方法论，我们<strong>先做预估</strong>，也就是估计一下问题重现的时间跨度。</p><p>客户说“每几百次出现一次”，我们可以保守估计为1000次中出现一次问题。那么通过这个数据，能得出时间跨度吗？还不行，因为我们还不知道<strong>请求的频率</strong>是多少。</p><p>我们再次跟客户确认后，了解到他们业务还处在起步阶段，并不十分繁忙，访问频率大概在10次/分钟。现在我们做个简单的算术题：1000/10=100分钟，这就是预估的时间跨度。</p><h3>抓包：抓多长时间合适？</h3><p>有了预估的时间跨度，我们就可以做相应时长的抓包了。我们让客户在主机上用tcpdump抓取了100分钟左右的数据包，并发回给我们做分析。</p><h3>监控：如何重现问题？</h3><p>在这个时间段内，这个站点依然在对外服务。除此以外，客户那边的几个工程师也用浏览器不断刷新页面作为测试，发现也有遇到一次页面卡顿的情况。所以我们已经清楚，问题现场也就是跟问题相关的数据包，已经在抓包文件里了。</p><p>在这个案例里，因为客户那边的监控手段比较缺乏，没有全面的客户端日志，所以动用了“人肉”重现的方法。</p><p>其实，这个看起来很朴实的方法，在不少场景下也是挺有用的。我前面也提过，<strong>网络排查是一项偏向实践性的工作，只要有效的方法，我们都可以参考采用</strong>。当然如果你有Grafana等比较先进的监控系统，自然可以采用告警通知等更好的办法。</p><p><img src="https://static001.geekbang.org/resource/image/2a/dd/2aa3b64b995d21037cb9323ccc57d9dd.jpg?wh=2000x1125" alt=""></p><h2>抓包分析1：如何在网络视角上精确定义问题？</h2><p>接下来，就进入了分析阶段。不过在具体展开前，我们先思考两个简单的问题：</p><ul>
<li>什么是慢/卡顿？</li>
<li>多慢才是慢？</li>
</ul><p>客户的应用是HTTP协议的，业务是在线二手商品交易，他们的客户是通过浏览器和App进来交易的。所以，针对第一个问题，“慢”对于浏览器来说，就可能是页面一直显示转圈圈的图，要很久才能加载好页面。对于App，就是界面里有很多内容空白，过一会儿才能正常使用。</p><p>第二个问题没有标准答案，但一般来说，一个页面响应超过3~4秒问题就很大了，1秒以内完成是最好的。页面打开越快，客户体验越好，成交量就越高。有研究发现，电商网站页面的加载时间只要快0.1秒，成交量就有明显的提升。</p><p>所以，基于以上的分析，我们确定了查找条件，就是“响应时间超过3秒的HTTP事务”相关的报文。但是当我们打开抓包文件，随机选取一个HTTP事务的报文，我们就能很方便地找到“响应时间超过3秒的HTTP事务”吗？</p><p><img src="https://static001.geekbang.org/resource/image/b0/d2/b085eaf6dac2598e3cbc3af7858eb6d2.png?wh=1155x206" alt="图片"></p><p>上图是某个随机选取的HTTP事务的TCP流。当然这里也是 <strong>Wireshark的一个小的知识点</strong>：左侧的两个水平方向的箭头（一个向右，一个向左），分别表示这两个数据包是HTTP请求和HTTP响应。然后我们可以根据第二列的时间差（Time），算出来HTTP耗时。</p><p>这次事务的耗时主要发生在642号和641号报文之间，大约是115毫秒，所以不符合3秒的条件。</p><h2>抓包分析2：如何用Wireshark实现对大量HTTP事务的性能分析？</h2><p>前面的做法是，先找到HTTP事务的报文，然后用Follow TCP Stream的方式找到这个TCP流，最后分析其HTTP请求和响应之间的耗时。如果抓包文件里只有几个这样的事务，这样做倒也无妨。但是，如果抓包文件里有几百几千个HTTP事务，难道也这么一个一个去对比分析？怕是几天都看不完。</p><p>事实上，我们还有更好的办法，也就是利用Wireshark的高级用法，来帮助我们实现对大量HTTP事务的某个性能指标进行解析和统计，也就是可以借助它的两个特性：<strong>过滤器（filter）和自定义列</strong>。</p><h3>过滤器</h3><p>我们先来看看如何使用Wireshark的过滤器，来实现方便的数据分析。</p><p>在这个案例里，我们关注的是HTTP事务的耗时。其实在Wireshark窗口里，我们可以选中一个HTTP响应报文，然后找到它的耗时。比如前面提到的115毫秒的那个事务，它的HTTP响应报文的详情是这样的：</p><p><img src="https://static001.geekbang.org/resource/image/34/1a/343587d46c4850yy81dfc65164ec4d1a.png?wh=618x399" alt="图片"></p><p>可以看到，<code>[Time since request: xxx seconds]</code> 就表示了HTTP耗时。它本身不是报文属性，而是Wireshark对报文的分析属性。所有Wireshark提供的分析属性，都会用<strong>方括号</strong>标识出来（这跟ps等命令里，把内核线程也用方括号标识出来的做法类似）。</p><p>这个HTTP耗时指标对应的Wireshark过滤器是 <code>http.time</code>。我们可以直接在Wireshark过滤器输入框里输入 <code>http.time</code>，看看会出现什么：</p><p><img src="https://static001.geekbang.org/resource/image/eb/ea/ebbc2c46d17f36881400a7073bd3b8ea.png?wh=653x307" alt="图片"></p><p>可见，所有的HTTP响应报文都被过滤显示出来了。这是因为Wireshark把http.time这个分析属性体现在HTTP响应报文上，所以这里搜出来的就都是响应报文了。而如果用过滤器http，就会同时显示HTTP请求和HTTP响应的报文。现在没有其他TCP包的干扰，看起来清爽多了。</p><p>不过等等，我们想要看的<strong>耗时信息在哪里呢？</strong>没有地方展示？</p><h3>自定义列</h3><p>到这里，就需要第二个特性上场了，也就是<strong>自定义列</strong>。跟之前课程里介绍的<a href="https://time.geekbang.org/column/article/481782">添加自定义列</a>的方法一样，我们在Wireshark窗口下方的http详情部分，选中前面介绍过的Time since request，右单击，选择Apply as column，然后Wireshark主窗口里就多了一列 <code>http.time</code>。</p><p>不过新增加的列默认出现在最右侧，你可以根据需要把它拖放到合适的位置，比如我把它拖到第三列，插入在info列之前，查看起来十分方便。</p><p><img src="https://static001.geekbang.org/resource/image/30/36/301281a684daaa0be292522485dee436.png?wh=729x309" alt="图片"></p><p>这样，我们结合 <code>http.time</code> 过滤器和 <code>http.time</code> 自定义列，就可以很直观地看清楚每个HTTP事务的耗时了。</p><p>好了，这时我们点击 <code>http.time</code> 列就可以排序了，一下子就可以找到耗时最高的几个事务，如下：</p><p><img src="https://static001.geekbang.org/resource/image/7b/e3/7b255eef494b951007941f65a72f0fe3.png?wh=738x216" alt="图片"></p><p>我们可以很清楚地看到，有两个事务消耗了长达5到6秒的时间，其他事务就相对很低了，都在1秒以内。既然已经定位到问题事务了，接下来按照常规套路，右单击这个包，选择Follow -&gt; TCP Stream，我们就可以跟踪到这个高耗时事务的前后TCP行为，进而可以定位是否是网络问题。</p><p><img src="https://static001.geekbang.org/resource/image/9e/b6/9e8882627282ca8baa15c944a1b065b6.png?wh=736x459" alt="图片"></p><p>这个完整的TCP流是这样的：</p><p><img src="https://static001.geekbang.org/resource/image/92/de/9244f5f49154e8494245d18dcde988de.png?wh=903x611" alt="图片"></p><p>显然，从第二列Time来看，6秒多的时间耗费在576号报文和647号报文之间，具体来说：</p><ul>
<li>576号报文：服务端（监听在8082端口）回复了TCP确认，确认收到客户端发送过来的POST请求。</li>
<li>中间<strong>停顿了6.5秒左右</strong>。</li>
<li>647号报文：服务端回复的HTTP响应头部，可以在详情部分里看到HTTP返回码和多个header。</li>
<li>648号报文：客户端确认收到HTTP响应头部。</li>
<li>649号报文：服务端继续发送HTTP响应的body部分。在这里，因为HTTP响应报文已经完整（648+649号报文），Wireshark可以在这649报文上显示 <code>HTTP/1.1 200 OK</code> 这样的信息了。</li>
<li>650号报文：客户端确认收到HTTP响应body部分，同时携带FIN标志位结束这个连接。</li>
</ul><p>非常明显，问题是<strong>服务端收到HTTP请求后，花了大约6.5秒的时间才回复了HTTP响应</strong>。这充分说明两点：</p><ul>
<li>网络上没有任何丢包、重传等问题；</li>
<li>服务端响应耗时高达6秒以上。</li>
</ul><p>既然排查了网络的嫌疑，客户就转而去检查应用层面的问题了。</p><h2><strong>是否还有其他可能？</strong></h2><p>当然你可能会问，是否有可能服务端及时发送HTTP响应了，只是一直丢包，导致6.5秒后客户端才收到呢？就是下图这种情况：</p><p><img src="https://static001.geekbang.org/resource/image/ee/4c/ee7ccdfd9f4834bb12cc5e948854744c.jpg?wh=1794x1013" alt=""></p><p>这个可能性当然是可能存在的，如果做得透彻一点，我们应该同时在客户端和服务端抓包，进行对比即可确认或排查这个可能性。具体的例子可以参考我们在<a href="https://time.geekbang.org/column/article/481042">第5讲</a>介绍的防火墙的案例，里面就是用两侧抓包来查出问题的。</p><p>但是在当前的案例中，假设真有网络问题引起的重传，那么这个<strong>重传行为不会只集中在HTTP响应</strong>上。</p><p>也就是说，一个有丢包表现的网络，不会“聪明”到只盯着HTTP响应去丢包，而是其他阶段也会有丢包。这里说的其他阶段，就是TCP握手、HTTP请求、TCP挥手，等等，丢包同样会引起这些阶段出现重传等现象。但是我们在这个抓包文件中并没有看到这类现象，因此反过来就说明，这个推测不太可能成立。</p><p>另外，细心的你可能已经注意到了，图中假想的丢包和重传，遵循了<a href="https://en.wikipedia.org/wiki/Exponential_backoff">指数退避原则</a>。这个知识点我们在<a href="https://time.geekbang.org/column/article/479163">第3讲</a>有介绍过，你如果觉得生疏了，可以去复习一下。</p><h2><strong>如何用命令行工具做同样的分析？</strong></h2><p>前面我介绍了如何在Wireshark里结合过滤器和自定义列，来定位“高耗时HTTP事务”。不过因为图形界面的关系，这个过程有好几步操作，稍显麻烦，有没有更快一些的办法呢？</p><p>其实是有的，这次我们不用Wireshark图形界面程序，而是利用它自带的另外一个命令行工具 <strong>tshark</strong>，我们在上节课里也介绍过这个工具<strong>。</strong></p><p>就拿前面这个案例来说，我们可以直接用tshark在命令行中，实现对高耗时HTTP事务的获取。直接运行以下命令：</p><pre><code class="language-plain">tshark -r 文件名 -T fields -e http.time | grep -v ^$
</code></pre><p>示例输出如下：</p><p><img src="https://static001.geekbang.org/resource/image/d6/52/d66f4b615a651dc0b389e0e0eyyde252.png?wh=479x321" alt="图片"></p><p>注意，我们在命令的后面，必须加上<strong>管道符“ | ”和“grep -v ^$”</strong>，要不然就会看到下面这种，有大段空白的输出（因为凡是非HTTP的数据包都没有输出，会成为一个空行）：</p><p><img src="https://static001.geekbang.org/resource/image/13/46/13075fe935cfb325511371f6b2c07946.png?wh=480x290" alt="图片"></p><p>当然，如果要针对某个高耗时的事务进行数据面的分析，那光看http.time这一个指标是不够的，你需要知道这个事务对应的包号、TCP流号等信息，并追踪这个流里面的数据包。比如，你可以运行以下命令，把http.time耗时最高的事务对应的TCP流数据包，都在命令行里展示出来：</p><pre><code class="language-plain">tshark -r 文件名 -T fields -e frame.number -e http.time -e tcp.stream | sort -k2 -r | head -1 | awk '{print $3}' | xargs -n 1 -I {} tshark -r captured.pcap -Y "tcp.stream eq {}"
</code></pre><p>我来解释一下其中的几个参数：</p><ul>
<li><code>-T fields -e frame.number -e http.time -e tcp.stream</code>：表示要展示数据包哪几个列的信息。frame.number表示帧号（包号）、http.time表示HTTP耗时、tcp.stream表示TCP流号。</li>
<li><code>-Y "tcp.stream eq {}"</code>：在管道符后面使用，指的是需要把这个TCP流号相关的数据包都展示出来。因为结合了xargs命令，所以eq后面是一个<code>{}</code>符号，这个值就是TCP流的编号（由awk命令输出）。</li>
</ul><p>下图是对这个案例应用此命令得到的输出，这一系列数据包跟我们前面在Wireshark图形界面里Follow TCP Stream，而得到的那些数据包是一致的：</p><p><img src="https://static001.geekbang.org/resource/image/ab/98/abf3a85e16062d1546103b8a305ed698.png?wh=744x277" alt="图片"></p><p>是不是有点神奇？我们在图形界面里能做的事情，在命令行里也一样能做到，只要借助tshark。而正因为它是命令行形式，所以具备下面这些<strong>优势</strong>：</p><ul>
<li>图形界面里需要反复多次进行的操作，在命令行里利用管道特性，一条命令就可以完成。</li>
<li>图形程序集中在单个文件的处理，而命令行可以方便地对多个文件进行批量处理。</li>
<li>命令行的输入和输出都是文本，便于复制，在多人沟通协作场景下更显便利。</li>
</ul><p>这样，通过利用tshark对大量HTTP事务的耗时进行统计，我们很容易就能得出整体的HTTP事务性能状况了，比如平均耗时、各耗时区间的事务占全部事务的比例，等等。这不仅能在<strong>问题排查</strong>的时候提供帮助，而且在一些<strong>性能调优</strong>的场合，还可以给我们提供应用日志以外的另一种性能数据源。</p><h2>小结</h2><p>这节课，我给你介绍了一种排查偶发性问题，你可以重点关注和回顾以下这些知识点。</p><ul>
<li><strong>偶发性问题的排查思路</strong></li>
</ul><p>即先预估时间，然后一边抓包一边观察问题是否出现，在问题出现后停止抓包，最后进行抓包分析。也就是这样的流程：</p><p><img src="https://static001.geekbang.org/resource/image/5c/71/5c0ea3757e87b3d2df8d04c6eb9d3171.jpg?wh=2000x528" alt=""></p><ul>
<li><strong>排查技巧</strong></li>
</ul><p>首先是控制tcpdump抓包大小的方法。</p><p>为了控制抓包文件在合理的范围，我们可以用两种方法。</p><ul>
<li>方法一：运行tcpdump时指定循环参数，比如每隔多少MB或者每隔多少分钟就生成一个文件，一共生成n个文件，循环使用。</li>
<li>方法二：tcpdump -s参数，指定-s后面的数值为54到74，就可以抓取到二层到四层的头部信息了。如果要抓取应用层头部，可以指定相应的更大的值。</li>
</ul><p>第二是找到HTTP耗时最高事务的方法。</p><p>为了找到HTTP耗时最高的事务，我们可以通过<strong>过滤器</strong> <code>http.time</code> 或者 <code>http</code>，把HTTP事务都过滤出来，然后增加一个<strong>自定义列</strong>来展示HTTP耗时。最后，我们点击这个列，就完成对HTTP耗时这个自定义列的排序了。</p><p>而除了Wireshark这个工具以外，我们用<strong>tshark</strong>命令行工具，也同样可以实现“从大量报文中对某个指标进行解析和排序”的目的。</p><p>第三是找到HTTP事务的报文对的方法。</p><p>在Wireshark中，选中HTTP的请求或者响应报文时，这个报文以及与它对应的响应或者请求报文的左边，会出现<strong>两个水平方向的箭头（一个向右，一个向左），表示它们属于同一个HTTP事务。</strong></p><h2>思考题</h2><p>最后，给你留两道思考题：</p><ul>
<li>前面我介绍了使用tshark来找到耗时最高的HTTP事务的方法。关于tshark，你自己还有哪些使用经验呢？</li>
<li>在“是否还有其他可能？”这里，我提到了可能的重传。如果要验证是否真的存在这种重传，你觉得应该做什么呢？</li>
</ul><p>欢迎在留言区分享你的答案，也欢迎你把今天的内容分享给更多的朋友，我们一起成长、进步。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/13/60/71/895ee6cf.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>分清云淡</span>
  </div>
  <div class="_2_QraFYR_0">tshark、tcpdump常用案例我整理了文字版放这里了：https:&#47;&#47;www.weibo.com&#47;1667773473&#47;LrrLQirmv<br> 基本上我们的服务器模板里必备这些，紧急情况下让远程复制粘贴就行</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 确实，很多命令全记住也不容易，我也有很多小本本：）</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-05-21 19:12:34</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/bf/35/0e3a92a7.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>晴天了</span>
  </div>
  <div class="_2_QraFYR_0">有一个疑问 问下老师.  <br><br>场景: 客户端a 请求 nginx b. nginx b将请求通过tcp转发给php-fpm c 开启的9000端口. <br><br>问题: a 到 b的http包可以抓到. 但是b到c的请求我就不知道该怎么筛选了. 目前想到的办法是将http的内容转为16进制, 然后在wareshark通过data.data contains hexString 进行筛选. 但是http是分段的, 有时可能会抓不到. 老师有没有更准确的办法教授一下 感谢.<br>  <br><br></div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 你好，这里应该是两个不同的TCP连接：<br>连接1：a到b<br>连接2：b的nginx到b自己的php-fpm，通过本地的TCP 9000端口<br><br>HTTP事务是在这两个中传输的时候，大部分信息是不变的，特别是payload。所以你可以尝试我在第17讲介绍的方法，当时也是在HAProxy两侧不同TCP连接中定位同一个HTTP事务。具体来说就是利用下面这种过滤器，在连接1和连接2中分别找到它：<br>tcp contains &quot;xxxx&quot;</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-28 18:58:05</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>那时刻</span>
  </div>
  <div class="_2_QraFYR_0">请问老师，[Time since request: xxx seconds]对应于 http.time，这个对应关系在哪里可以查找到呢？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 你把[Time since request: xxx seconds]右单击选择apply as column，然后主窗口里多了一个列。你对这个列右单击选择edit column，就能看到它的fields里面的内容就是http.time了~</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-02 10:12:33</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Realm</span>
  </div>
  <div class="_2_QraFYR_0">1 tshark -R &quot;tcp.analysis.retransmission || tcp.analysis.out_of_order&quot;<br>通过-R 指定过滤条件，抓重传和乱序的包<br><br>2 双向抓包对比，确认是否有重传；</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 两个都对了，厉害了！tshark的功能确实很强大，也很实用，在后续课程里会继续介绍的</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-02 22:26:19</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Bachue Zhou</span>
  </div>
  <div class="_2_QraFYR_0">‪抓包常态化的误区，搞技术的人都能理解，偏偏某些领导无法理解或不愿意理解‬。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这种情况是有点无奈。不过可以换一个想法，看看领导的诉求是什么。“常态化抓包”是目标还是手段？看看领导的目标具体是什么，达成这个目标的手段可以是什么，可以不是什么？<br>我们常犯的错误，是把手段当成了目标：）</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-01 08:48:53</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKzqiaZnBw2myRWY802u48Rw3W2zDtKoFQ6vN63m4FdyjibM21FfaOYe8MbMpemUdxXJeQH6fRdVbZA/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>kissingers</span>
  </div>
  <div class="_2_QraFYR_0">最终还是通过抓包来分析的，有没有这类问题不通过抓包，比如通过现象---&gt;可能原因分析----&gt;找到原因比如配置等问题的案例分享</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这种案例当然有，不过有点过于经验性，我希望这个课程是提供一种具体到细节和原理性的分析。这种分析方法应该是要掌握的，即使你到后期可以做到“通过现象---&gt;可能原因分析----&gt;找到原因”，但脱离了这个抓包分析的能力，就有点不扎实。各种软件的配置项都会变化，我们需要学习的知识最好要少一些“偶然性知识”（比如某个软件的某个配置叫某个名字，在它的值为某个数字的时候会出现某种问题），而多一些“必然性知识”（网络协议是十多年二十多年都不会有大的改变的）。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-05-10 12:02:23</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/4e/bd/7fc7c14f.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>汤玉民</span>
  </div>
  <div class="_2_QraFYR_0">老师 非常棒的课程</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 谢谢你的支持：）</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-29 14:29:39</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/c4/03/f753fda7.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>JianXu</span>
  </div>
  <div class="_2_QraFYR_0">看到这里我觉得抓包对老师来说基本上就是“瑞士军刀”。对于偶发性问题，监控数据挺重要的。我司就要全面上线SLB , Mesh … 节点多，还是分布式系统，排查偶发性问题更难了。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，对于我们大规模应用，对各种数据源的依赖性更高。另外，跳数越多，排查复杂度越高，课程里的案例算比较简单的，大规模应用下的问题耗时更长，基本上少不了多次的来回，比如：<br>第一回：大致确定问题位置，比如是靠近客户端，还是靠近LB，还是靠近服务端<br>第二回：在这个相对小的范围里利用现有的日志或者打开新的debug日志，进一步缩小范围<br>第三回：上tcpdump等工具来定位根因</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-21 22:47:07</div>
  </div>
</div>
</div>
</li>
</ul>