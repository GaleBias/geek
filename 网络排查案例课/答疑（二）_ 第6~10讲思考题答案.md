<audio title="答疑（二）_ 第6~10讲思考题答案" src="https://static001.geekbang.org/resource/audio/9c/10/9c0c9c0bb4975a38b20f49d348863a10.mp3" controls="controls"></audio> 
<p>你好，我是胜辉。</p><p>在上一节答疑课里，我们回顾了第1到第5讲的思考题，分析了每道题目的解题思路，当然更重要的是对这五节课的知识点做了一次复习和补充。你看完了这些解答后的感觉如何呢？跟之前你自己的思考过程和结论相比，又有哪些相同和不同之处呢？相信通过再一次的思考，你对知识的掌握将会更加深刻。</p><p>那么这节课，我们就继续讲解这些课后的思考题。先从第6讲开始。</p><h2>06讲的答疑</h2><h3>思考题</h3><p>这节课，我给你介绍了利用防火墙的TTL跟原先的正常报文的TTL不一致的特点，从而识别出防火墙的方法。那么，假设有一天，防火墙公司把这个特性也完善了，我们再也不能仅凭TTL的突变而发现防火墙了，你觉得还有什么办法可以识别出防火墙吗？</p><h3>答案</h3><p>这是一个开放式的问题，其实并没有标准答案。不过，通过对这个问题的思考，我们可以对网络的理解更进一步。我们先参考下面这张图，复习一下用TTL判断防火墙的原理：</p><p><img src="https://static001.geekbang.org/resource/image/f6/56/f6a1206ea604d7f3dd88981e39366256.jpg?wh=1694x562" alt=""></p><blockquote>
<p>补充：上图是一个例子，假设防火墙是路径上的第5跳，那么防火墙自己发出的报文的TTL就比真正的发送端的TTL多了5。</p>
</blockquote><p>然后想一想，我们之所以能通过TTL定位防火墙，本质原因是什么呢？实际上，本质原因就是这个IP报文是防火墙自己构造的，而<strong>在构造时TTL被设置为了初始值</strong>。</p><!-- [[[read_end]]] --><p>那么，还有哪些元信息也是在这个构造好的报文里呢？其实这些信息也可以帮我们辅助判断防火墙。</p><p>另外在IP层，除了TTL，还有一个字段也值得我们注意，它就是<strong>IP ID</strong>。这个字段占用了2个字节，所以它的最大值是2^16-1，也就是65535。IP ID一般是IP报文的发起端设置的，每次发包递增1，然后在0到65535之间循环使用。</p><p>它最主要的用途，是<strong>接收端会根据这个ID来组装（assemble）同一组IP分片（fragments），</strong>而中间设备（交换机、路由器）不会改动IP ID。并且在防火墙构造RST报文的时候，IP包的TTL和ID值也是防火墙自己设置的，也就有可能被我们用来发现防火墙。所以，如果SYN+ACK和RST的IP ID不连续，我们就可以判断出防火墙，也就是下图这样：</p><p><img src="https://static001.geekbang.org/resource/image/51/52/51df7643ff2127011ce9e6fd124e9652.jpg?wh=1846x884" alt=""></p><p>不过，我在探究这个可能性的时候，又遇到了新的问题。要知道，Linux系统发送SYN+ACK的时候，IP ID一定是0，但是我既在Wireshark里看到了这个现象，也在内核代码里证实了这一点。而这就给我们利用IP ID带来了障碍：<strong>因为即使RST真的是对端发出的，两个报文的IP ID也会不同。</strong></p><p>只有当我们收到至少三个报文，也就是除了SYN+ACK和RST之外，我们还需要在中间收到一些报文，才可以对比RST跟中间报文的IP ID的差别，然后进行判断。</p><p>所以，利用IP ID的方法，对于TCP握手后就发生RST的情况并不适用，但对于交互过程中发生RST的情况应该是适用的。你有机会也可以在遇到RST时，来抓包验证一下。</p><p><img src="https://static001.geekbang.org/resource/image/16/d5/168e95c43c17fc318d72df93205231d5.jpg?wh=1821x943" alt=""></p><h2>07讲的答疑</h2><h3>思考题</h3><ol>
<li>tcp.payload eq abc，这个过滤器可以搜索到精确匹配“abc”字符串的报文。那么，如果是模糊匹配，比如只要包含“abc”的报文我都想搜到，这个过滤器又该如何写呢？</li>
<li>在工作中，你遇到过跟TCP Keep-alive相关的问题吗？你是怎么解决的呢？</li>
</ol><h3>答案</h3><p>第一个问题，其实在上节答疑课里我也提到过，就是利用各层的 <strong>contains</strong> 动词来写过滤器。比如：</p><ul>
<li>应用层可以是 <code>http contains "abc"</code>；</li>
<li>传输层可以是 <code>tcp contains "abc"</code>；</li>
<li>网络层可以是 <code>ip contains "abc"</code>；</li>
<li>数据链路层可以是 <code>frame contains "abc"</code>。</li>
</ul><p>这类过滤器的使用场景一般是这样的：我们知道应用层的某一个信息，比如HTTP报文里面的某个uuid，然后再通过这个信息，去找到对应的报文。</p><p>而在这里，又可以细分为两种不同的场景。</p><p><strong>第一种，某一个TCP连接在通信两端的报文的对应。</strong>比如，客户端发出的HTTP报文里含有某个uuid，那么我们需要在服务端的抓包文件里，把这个TCP流过滤出来，就可以用上面说的那些过滤器。</p><p><img src="https://static001.geekbang.org/resource/image/61/e6/6180fd2be0492305d612eb6e2f2fbce6.jpg?wh=2000x954" alt=""></p><p><strong>第二种，LB前后方两个不同TCP连接的报文的对应。</strong>比如，LB会转发请求给后端多台服务器中的某一个，而这个选择一般是动态的，这就给我们的排查工作带来了不小的障碍。</p><p>那么这里可以参考的方法就是：在“客户端&lt;-&gt;LB”这一侧的连接中，找到HTTP报文的某个uuid，然后在“LB&lt;-&gt;多个后端IP”这一侧的抓包中，搜索这个uuid，就能得到同样是这个请求的相关报文了。</p><p>我们可以看看下面这个示意图：</p><p><img src="https://static001.geekbang.org/resource/image/28/6d/282b9b474a7b96998c657bfdbebae46d.jpg?wh=2000x1125" alt=""></p><p>也就是说，TCP流1和TCP流1<code>'</code>，还有TCP流2和TCP流2<code>'</code>，分别是同一个TCP流在连接两侧的不同体现。而<strong>由于流1和流2确实是完全不同的连接，无法用任何TCP报文头部的信息来进行匹配，所以只能用应用层的信息来找到对应关系</strong>。</p><p>第二个问题也是一个开放式的问题。我看到不少同学都分享了他们的经验，这也增加了我自己的见识，真是一件多赢的事。比如，<strong>@江山如画</strong>同学对这个问题的回复是这样的：</p><blockquote>
<p>在工作中，我目前还没有碰到过和TCP Keep-alive有关的问题，不过我之前看一些建立网络隧道的软件里，有Keep-alive这个参数，查询说它和SNAT有关，就让我一直很迷惑。<br>
&nbsp;<br>
今天学习了老师的课，我又去深究了下。原来Virtual Tunnel会建立虚拟网卡，它和物理网卡之间需要做流量的桥接，进而就需要做SNAT。然后SNAT会维护一个端口映射表，因为链接太多可能会占满本地端口，如果没有设置Keep-alive，那么在一段时间内都没有传输数据的话，就会把端口转换的记录给删掉，这时候通信双方想再通信就不行了。所以需要每隔一段时间发送心跳包，保证SNAT端口映射表中的记录不被删掉，从而保证连接存活。</p>
</blockquote><p>这实际上就是一个很典型的场景，也就是NAT和TCP Keep-alive之间的关系。NAT是维护连接跟踪表的，里面的表项有一定的有效期，过了有效期的表项就会被清空。而TCP Keep-alive正好可以定期去刷新这个计时器，让它“永葆青春”，表项不被删除，这个连接就可以一直愉快地工作下去了。</p><p>类似地，<strong>@Geek_535c45</strong>同学也对TCP Keep-alive问题发出了灵魂的拷问：</p><blockquote>
<p>Chrome每隔45秒发起TCP Keep-alive包的意义是什么呢？</p>
</blockquote><p>其实答案也跟上面的解释差不多，Chrome每隔45秒的TCP Keep-alive，主要是起到下面这两个作用：</p><ul>
<li><strong>避免连接被中间环节给撤销掉</strong>。一般客户端是在内网里的，出公网的时候NAT会转换为公网IP跟对端通信。而跟上面的例子类似，为了保持NAT表项不被回收，所以Chrome要发送保活报文。</li>
<li><strong>避免被服务端认为是无效连接给撤销掉</strong>。服务端一般也有idle timeout时间，也就是如果一个客户端连接超过一定时间没有报文传送，服务端就会取消这个连接，而且这时很可能不发送FIN或者RST，导致客户端对连接失效这个事情并不知情。因为服务端要面向公网上成千上万的访问者，所以它的逻辑是定时清除无效连接，以保证服务端的资源得到合理的使用。</li>
</ul><h2>08讲的答疑</h2><h3>思考题</h3><ol>
<li>在LB或者网关上修改MSS，虽然可以减小MSS，从而达到让通信成功这个目的，但是这个方案有没有什么劣势或者不足，也同样需要我们认真考量呢？你可以从运维和可用性的角度来思考。</li>
<li>你有没有遇到过MTU引发的问题呢？</li>
</ol><h3>答案</h3><p>对于第一个问题，在LB或者网关上修改MSS，这当然起到了作用。从短期来看，也是很不错的临时方案。但是长期来看，一旦客户和自己发生人员流动，又缺乏文档记录，就很可能会引起问题。比如说，这个配置可能会被后来的人当作无用配置而清除，而到时候如果没有人了解这个上下文，显然就要花很多时间去排查，给双方带去的业务影响也不会小。</p><p>尽管这可能算是一个非技术问题，但是也会影响到自己团队和兄弟团队的工作体验。所以我们做运维工作，还有一个重要的原则：<strong>优先选择简洁又容易维护的方案</strong>，而不是复杂且不易维护的方案，避免给以后的运维工作埋下隐患。</p><p>所以，后来我们选择的长期方案还是在两端修改MTU，这样的话客户团队就很清楚自己机器上的配置，就有责任也有条件做好维护。</p><p>第二个问题，还是<strong>@江山如画</strong>同学，他分享了一个典型案例：</p><blockquote>
<p>之前我们手动创建了虚拟网卡，和物理网卡之间做了流量的桥接，发现有些报文在这二者之间转发时会被丢掉。然后通过分析，我们发现虚拟网卡的MTU设置过大，并且报文DF位设置为了1，后来我们通过ifconfig命令把虚拟网卡的MTU改小，报文就可以正常转发了。</p>
</blockquote><p>不用我做更多解释，你应该都很清楚这个场景里的技术细节了。这也是比较常见的情况，你掌握好以后应该也有机会运用到实际工作中，也就是说，<strong>如果遇到丢包的问题，你可以看看MTU的值是否超标了</strong>。这是一个比较合算的“投资”，就花几分钟查一下，也许真能解决一个原本要查几个小时的大问题。</p><h2>09讲的答疑</h2><h3>思考题</h3><p>你有没有在工作中遇到过TCP传输速度相关的问题呢？通过这节课的学习，你已经掌握了传输速度相关的不少知识，你准备怎么运用这些知识，来解决这个传输问题呢？</p><h3>答案</h3><p>我看到留言中有一个同学的回答是这样的：</p><blockquote>
<p>我们公司之前有一个场景是多个客户端连接同一个服务端，如果某个客户端下载文件或上传文件，占用了大量的带宽，就会导致新的客户端连不上服务端。后来我们就在服务端使用tc工具做了流控，根据客户端个数来均分带宽，还有限制单个IP的最大使用带宽。</p>
</blockquote><p>其实， tc的原理是调整qdisc发送缓存队列，超出队列的数据就丢弃，这样的话发送端就探测到了“拥塞”，进而会主动降速，从而也就达到了限制速度的效果。而“拥塞”这个知识点，又是我们在<a href="https://time.geekbang.org/column/article/486281">第11讲</a>里深入探讨过的内容。其实从第9到13讲的内容都是关于传输的，所以我建议你可以把第9到13讲的内容结合起来学习，应该就能更加深入和全面地理解TCP传输这个重要话题了。</p><h2>10讲的答疑</h2><h3>思考题</h3><ol>
<li>TCP的序列号和确认号，最大可以到多少？</li>
<li>接收端只确认部分数据，导致了“数据滞留”现象，这个现象背后的原因可能是什么呢？</li>
</ol><h3>答案</h3><p>第一个问题呢，其实是一个简单的<strong>协议规范的问题</strong>。这个知识点，你很容易就可以在<a href="https://www.ietf.org/archive/id/draft-ietf-tcpm-rfc793bis-25.html#section-3.10.7.4-2.1.2.1.9.7.2.1">RFC793</a>里找到。TCP的序列号和确认号的长度都是4个字节，4个字节也就是32位，所以最大值是2^32-1，也就是4G。我也建议你记住这些小的知识点，因为它是在工作中高频使用的知识点，你能记住的话就不用去搜索了，可以提升工作的效率。</p><p>第二个问题就比较复杂了，而且因为当时的现场没有了，所以也没有标准答案。但是这个思考的过程对我们掌握这一讲的知识是很有帮助的，而且，我们其实还是可以大致推导出当时的情景。</p><p>我直接借用<a href="https://time.geekbang.org/column/article/485689">第10讲</a>里面的一张示意图：</p><p><img src="https://static001.geekbang.org/resource/image/5d/e1/5daef13e8f38a14a86c45yyd28513ee1.jpg?wh=2000x872" alt=""></p><p>我也来简单描述一下这个过程。</p><ul>
<li>在t1这个时间点，B通知A：“我的接收窗口是1000字节”。</li>
<li>在t2这个时间点，A收到了B的通知，然后发送了1000字节，此时这些都属于在途字节数。</li>
<li>在t3这个时间点，B收到了1000字节，此时接收窗口（缓冲区）全部用完，Wireshark据此判断出“Window Full”。然后B向A发送确认包，确认了300个字节。</li>
<li>在t4这个时间点，A收到B确认300个字节的确认包，于是<strong>判断出在途字节数是700字节，所以A能发的最多只有300字节。</strong></li>
</ul><p>我们再来看一下接收端的报文处理流程。如果我们把缓冲区（包括Ring Buffer和Recieve Buffer）比作水池，那么报文进入缓冲区，就相当于有水龙头往里注水；应用程序到缓冲区取走数据，又相当于有水龙头放出水。这两个水龙头的速度的不同，就造成了缓冲区的动态调整。</p><p><img src="https://static001.geekbang.org/resource/image/a4/f5/a483db4d1ffe854e660d4c4611cde0f5.jpg?wh=2000x778" alt=""></p><p>那么，发生数据“滞留”，其实就相当于水池中一直囤着水，也就是“放水速度不够”，应用程序没有把数据都及时读取走导致的。</p><p>显然，比较理想的情况是放水的速度大于等于注水的速度，这是传输速度最快的方式。</p><p>但是，我们也要认识到，操作系统设立缓冲区的一大原因，就是考虑到“注水”和“放水”的速度本来就是经常不相等的，所以用缓冲区这个“空间”，来抵消速度不同导致的“时间”上的矛盾。简单来说就是“<strong>用空间换时间</strong>”。而且，不仅是网络接收和发送的缓冲区如此，大部分缓冲区也都是“用空间换时间”原则的体现。</p><p>所以通过这个思考，你对TCP的缓冲区等概念，是否也有了新的认识了呢？</p><p>好了，今天的答疑就到这里。如果你还有什么疑问，同样可以回复到留言区，我们一同进步、成长。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/20/81/02/59f5f168.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>小白debug</span>
  </div>
  <div class="_2_QraFYR_0">看了“数据滞留”现象的那部分，有些疑惑，表述看起来像是在说，应用层收了300b之后，才会ack300。但实际上ack的行为跟应用层是否收这个数据无关才对。我理解 应该是t3时B发 ack=1000 + 1，win=0，window full，此时A会发现对方接收窗口满了，过一阵A再发一次窗口探测，此时B的缓冲区被应用层收走了300b，所以此时B回复给A的是ack=1000 + 1， win=300.   求老师帮助解惑。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: “ack的行为跟应用层是否收这个数据无关”--这是正确的，也就是TCP不需要等应用层取走数据后再给发送端给与TCP确认。不过，应用层收取数据太慢的话，事实上会导致接收缓冲区变大，容易触及分配给这个socket的缓冲区上限。到达上限的时候，就是发送windows=0的时候了~<br>另外，我在t3这里标记了“window full”，这是wireshark的解读，并不是tcp报文本身携带的信息。接收方接收窗口是1000，收到了1000，那么此时窗口用完了，这是一种判断。它跟zero window是不同的。<br>window full：在途数据=接收窗口，是wireshark的解读<br>zero window: 明确的在报文里window字段是0，不需要wireshark也可以直接看出来，比如在tcpdump的输出里</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-07-23 09:18:16</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>那时刻</span>
  </div>
  <div class="_2_QraFYR_0">请问老师例子中在途字节数是 700 字节，是因服务器window full直接丢弃？还是有可能服务器把缓冲区数据被应用程序处理后再次接收呢？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 在途字节数700字节，是发送端自己判断出来的，是根据“已发送数据 - 被确认数据”得出的。<br>而Window Full是Wireshark根据报文情况作出的解读，这个信息表示：在被标记的时间点，（服务端的）接收窗口已经被用完。这里不会有丢弃的行为。<br>在服务端确认了300字节的数据后，发送端就知道，虽然另外700字节还未被确认（因此仍属于在途数据），但是窗口已经空出了300字节了，于是可以继续发送300字节。<br>在服务端应用程序从缓冲区取走更多数据后，发送端就可以发送更多字节。<br>概括来说，在TCP里，发送端是不会发出超过对方缓冲区大小的数据的（恶意的除外）。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-17 10:29:45</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/fe/b0/260f41f0.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>loris</span>
  </div>
  <div class="_2_QraFYR_0">老师，最近排查一个数据库查询结果返回的问题，根据ID查询返回一个大文本字段，整体结果20分钟才返回，如果立即中断查询，查询结果立即返回<br>抓包分析发现有很多Tcp zero window 报文 ，老师能不能对Tcp zero window补充讲解一下</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 正好有个学员也问到了zero window的问题，我把问题和回复都在这里发一下，供你参考：<br><br>问：老师，我们工作中有同事遇到了tcp window zero，我当时没参与这个任务，没去看具体的抓包数据，但好像也是接收端窗口满了的原因。请问window zero 和window full的区别是什么呢？是视角不同吗？zero是接收端视角，full是发送端视角？<br><br>作者回复: 你好，这两个信息都是关于window的，确实很容易搞混，我这里解释一下。其实跟视角没关系。<br>tcp window zero是指，这个tcp报文的window字段明确就是0，也就意味着这个报文的发送方的接收缓冲区已经变成0了，另一方就会停止发送数据。当然，为了避免无限等待，另一方会有探测机制，定制发送一个零载荷的报文，让window zero这一端回复报文，从这个回复报文里读取到最新的window值。<br>tcp window full是指，这个报文发送后，另一端的接收窗口就满了。我举个例子，现在A和B在通信，A的一个报文被wireshark标记为tcp window full，指的是A的未被确认的数据量（也就是在途字节数）跟B的接收窗口相等。这意味着A不会发送更多报文（即使B没有发送window zero的报文），因为A知道发送出去的数据量已经“填满”了B的接收缓冲区~</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-09 01:03:04</div>
  </div>
</div>
</div>
</li>
</ul>