<audio title="30 _ 文件缓存：常用文档应该放在触手可得的地方" src="https://static001.geekbang.org/resource/audio/fb/8e/fb5daec4baa92b1c2cf0850886a3e18e.mp3" controls="controls"></audio> 
<p>上一节，我们讲了文件系统的挂载和文件的打开，并通过打开文件的过程，构建了一个文件管理的整套数据结构体系。其实到这里，我们还没有对文件进行读写，还属于对于元数据的操作。那这一节，我们就重点关注读写。</p><h2>系统调用层和虚拟文件系统层</h2><p>文件系统的读写，其实就是调用系统函数read和write。由于读和写的很多逻辑是相似的，这里我们一起来看一下这个过程。</p><p>下面的代码就是read和write的系统调用，在内核里面的定义。</p><pre><code>SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
{
	struct fd f = fdget_pos(fd);
......
	loff_t pos = file_pos_read(f.file);
	ret = vfs_read(f.file, buf, count, &amp;pos);
......
}


SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
		size_t, count)
{
	struct fd f = fdget_pos(fd);
......
	loff_t pos = file_pos_read(f.file);
    ret = vfs_write(f.file, buf, count, &amp;pos);
......
}
</code></pre><p>对于read来讲，里面调用vfs_read-&gt;__vfs_read。对于write来讲，里面调用vfs_write-&gt;__vfs_write。</p><p>下面是__vfs_read和__vfs_write的代码。</p><pre><code>ssize_t __vfs_read(struct file *file, char __user *buf, size_t count,
		   loff_t *pos)
{
	if (file-&gt;f_op-&gt;read)
		return file-&gt;f_op-&gt;read(file, buf, count, pos);
	else if (file-&gt;f_op-&gt;read_iter)
		return new_sync_read(file, buf, count, pos);
	else
		return -EINVAL;
}


ssize_t __vfs_write(struct file *file, const char __user *p, size_t count,
		    loff_t *pos)
{
	if (file-&gt;f_op-&gt;write)
		return file-&gt;f_op-&gt;write(file, p, count, pos);
	else if (file-&gt;f_op-&gt;write_iter)
		return new_sync_write(file, p, count, pos);
	else
		return -EINVAL;
}
</code></pre><p>上一节，我们讲了，每一个打开的文件，都有一个struct file结构。这里面有一个struct file_operations f_op，用于定义对这个文件做的操作。__vfs_read会调用相应文件系统的file_operations里面的read操作，__vfs_write会调用相应文件系统file_operations里的write操作。</p><h2>ext4文件系统层</h2><!-- [[[read_end]]] --><p>对于ext4文件系统来讲，内核定义了一个ext4_file_operations。</p><pre><code>const struct file_operations ext4_file_operations = {
......
	.read_iter	= ext4_file_read_iter,
	.write_iter	= ext4_file_write_iter,
......
}
</code></pre><p>由于ext4没有定义read和write函数，于是会调用ext4_file_read_iter和ext4_file_write_iter。</p><p>ext4_file_read_iter会调用generic_file_read_iter，ext4_file_write_iter会调用__generic_file_write_iter。</p><pre><code>ssize_t
generic_file_read_iter(struct kiocb *iocb, struct iov_iter *iter)
{
......
    if (iocb-&gt;ki_flags &amp; IOCB_DIRECT) {
......
        struct address_space *mapping = file-&gt;f_mapping;
......
        retval = mapping-&gt;a_ops-&gt;direct_IO(iocb, iter);
    }
......
    retval = generic_file_buffered_read(iocb, iter, retval);
}


ssize_t __generic_file_write_iter(struct kiocb *iocb, struct iov_iter *from)
{
......
    if (iocb-&gt;ki_flags &amp; IOCB_DIRECT) {
......
        written = generic_file_direct_write(iocb, from);
......
    } else {
......
		written = generic_perform_write(file, from, iocb-&gt;ki_pos);
......
    }
}
</code></pre><p>generic_file_read_iter和__generic_file_write_iter有相似的逻辑，就是要区分是否用缓存。</p><p>缓存其实就是内存中的一块空间。因为内存比硬盘快得多，Linux为了改进性能，有时候会选择不直接操作硬盘，而是读写都在内存中，然后批量读取或者写入硬盘。一旦能够命中内存，读写效率就会大幅度提高。</p><p>因此，根据是否使用内存做缓存，我们可以把文件的I/O操作分为两种类型。</p><p>第一种类型是<strong>缓存I/O</strong>。大多数文件系统的默认I/O操作都是缓存I/O。对于读操作来讲，操作系统会先检查，内核的缓冲区有没有需要的数据。如果已经缓存了，那就直接从缓存中返回；否则从磁盘中读取，然后缓存在操作系统的缓存中。对于写操作来讲，操作系统会先将数据从用户空间复制到内核空间的缓存中。这时对用户程序来说，写操作就已经完成。至于什么时候再写到磁盘中由操作系统决定，除非显式地调用了sync同步命令。</p><p>第二种类型是<strong>直接IO</strong>，就是应用程序直接访问磁盘数据，而不经过内核缓冲区，从而减少了在内核缓存和用户程序之间数据复制。</p><p>如果在读的逻辑generic_file_read_iter里面，发现设置了IOCB_DIRECT，则会调用address_space的direct_IO的函数，将数据直接读取硬盘。我们在mmap映射文件到内存的时候讲过address_space，它主要用于在内存映射的时候将文件和内存页产生关联。</p><p>同样，对于缓存来讲，也需要文件和内存页进行关联，这就要用到address_space。address_space的相关操作定义在struct address_space_operations结构中。对于ext4文件系统来讲， address_space的操作定义在ext4_aops，direct_IO对应的函数是ext4_direct_IO。</p><pre><code>static const struct address_space_operations ext4_aops = {
......
	.direct_IO		= ext4_direct_IO,
......
};
</code></pre><p>如果在写的逻辑__generic_file_write_iter里面，发现设置了IOCB_DIRECT，则调用generic_file_direct_write，里面同样会调用address_space的direct_IO的函数，将数据直接写入硬盘。</p><p>ext4_direct_IO最终会调用到__blockdev_direct_IO-&gt;do_blockdev_direct_IO，这就跨过了缓存层，到了通用块层，最终到了文件系统的设备驱动层。由于文件系统是块设备，所以这个调用的是blockdev相关的函数，有关块设备驱动程序的原理我们下一章详细讲，这一节我们就讲到文件系统到块设备的分界线部分。</p><pre><code>/*
 * This is a library function for use by filesystem drivers.
 */
static inline ssize_t
do_blockdev_direct_IO(struct kiocb *iocb, struct inode *inode,
		      struct block_device *bdev, struct iov_iter *iter,
		      get_block_t get_block, dio_iodone_t end_io,
		      dio_submit_t submit_io, int flags)
{......}
</code></pre><p>接下来，我们重点看带缓存的部分如果进行读写。</p><h2>带缓存的写入操作</h2><p>我们先来看带缓存写入的函数generic_perform_write。</p><pre><code>ssize_t generic_perform_write(struct file *file,
				struct iov_iter *i, loff_t pos)
{
	struct address_space *mapping = file-&gt;f_mapping;
	const struct address_space_operations *a_ops = mapping-&gt;a_ops;
	do {
		struct page *page;
		unsigned long offset;	/* Offset into pagecache page */
		unsigned long bytes;	/* Bytes to write to page */
		status = a_ops-&gt;write_begin(file, mapping, pos, bytes, flags,
						&amp;page, &amp;fsdata);
		copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
		flush_dcache_page(page);
		status = a_ops-&gt;write_end(file, mapping, pos, bytes, copied,
						page, fsdata);
		pos += copied;
		written += copied;


		balance_dirty_pages_ratelimited(mapping);
	} while (iov_iter_count(i));
}
</code></pre><p>这个函数里，是一个while循环。我们需要找出这次写入影响的所有的页，然后依次写入。对于每一个循环，主要做四件事情：</p><ul>
<li>对于每一页，先调用address_space的write_begin做一些准备；</li>
<li>调用iov_iter_copy_from_user_atomic，将写入的内容从用户态拷贝到内核态的页中；</li>
<li>调用address_space的write_end完成写操作；</li>
<li>调用balance_dirty_pages_ratelimited，看脏页是否太多，需要写回硬盘。所谓脏页，就是写入到缓存，但是还没有写入到硬盘的页面。</li>
</ul><p>我们依次来看这四个步骤。</p><pre><code>static const struct address_space_operations ext4_aops = {
......
	.write_begin		= ext4_write_begin,
	.write_end		= ext4_write_end,
......
}
</code></pre><p>第一步，对于ext4来讲，调用的是ext4_write_begin。</p><p>ext4是一种日志文件系统，是为了防止突然断电的时候的数据丢失，引入了<strong>日志</strong>**（<strong><strong>Journal</strong></strong>）**<strong>模式</strong>。日志文件系统比非日志文件系统多了一个Journal区域。文件在ext4中分两部分存储，一部分是文件的元数据，另一部分是数据。元数据和数据的操作日志Journal也是分开管理的。你可以在挂载ext4的时候，选择Journal模式。这种模式在将数据写入文件系统前，必须等待元数据和数据的日志已经落盘才能发挥作用。这样性能比较差，但是最安全。</p><p>另一种模式是<strong>order模式</strong>。这个模式不记录数据的日志，只记录元数据的日志，但是在写元数据的日志前，必须先确保数据已经落盘。这个折中，是默认模式。</p><p>还有一种模式是<strong>writeback</strong>，不记录数据的日志，仅记录元数据的日志，并且不保证数据比元数据先落盘。这个性能最好，但是最不安全。</p><p>在ext4_write_begin，我们能看到对于ext4_journal_start的调用，就是在做日志相关的工作。</p><p>在ext4_write_begin中，还做了另外一件重要的事情，就是调用grab_cache_page_write_begin，来得到应该写入的缓存页。</p><pre><code>struct page *grab_cache_page_write_begin(struct address_space *mapping,
					pgoff_t index, unsigned flags)
{
	struct page *page;
	int fgp_flags = FGP_LOCK|FGP_WRITE|FGP_CREAT;
	page = pagecache_get_page(mapping, index, fgp_flags,
			mapping_gfp_mask(mapping));
	if (page)
		wait_for_stable_page(page);
	return page;
}
</code></pre><p>在内核中，缓存以页为单位放在内存里面，那我们如何知道，一个文件的哪些数据已经被放到缓存中了呢？每一个打开的文件都有一个struct file结构，每个struct file结构都有一个struct address_space用于关联文件和内存，就是在这个结构里面，有一棵树，用于保存所有与这个文件相关的的缓存页。</p><p>我们查找的时候，往往需要根据文件中的偏移量找出相应的页面，而基数树radix tree这种数据结构能够快速根据一个长整型查找到其相应的对象，因而这里缓存页就放在radix基数树里面。</p><pre><code>struct address_space {
	struct inode		*host;		/* owner: inode, block_device */
	struct radix_tree_root	page_tree;	/* radix tree of all pages */
	spinlock_t		tree_lock;	/* and lock protecting it */
......
}
</code></pre><p>pagecache_get_page就是根据pgoff_t index这个长整型，在这棵树里面查找缓存页，如果找不到就会创建一个缓存页。</p><p>第二步，调用iov_iter_copy_from_user_atomic。先将分配好的页面调用kmap_atomic映射到内核里面的一个虚拟地址，然后将用户态的数据拷贝到内核态的页面的虚拟地址中，调用kunmap_atomic把内核里面的映射删除。</p><pre><code>size_t iov_iter_copy_from_user_atomic(struct page *page,
		struct iov_iter *i, unsigned long offset, size_t bytes)
{
	char *kaddr = kmap_atomic(page), *p = kaddr + offset;
	iterate_all_kinds(i, bytes, v,
		copyin((p += v.iov_len) - v.iov_len, v.iov_base, v.iov_len),
		memcpy_from_page((p += v.bv_len) - v.bv_len, v.bv_page,
				 v.bv_offset, v.bv_len),
		memcpy((p += v.iov_len) - v.iov_len, v.iov_base, v.iov_len)
	)
	kunmap_atomic(kaddr);
	return bytes;
}
</code></pre><p>第三步，调用ext4_write_end完成写入。这里面会调用ext4_journal_stop完成日志的写入，会调用block_write_end-&gt;__block_commit_write-&gt;mark_buffer_dirty，将修改过的缓存标记为脏页。可以看出，其实所谓的完成写入，并没有真正写入硬盘，仅仅是写入缓存后，标记为脏页。</p><p>但是这里有一个问题，数据很危险，一旦宕机就没有了，所以需要一种机制，将写入的页面真正写到硬盘中，我们称为回写（Write Back）。</p><p>第四步，调用 balance_dirty_pages_ratelimited，是回写脏页的一个很好的时机。</p><pre><code>/**
 * balance_dirty_pages_ratelimited - balance dirty memory state
 * @mapping: address_space which was dirtied
 *
 * Processes which are dirtying memory should call in here once for each page
 * which was newly dirtied.  The function will periodically check the system's
 * dirty state and will initiate writeback if needed.
  */
void balance_dirty_pages_ratelimited(struct address_space *mapping)
{
	struct inode *inode = mapping-&gt;host;
	struct backing_dev_info *bdi = inode_to_bdi(inode);
	struct bdi_writeback *wb = NULL;
	int ratelimit;
......
	if (unlikely(current-&gt;nr_dirtied &gt;= ratelimit))
		balance_dirty_pages(mapping, wb, current-&gt;nr_dirtied);
......
}
</code></pre><p>在balance_dirty_pages_ratelimited里面，发现脏页的数目超过了规定的数目，就调用balance_dirty_pages-&gt;wb_start_background_writeback，启动一个背后线程开始回写。</p><pre><code>void wb_start_background_writeback(struct bdi_writeback *wb)
{
	/*
	 * We just wake up the flusher thread. It will perform background
	 * writeback as soon as there is no other work to do.
	 */
	wb_wakeup(wb);
}


static void wb_wakeup(struct bdi_writeback *wb)
{
	spin_lock_bh(&amp;wb-&gt;work_lock);
	if (test_bit(WB_registered, &amp;wb-&gt;state))
		mod_delayed_work(bdi_wq, &amp;wb-&gt;dwork, 0);
	spin_unlock_bh(&amp;wb-&gt;work_lock);
}


  (_tflags) | TIMER_IRQSAFE);		\
	} while (0)


/* bdi_wq serves all asynchronous writeback tasks */
struct workqueue_struct *bdi_wq;


/**
 * mod_delayed_work - modify delay of or queue a delayed work
 * @wq: workqueue to use
 * @dwork: work to queue
 * @delay: number of jiffies to wait before queueing
 *
 * mod_delayed_work_on() on local CPU.
 */
static inline bool mod_delayed_work(struct workqueue_struct *wq,
				    struct delayed_work *dwork,
				    unsigned long delay)
{....
</code></pre><p>通过上面的代码，我们可以看出，bdi_wq是一个全局变量，所有回写的任务都挂在这个队列上。mod_delayed_work函数负责将一个回写任务bdi_writeback挂在这个队列上。bdi_writeback有个成员变量struct delayed_work dwork，bdi_writeback就是以delayed_work的身份挂到队列上的，并且把delay设置为0，意思就是一刻不等，马上执行。</p><p>那具体这个任务由谁来执行呢？这里的bdi的意思是backing device info，用于描述后端存储相关的信息。每个块设备都会有这样一个结构，并且在初始化块设备的时候，调用bdi_init初始化这个结构，在初始化bdi的时候，也会调用wb_init初始化bdi_writeback。</p><pre><code>static int wb_init(struct bdi_writeback *wb, struct backing_dev_info *bdi,
		   int blkcg_id, gfp_t gfp)
{
	wb-&gt;bdi = bdi;
	wb-&gt;last_old_flush = jiffies;
	INIT_LIST_HEAD(&amp;wb-&gt;b_dirty);
	INIT_LIST_HEAD(&amp;wb-&gt;b_io);
	INIT_LIST_HEAD(&amp;wb-&gt;b_more_io);
	INIT_LIST_HEAD(&amp;wb-&gt;b_dirty_time);
	wb-&gt;bw_time_stamp = jiffies;
	wb-&gt;balanced_dirty_ratelimit = INIT_BW;
	wb-&gt;dirty_ratelimit = INIT_BW;
	wb-&gt;write_bandwidth = INIT_BW;
	wb-&gt;avg_write_bandwidth = INIT_BW;
	spin_lock_init(&amp;wb-&gt;work_lock);
	INIT_LIST_HEAD(&amp;wb-&gt;work_list);
	INIT_DELAYED_WORK(&amp;wb-&gt;dwork, wb_workfn);
	wb-&gt;dirty_sleep = jiffies;
......
}


#define __INIT_DELAYED_WORK(_work, _func, _tflags)			\
	do {								\
		INIT_WORK(&amp;(_work)-&gt;work, (_func));			\
		__setup_timer(&amp;(_work)-&gt;timer, delayed_work_timer_fn,	\
			      (unsigned long)(_work),			\
</code></pre><p>这里面最重要的是INIT_DELAYED_WORK。其实就是初始化一个timer，也即定时器，到时候我们就执行wb_workfn这个函数。</p><p>接下来的调用链为：wb_workfn-&gt;wb_do_writeback-&gt;wb_writeback-&gt;writeback_sb_inodes-&gt;__writeback_single_inode-&gt;do_writepages，写入页面到硬盘。</p><p>在调用write的最后，当发现缓存的数据太多的时候，会触发回写，这仅仅是回写的一种场景。另外还有几种场景也会触发回写：</p><ul>
<li>用户主动调用sync，将缓存刷到硬盘上去，最终会调用wakeup_flusher_threads，同步脏页；</li>
<li>当内存十分紧张，以至于无法分配页面的时候，会调用free_more_memory，最终会调用wakeup_flusher_threads，释放脏页；</li>
<li>脏页已经更新了较长时间，时间上超过了timer，需要及时回写，保持内存和磁盘上数据一致性。</li>
</ul><h2>带缓存的读操作</h2><p>带缓存的写分析完了，接下来，我们看带缓存的读，对应的是函数generic_file_buffered_read。</p><pre><code>static ssize_t generic_file_buffered_read(struct kiocb *iocb,
		struct iov_iter *iter, ssize_t written)
{
	struct file *filp = iocb-&gt;ki_filp;
	struct address_space *mapping = filp-&gt;f_mapping;
	struct inode *inode = mapping-&gt;host;
	for (;;) {
		struct page *page;
		pgoff_t end_index;
		loff_t isize;
		page = find_get_page(mapping, index);
		if (!page) {
			if (iocb-&gt;ki_flags &amp; IOCB_NOWAIT)
				goto would_block;
			page_cache_sync_readahead(mapping,
					ra, filp,
					index, last_index - index);
			page = find_get_page(mapping, index);
			if (unlikely(page == NULL))
				goto no_cached_page;
		}
		if (PageReadahead(page)) {
			page_cache_async_readahead(mapping,
					ra, filp, page,
					index, last_index - index);
		}
		/*
		 * Ok, we have the page, and it's up-to-date, so
		 * now we can copy it to user space...
		 */
		ret = copy_page_to_iter(page, offset, nr, iter);
    }
}
</code></pre><p>读取比写入总体而言简单一些，主要涉及预读的问题。</p><p>在generic_file_buffered_read函数中，我们需要先找到page cache里面是否有缓存页。如果没有找到，不但读取这一页，还要进行预读，这需要在page_cache_sync_readahead函数中实现。预读完了以后，再试一把查找缓存页，应该能找到了。</p><p>如果第一次找缓存页就找到了，我们还是要判断，是不是应该继续预读；如果需要，就调用page_cache_async_readahead发起一个异步预读。</p><p>最后，copy_page_to_iter会将内容从内核缓存页拷贝到用户内存空间。</p><h2>总结时刻</h2><p>这一节对于读取和写入的分析就到这里了。我们发现这个过程还是很复杂的，我这里画了一张调用图，你可以看到调用过程。</p><p>在系统调用层我们需要仔细学习read和write。在VFS层调用的是vfs_read和vfs_write并且调用file_operation。在ext4层调用的是ext4_file_read_iter和ext4_file_write_iter。</p><p>接下来就是分叉。你需要知道缓存I/O和直接I/O。直接I/O读写的流程是一样的，调用ext4_direct_IO，再往下就调用块设备层了。缓存I/O读写的流程不一样。对于读，从块设备读取到缓存中，然后从缓存中拷贝到用户态。对于写，从用户态拷贝到缓存，设置缓存页为脏，然后启动一个线程写入块设备。</p><p><img src="https://static001.geekbang.org/resource/image/0c/65/0c49a870b9e6441381fec8d9bf3dee65.png?wh=2683*2323" alt=""></p><h2>课堂练习</h2><p>你知道如何查询和清除文件系统缓存吗？</p><p>欢迎留言和我分享你的疑惑和见解 ，也欢迎可以收藏本节内容，反复研读。你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p><p><img src="https://static001.geekbang.org/resource/image/8c/37/8c0a95fa07a8b9a1abfd394479bdd637.jpg?wh=1110*659" alt=""></p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/4a/2c/f8451d77.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>石维康</span>
  </div>
  <div class="_2_QraFYR_0">查看文件缓存:通过free命令中的buff&#47;cache一栏的信息即可看到文件缓存的用量。<br>清除缓存：sync; echo 1 &gt; &#47;proc&#47;sys&#47;vm&#47;drop_caches</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 赞</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-05 11:31:42</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/74/c9/d3439ca4.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>why</span>
  </div>
  <div class="_2_QraFYR_0">- 系统调用层和虚拟文件系统层<br>    - 调用 read&#47;write 进行读写 → vfs_read&#47;write → __vfs_read&#47;write<br>    - 打开文件时创建 struct file, 其中有 file_operations, 虚拟文件系统调用 operations 中的 read&#47;write<br>- ext4 文件系统层<br>    - 调用到 generic_file_read&#47;write_iter,  其中判断是否需要使用缓存<br>    - 缓存, 即内存中一块空间, 可分为两类 I&#47;O<br>        - 缓存 I&#47;O: 默认模式, 读操作先检测缓存区中是否有, 若无则从文件系统读取并缓存; 写操作直接从用户空间赋值到内核缓存中, 再由 OS 决定或用户调用 sync 写回磁盘<br>        - 直接 I&#47;O: 程序直接访问磁盘, 不经过缓存<br>    - 直接 I&#47;O 过程:<br>        - 读: 若设置了 IOCB_DIRECT, 调用 address_space 的 direct_io 直接读取硬盘( 文件与内存页映射) ; 若使用缓存也要调用 address_sapce 进行文件与内存页的映射<br>        - 写: 若设置了 IOCB_DIRECT, 调用块设备驱动直接写入磁盘<br>    - 带缓存写过程<br>        - 在 while 循环中, 找出写入影响的页, 并依次写入, 完成以下四步<br>            - 每一页调用 write_begin 做准备<br>            - 将写入内容从用户态拷贝到内核态<br>            - 调用 write_end 完成写入<br>            - 查看脏页 (未写入磁盘的缓存) 是否过多, 是否需要写回磁盘<br>        - write_begin 做准备<br>            - ext4 是日志文件系统, 通过日志避免断电数据丢失<br>            - 文件分为元数据和数据, 其操作日志页分开维护<br>                - Journal 模式下: 写入数据前, 元数据及数据日志必须落盘, 安全但性能差<br>                - Order 模式下: 只记录元数据日志, 写日志前, 数据必须落盘, 折中<br>                - Writeback 模式下: 仅记录元数据日志, 数据不用先落盘<br>            - write_begin 准备日志, 并得到应该写入的缓存页<br>            - 内核中缓存以页为单位, 打开文件的 file 结构中用 radix tree 维护文件的缓存页<br>        - iov_iter_copy_from_user_atomic 拷贝内容, kmap_atomic 将缓存页映射到内核虚拟地址; 将拥护他数据拷贝到内核态; kunmap_aotmic 解映射<br>        - write_end, 先完成日志写入 并将缓存设置为脏页<br>        - 调用 balance_dirty_pages_ratelimited 若发先脏页超额, 启动一个线程执行回写.<br>            - 回写任务 delayed_work 挂在 bdi_wq  队列, 若delay 设为 0, 马上执行回写<br>            - bdi = backing device info 描述块设备信息, 初始化块设备时回初始化 timer, 到时会执行写回函数<br>        - 另外其他情况也会回写<br>            - 用户调用 sync 或内存紧张时, 回调用 wakeup_flusher_threads 刷回脏页<br>            - 脏页时间超过 timer, 及时回写<br>    - 带缓存读<br>        - generic_file_buffered_read 从 page cache 中判断是否由缓存页<br>            - 若没则从文件系统读取并预读并缓存, 再次查找缓存页<br>            - 若有, 还需判断是否需要预读, 若需要调用 page_cache_async_readahead<br>            - 最后调用 copy_page_to_user 从内核拷贝到用户空间</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-07 14:06:53</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/5e/96/a03175bc.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>莫名</span>
  </div>
  <div class="_2_QraFYR_0">“ext4_direct_IO 最终会调用到 __blockdev_direct_IO-&gt;do_blockdev_direct_IO，这就跨过了缓存层，直接到了文件系统的设备驱动层。” 觉得这个说法并不准确，绕过缓存，但并没有直接到达设备驱动层，而是通用块层，主要用于io合并之类操作，然后才是设备驱动层。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的。赞，谢谢指正</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-07-22 08:58:59</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/16/a0/3f/06b690ba.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>刘桢</span>
  </div>
  <div class="_2_QraFYR_0">打卡，今年12月冲北邮！</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 加油</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-05 01:40:38</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/16/63/9d/a5c2fe8c.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>马媛媛</span>
  </div>
  <div class="_2_QraFYR_0">请问 ext4的Journal 模式有什么优势呢，有日志逐条落盘的这个开销，为啥write不直接落盘呢？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 写入日志由于是顺序的，写入速度快很多</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-06 14:50:43</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/44/a7/171c1e86.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>啦啦啦</span>
  </div>
  <div class="_2_QraFYR_0">老师，我想问下，在学习mysql实战45讲这个课程里面，讲了数据库也有脏页和干净页，以及如何将脏页刷回磁盘的几个时机，请问这个机制是和本节课讲的操作系统的机制是一回事吗？谢谢老师</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 不一样，那是数据库层次的，不是操作系统层次的。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-07-25 12:04:53</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/ce/c6/958212b5.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>sugar</span>
  </div>
  <div class="_2_QraFYR_0">看完了老师讲的文件系统的几节，收获颇丰。但如果想要自己去实践一下，很想知道有没有像wireshark那样的网络抓包工具一样底层的 可以针对文件系统，磁盘物理结构进行监控 分析的工具呢？google了一番没找到...</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-14 10:19:01</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/12/86/fa/4bcd7365.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>玉剑冰锋</span>
  </div>
  <div class="_2_QraFYR_0">请教老师个问题1.系统默认脏页多长时间或者数量是多少的时候触发事件？2.如果脏页在回写过程中出现故障如何保证数据完整性？3.这里只是提到ext4，其他文件系统跟ext4相比原理一样吗？比如xfs？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: vm.dirty_background_bytes = 0<br>vm.dirty_background_ratio = 10<br>vm.dirty_bytes = 0<br>vm.dirty_expire_centisecs = 3000<br>vm.dirty_ratio = 30<br>vm.dirty_writeback_centisecs = 500<br><br>每个文件系统各自有各自的格式</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-12 08:02:17</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/8e/bb/c039dc11.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>garlic</span>
  </div>
  <div class="_2_QraFYR_0">free 查看Cache分配使用情况，其中 page cache是针对 file systems ， buffer是针对 block devices 两者是在不同时期不同场景下涉及的缓存机制，kernel2.4版本之前是分开的，并存的。之后版本进行了融合， 清除缓存可以操作 &#47;proc&#47;sys&#47;vm&#47;drop_caches， 学习笔记https:&#47;&#47;garlicspace.com&#47;2021&#47;03&#47;30&#47;%e6%9f%a5%e8%af%a2%e5%92%8c%e6%b8%85%e9%99%a4%e6%96%87%e4%bb%b6%e7%b3%bb%e7%bb%9f%e7%bc%93%e5%ad%98&#47;</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-04-13 08:33:47</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>安排</span>
  </div>
  <div class="_2_QraFYR_0">打卡，每天课程发出后及时看完</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-05 09:08:57</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/18/22/89/73397ccb.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>响雨</span>
  </div>
  <div class="_2_QraFYR_0">缓存利用局部性原理提高数据的读写速度，同时日志系统能够使随机读写变为顺序读写，也能提高速度。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2020-12-03 14:01:33</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>核桃</span>
  </div>
  <div class="_2_QraFYR_0">这里建议作者明确说一下bio的概念，不管是直接io还是走缓存，最后都是会封装成一个bio请求到block层的。<br><br>另外，这里有一句说法，所有的异步IO 都是直接IO，这点可以关联起来看</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-05-03 15:26:06</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/aa/21/6c3ba9af.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>lfn</span>
  </div>
  <div class="_2_QraFYR_0">2019-12-14，打卡。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-12-14 18:31:23</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>djfhchdh</span>
  </div>
  <div class="_2_QraFYR_0">free命令查看缓存</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 赞</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-20 21:03:06</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/fd/80/52763d62.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>周平</span>
  </div>
  <div class="_2_QraFYR_0">老师讲的很清晰，方便以后查看和复习</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-10 09:13:11</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/13/0f/ab/9748f40b.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>微秒</span>
  </div>
  <div class="_2_QraFYR_0">打卡，慢慢看，虽然不是很懂。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2019-06-06 17:14:30</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/fd/08/c039f840.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>小鳄鱼</span>
  </div>
  <div class="_2_QraFYR_0">第二遍： 与CPU的回写（高速缓存）策略不同的是，CPU是第二次使用脏Cache Line时立即回写。而这里，要达到一定数量的脏页才回写。为此，还需要配合更多的触发回写：长时间未回写，缓存空间紧张，用户主动sync<br>此外，回写采用的是异步线程，也可能导致数据丢失。因此还提供了日志。默认策略是：order。<br>这一切都是为了性能服务的。但这个日志策略，还考虑了数据安全跟机制性能，没有把路封死。让用户自行选择！在开发基础设施的过程中，就应该同时考虑多种场景，不帮用户选择，让他自己选择？</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-05-17 09:02:18</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/14/50/c23cf47d.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>李</span>
  </div>
  <div class="_2_QraFYR_0">不知道老师还会解答不？我有个疑问<br><br>mmap 和write 写的区别，按原理，mmap少了一次用户到内核的数据拷贝，应该快一些。<br>但我发现写数据比较大的情况下， mmap比write反而慢了。<br>不知道这个是什么原因？<br><br><br></div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2020-10-24 21:33:46</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1b/58/62/346dd248.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Q罗</span>
  </div>
  <div class="_2_QraFYR_0">元数据和数据有什么区别？</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2020-06-20 07:33:00</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/0b/6f/68cd0614.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>brian</span>
  </div>
  <div class="_2_QraFYR_0">缓存I&#47;O 内核缓存区 等于 内核缓冲区么 ？ 缓存，缓冲含义不是不同的吗？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是一个意思，用词有点随意了</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2020-05-28 18:42:03</div>
  </div>
</div>
</div>
</li>
</ul>