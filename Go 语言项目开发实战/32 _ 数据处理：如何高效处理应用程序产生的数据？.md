<audio title="32 _ 数据处理：如何高效处理应用程序产生的数据？" src="https://static001.geekbang.org/resource/audio/a0/3a/a0a645d030cf0060c06690d1bb761b3a.mp3" controls="controls"></audio> 
<p>你好，我是孔令飞。今天我们来聊聊，如何更好地进行异步数据处理。</p><p>一个大型应用为了后期的排障、运营等，会将一些请求数据保存在存储系统中，供日后使用。例如：应用将请求日志保存到 Elasticsearch 中，方便排障；网关将 API 请求次数、请求消息体等数据保存在数据库中，供控制台查询展示。</p><p>为了满足这些需求，我们需要进行数据采集，数据采集在大型应用中很常见，但我发现不少开发者设计的数据采集服务，通常会存在下面这些问题：</p><ul>
<li>采集服务只针对某个采集需求开发，如果采集需求有变，需要修改主代码逻辑，代码改动势必会带来潜在的 Bug，增加开发测试工作量。</li>
<li>数据采集服务会导致已有的服务请求延时变高。</li>
<li>采集数据性能差，需要较长时间才能采集完一批数据。</li>
<li>启停服务时，会导致采集的数据丢失。</li>
</ul><p>这一讲，我就来详细教你如何设计和落地一个数据采集服务，解决上面这些问题。</p><h2>数据采集方式的分类</h2><p>首先，你需要知道当前数据采集有哪些方式，以便更好地理解异步数据处理方案。</p><p>目前，数据采集主要有两种方式，分别是同步采集和异步采集。二者的概念和优缺点如下表所示：</p><p><img src="https://static001.geekbang.org/resource/image/d4/b9/d4d4d6547225de5b565f99957106dbb9.jpg?wh=1920x1058" alt="图片"></p><p>现代应用对性能的要求越来越高，而异步采集对应用程序的性能影响更小，因此异步采集更受开发者欢迎，得到了大规模的应用。接下来，我要介绍的 IAM Pump Server 服务，采用的就是异步采集的方式。</p><!-- [[[read_end]]] --><h2>数据采集系统设计</h2><p>这一讲，我采用理论+实战的方式来展示如何设计一个数据采集服务，这里先来介绍下关于数据采集的理论知识，后面会有具体的实战案例。</p><p>在过往的项目开发中，我发现很多开发人员添加了数据采集功能后，因为同步上报数据、单线程、上报逻辑不对等原因，让整个应用程序的性能受到了严重影响。那么，如何在采集过程中不影响程序的性能？</p><p>答案就是让数据采集模型化。通过模型化，可以使设计出来的采集系统功能更加通用，能够满足未来的很多同类需求，我们也就不需要重复开发相同的系统了。</p><p>我今天就来给你详细介绍下，如何将数据采集功能模型化，以及该模型是如何解决上面说的的各种问题的。</p><h3>设计数据采集系统时需要解决的核心问题</h3><p>采集系统首先需要一个数据源 Input，Input 可以是一个或者多个，Input 中的数据来自于应用程序上报。采集后的数据通常需要经过处理，比如格式化、增删字段、过滤无用的数据等，然后将处理后的数据存储到下游系统（Output）中，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/a9/75/a91db8c7818af0898a1774073e9bfe75.jpg?wh=1920x1145" alt="图片"></p><p>这里，我们需要解决这 3 个核心问题：</p><ul>
<li>进行数据采集，就需要在正常流程中多加一个上报数据环节，这势必会影响程序的性能。那么，如何让程序的性能损失最小化？</li>
<li>如果 Input 产生数据的速度大于 Output 的消费能力，产生数据堆积怎么办？</li>
<li>数据采集后需要存储到下游系统。在存储之前，我们需要对数据进行不同的处理，并可能会存储到不同的下游系统，这种可变的需求如何满足？</li>
</ul><p>对于让程序性能损失最小化这一点，最好的方法是异步上报。如果是异步，我们需要先把数据缓存在内存中，然后再异步上报到目标系统中。当然，为了提高上报的效率，可以采用批量上报的方式。</p><p>对于数据堆积这个问题，比较好的解决方法是，将采集的数据先上报到一些具有高吞吐量、可以存储大量数据的中间组件，比如 Kafka、Redis 中。这种方式也是业界标准的处理方式。</p><p>对于采集需求多样化这个问题，我们可以将采集程序做成插件化、可扩展的，满足可变的需求。</p><p>要解决这 3 个问题，其实就涉及到了数据采集系统中的两个功能点的设计，它们分别是数据上报功能和数据采集功能。接下来我们就来看下，如何设计这两个功能点。</p><h3>数据上报功能设计</h3><p>为了提高异步上报的吞吐量，你可以将数据缓存在内存中（Go 中可以使用有缓冲 channel），并使用多个 worker 去消费内存中的数据。使用多个 worker ，可以充分发挥 CPU 的多核能力。另外，上报给下游系统时，你也可以采用批量上报的方式。</p><h3>数据采集功能设计</h3><p>现代应用程序越来越讲究插件化、扩展性，在设计采集系统时，也应该考虑到未来的需求。比如，未来你可能需要将数据从上报到 MongoDB 切换到 HBase 中，或者同时将数据上报到 MongoDB 和 HBase 中。因此，上报给下游的程序逻辑要具有插件化的能力，并能通过配置选择需要的插件。</p><p>为了提高程序性能，会先把数据缓存在内存中。但是这样有个缺点：在关停程序时，内存中的数据就会丢失。所以，在程序结束之前，我们需要确保内存中的数据能够上报成功，也就是说采集程序需要实现优雅关停功能。优雅关停不仅要确保缓存中的数据被成功上报，还要确保正在处理的数据被成功上报。</p><p>当然了，既然是数据采集，还要能够配置采集的频率。最后，因为采集程序通常是非 API 类型的，所以还需要对外暴露一个特殊的 API，用来返回采集程序的健康状态。</p><h3>数据采集应用模型</h3><p>通过上面的分析和设计，可以绘制出下面这个采集模型：</p><p><img src="https://static001.geekbang.org/resource/image/2e/34/2ecccdb3c851577f9cd5a56bb7197c34.jpg?wh=1920x910" alt="图片"></p><p>异步上报需要额外的异步逻辑，会增加开发工作量和程序复杂度，所以，对于一些 Input 数据生产速度小于 Output 消费速度，并且 Output 具有高吞吐量、低延时特性的场景，也可以采用同步上报，例如同步上报给 Redis。</p><h2>数据采集系统落地项目：iam-authz-server + iam-pump</h2><p>上面，我介绍了数据采集系统的架构，但是只有模型和理论，肯定还不足以解决你对数据采集程序的开发需求。所以，接下来我来介绍下如何落地上面的数据采集架构。整个架构包括两个部分，分别由不同的服务实现：</p><ul>
<li>iam-authz-server：实现数据上报功能。</li>
<li>iam-pump：实现数据采集功能。</li>
</ul><p>整个采集系统的架构，跟上面描述的数据采集架构完全一致，这里就不重复说明了。</p><h2>iam-authz-server：数据上报</h2><p>数据上报的最大难点，就是如何减少上报逻辑对应用性能的影响。对此，我们主要的解决思路就是异步上报数据。</p><p>接下来我会介绍 iam-authz-server 的数据上报设计。这是一个非常成熟的设计，在我所开发和了解的项目中被大量采用，有些项目可以承载十亿级/天的请求量。通过介绍这个设计，我们来看看异步上报的具体方法，以及上报过程中要考虑的因素。</p><p>iam-authz-server 的数据上报架构如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/4d/3f/4d288a15fa6ebaae5ef25df8af5ac13f.jpg?wh=1920x764" alt="图片"></p><p>iam-authz-server 服务中的数据上报功能可以选择性开启，开启代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/server.go#L147-L156">internal/authzserver/server.go</a> ，代码如下：</p><pre><code class="language-go">&nbsp;if s.analyticsOptions.Enable {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; analyticsStore := storage.RedisCluster{KeyPrefix: RedisKeyPrefix}&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns := analytics.NewAnalytics(s.analyticsOptions, &amp;analyticsStore)&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Start()&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; s.gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; analyticsIns.Stop()&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return nil&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; }))&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; }&nbsp; &nbsp;&nbsp; 
</code></pre><p>上面的代码中，当 <code>s.analyticsOptions.Enable</code> 为 <code>true</code> 时，开启数据上报功能。因为数据上报会影响程序的性能，而且在未来可能会存在禁掉数据上报功能的场景，所以在设计 iam-authz-server 时，就把数据上报功能做成了可配置的，也就是说可以通过配置文件来启用/禁用数据上报功能。配置方式也很简单：将 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-authz-server.yaml#L63">iam-authz-server.yaml</a> 的 analytics.enable 设置为 true，代表开启数据上报功能；设置为 false ，则代表关闭数据上报功能。</p><p>这里，我建议你在设计程序时，将未来的可能变量考虑进去，并将这些变量做成可配置的。这样，如果哪天需求变化，我们就能通过修改配置文件，而不是修改代码的方式来满足需求。这种方式可以将应用程序的变动局限在配置文件中，从而大大减小现网服务出现故障的概率，做到只变更配置文件就可以缩短发布变更的周期。</p><p>在上面的代码中，通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L64-L79">NewAnalytics</a> 创建一个数据上报服务，代码如下：</p><pre><code class="language-go">func NewAnalytics(options *AnalyticsOptions, store storage.AnalyticsHandler) *Analytics {&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; ps := options.PoolSize&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; recordsBufferSize := options.RecordsBufferSize&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; workerBufferSize := recordsBufferSize / uint64(ps)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; log.Debug("Analytics pool worker buffer size", log.Uint64("workerBufferSize", workerBufferSize))&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; recordsChan := make(chan *AnalyticsRecord, recordsBufferSize)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; return &amp;Analytics{&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; store:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; store,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; poolSize:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ps,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; recordsChan:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; recordsChan,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; workerBufferSize:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;workerBufferSize,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; recordsBufferFlushInterval: options.FlushInterval,&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp; }&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;
}&nbsp; &nbsp; &nbsp;&nbsp;
</code></pre><p>这里的代码根据传入的参数，创建 Analytics 类型的变量并返回，变量中有 5 个字段需要你关注：</p><ul>
<li>store： <a href="https://github.com/marmotedu/iam/blob/v1.0.6/pkg/storage/storage.go#L65-L71">storage.AnalyticsHandler</a> 接口类型，提供了 <code>Connect() bool</code>和 <code>AppendToSetPipelined(string, byte)</code>函数，分别用来连接 storage 和上报数据给 storage。iam-authz-server 用了 redis storage。</li>
<li>recordsChan：授权日志会缓存在 recordsChan 带缓冲 channel 中，其长度可以通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-authz-server.yaml#L65">iam-authz-server.yaml</a> 配置文件中的  <code>analytics.records-buffer-size</code>  配置。</li>
<li>poolSize：指定开启 worker 的个数，也就是开启多少个 Go 协程来消费 recordsChan 中的消息。</li>
<li>workerBufferSize：批量投递给下游系统的的消息数。通过批量投递，可以进一步提高消费能力、减少 CPU 消耗。</li>
<li>recordsBufferFlushInterval：设置最迟多久投递一次，也就是投递数据的超时时间。</li>
</ul><p>analytics.ecords-buffer-size 和 analytics.pool-size 建议根据部署机器的 CPU 和内存来配置。在应用真正上线前，我建议你通过压力和负载测试，来配置一个合适的值。</p><p>Analytics提供了 3 种方法：</p><ul>
<li>Start()，用来启动数据上报服务。</li>
<li>Stop()，用来关停数据上报服务。主程序在收到系统的终止命令后，调用 Stop 方法优雅关停数据上报服务，确保缓存中的数据都上报成功。</li>
<li>RecordHit(record *AnalyticsRecord) error，用来记录 AnalyticsRecord 的数据。</li>
</ul><p>通过 NewXxx （NewAnalytics）返回一个 Xxx （Analytics）类型的结构体，Xxx（Analytics） 类型带有一些方法，如下：</p><pre><code class="language-go">func NewAnalytics(options) *Analytics {
    ...
}

func (r *Analytics) Start() {
    ...
}
func (r *Analytics) Stop() {
    ...
}
func (r *Analytics) RecordHit(record *AnalyticsRecord) error {
    ...
}
</code></pre><p>其实，上述代码段是一种常见的 Go 代码编写方式/设计模式。你在以后的开发生涯中，会经常遇到这种设计方式。使用上述代码设计方式有下面两个好处。</p><ul>
<li><strong>功能模块化：</strong>将数据上报的功能封装成一个服务模块，数据和方法都围绕着 Xxx 结构体来展开。这和 C++、Java、Python 的类有相似的地方，你可以这么理解：Xxx 相当于类，NewXxx 相当于初始化一个类实例，Start、Stop、RecordHit 是这个类提供的方法。功能模块化可以使程序逻辑更加清晰，功能更独立、更好维护，也可以供其他应用使用。</li>
<li><strong>方便数据传递：</strong>可以将数据存放在 Xxx 结构体字段中，供不同的方法共享使用，如果有并发，数据共享时，注意要给非并发安全的类型加锁，例如recordsChan。</li>
</ul><p>接下来，我会介绍 iam-authz-server 服务中跟数据上报相关的 3 部分核心代码，分别是启动数据上报服务、异步上报授权日志和优雅关停数据上报。</p><h3>启动服务：启动数据上报服务</h3><p>在服务启动时，首先要启动数据上报功能模块。我们通过调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L87-L100">analyticsIns.Start()</a> 启动数据上报服务。Start 代码如下：</p><pre><code class="language-go">func (r *Analytics) Start() {
    analytics = r
    r.store.Connect()

    // start worker pool
    atomic.SwapUint32(&amp;r.shouldStop, 0)
    for i := 0; i &lt; r.poolSize; i++ {
        r.poolWg.Add(1)
        go r.recordWorker()
    }

    // stop analytics workers
    go r.Stop()
}
</code></pre><p>这里有一点需要你注意，数据上报和数据采集都大量应用了 Go 协程来并发地执行操作，为了防止潜在的并发读写引起的Bug，建议你的测试程序编译时加上 -race，例如go build -race cmd/iam-authz-server/authzserver.go。然后，在测试过程中，观察程序日志，看有无并发问题出现。</p><p>Start 中会开启 poolSize 个数的 worker 协程，这些协程共同消费 recordsChan 中的消息，消费逻辑见 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L128-L173">recordWorker()</a> ，代码如下：</p><pre><code class="language-go">func (r *Analytics) recordWorker() {
	defer r.poolWg.Done()

	// this is buffer to send one pipelined command to redis
	// use r.recordsBufferSize as cap to reduce slice re-allocations
	recordsBuffer := make([][]byte, 0, r.workerBufferSize)

	// read records from channel and process
	lastSentTS := time.Now()
	for {
		readyToSend := false
		select {
		case record, ok := &lt;-r.recordsChan:
			// check if channel was closed and it is time to exit from worker
			if !ok {
				// send what is left in buffer
				r.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)
				return
			}

			// we have new record - prepare it and add to buffer

			if encoded, err := msgpack.Marshal(record); err != nil {
				log.Errorf("Error encoding analytics data: %s", err.Error())
			} else {
				recordsBuffer = append(recordsBuffer, encoded)
			}

			// identify that buffer is ready to be sent
			readyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize

		case &lt;-time.After(r.recordsBufferFlushInterval):
			// nothing was received for that period of time
			// anyways send whatever we have, don't hold data too long in buffer
			readyToSend = true
		}

		// send data to Redis and reset buffer
		if len(recordsBuffer) &gt; 0 &amp;&amp; (readyToSend || time.Since(lastSentTS) &gt;= recordsBufferForcedFlushInterval) {
			r.store.AppendToSetPipelined(analyticsKeyName, recordsBuffer)
			recordsBuffer = recordsBuffer[:0]
			lastSentTS = time.Now()
		}
	}
}
</code></pre><p>recordWorker 函数会将接收到的授权日志保存在 recordsBuffer 切片中，当数组内元素个数为 workerBufferSize ，或者距离上一次投递时间间隔为 recordsBufferFlushInterval 时，就会将 recordsBuffer 数组中的数据上报给目标系统（Input）。<br>
recordWorker()中有些设计技巧，很值得你参考。</p><ul>
<li>使用 <a href="https://github.com/vmihailenco/msgpack">msgpack</a> 序列化消息：msgpack 是一个高效的二进制序列化格式。它像 JSON 一样，让你可以在各种语言之间交换数据。但是它比 JSON 更快、更小。</li>
<li>支持 Batch Windows：当 worker 的消息数达到指定阈值时，会批量投递消息给 Redis，阈值判断代码为<code>readyToSend = uint64(len(recordsBuffer)) == r.workerBufferSize</code>。</li>
<li>超时投递：为了避免因为产生消息太慢，一直达不到 Batch Windows，无法投递消息这种情况，投递逻辑也支持超时投递，通过 <code>case &lt;-time.After(r.recordsBufferFlushInterval)</code>代码段实现。</li>
<li>支持优雅关停：当 recordsChan 关闭时，将 recordsBuffer 中的消息批量投递给 Redis，之后退出 worker 协程。</li>
</ul><p>这里有个注意事项：投递完成后，你需要重置 recordsBuffer 和计时器，否则会重复投递数据：</p><pre><code class="language-go">recordsBuffer = recordsBuffer[:0]
lastSentTS = time.Now()
</code></pre><p>这里还设置了一个最大的超时时间 recordsBufferForcedFlushInterval，确保消息最迟被投递的时间间隔。也就是说， iam-authz-server 强制要求最大投递间隔为 recordsBufferForcedFlushInterval 秒，这是为了防止配置文件将 recordsBufferFlushInterval 设得过大。</p><h3>运行服务：异步上报授权日志</h3><p>开启了数据上报服务后，当有授权日志产生时，程序就会自动上报数据。接下来，我会详细介绍下如何高效上报数据。</p><p>iam-authz-server 会在授权成功时调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/authorization/authorizer/authorizer.go#L100-L115">LogGrantedAccessRequest</a> 函数，在授权失败时调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/authorization/authorizer/authorizer.go#L71-L97">LogRejectedAccessRequest</a> 函数。并且，在这两个函数中，调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L115-L126">RecordHit </a>函数，记录授权日志。</p><p>iam-authz-server 通过调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L115-L126">RecordHit(record *AnalyticsRecord) error</a> 函数，异步缓存授权日志。调用 RecordHit 后，会将 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L26-L35">AnalyticsRecord</a> 类型的消息存放到 recordsChan 有缓冲 channel 中。</p><p>这里要注意：在缓存前，需要判断上报服务是否在优雅关停中，如果在关停中，则丢弃该消息：</p><pre><code class="language-go">if atomic.LoadUint32(&amp;r.shouldStop) &gt; 0 {
    return nil
}
</code></pre><p>通过将授权日志缓写入 recordsChan 有缓冲 channel 中，LogGrantedAccessRequest 和 LogRejectedAccessRequest 函数可以不用等待授权日志上报成功就返回，这样就使得整个授权请求的性能损耗几乎为零。</p><h3>关停服务：优雅关停数据上报</h3><p>完成数据上报之后的下一步，就是要优雅地将数据上报关停。为了确保在应用关停时，缓存中的数据和正在投递中的数据都能够投递到 Redis，iam-authz-server 实现了数据上报关停功能，代码如下：</p><pre><code class="language-go">gs.AddShutdownCallback(shutdown.ShutdownFunc(func(string) error {
    analyticsIns.Stop()
    return nil
}))
</code></pre><p>当收到 os.Interrupt 和 syscall.SIGTERM 系统信号后，调用 analyticsIns.Stop()函数，关停数据上报服务， <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/authzserver/analytics/analytics.go#L103-L112">Stop</a> 函数会停止接收新的授权日志，并等待正在上报的数据上报完成。</p><p>上面我介绍了数据上报部分的功能设计，接下来，我来介绍下数据采集部分的功能设计。</p><h2>iam-pump：数据采集</h2><p>iam-authz-server 将数据上报到 Redis，iam-pump 消费 Redis 中的数据，并保存在 MongoDB 中做持久化存储。</p><p>iam-pump 的设计要点是：插件化、可配置地将 Redis 中的数据处理后存储到下游系统中，并且实现优雅关停功能，这些也是设计数据采集程序的要点和难点所在。下面，我们就来看下 iam-pump 是如何插件化地实现一个数据采集程序的。这个数据采集程序的设计思路，在我开发的大型企业应用中有实际的落地验证，你可以放心使用。</p><p>iam-pump 数据采集架构如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/91/ed/913b92d58cfd7cba0dff26612be9e9ed.jpg?wh=1920x1129" alt="图片"></p><p>在iam-pump服务启动时，要启动数据采集功能，启动代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58">internal/pump/server.go</a>。</p><p>接下来，我会介绍下 iam-pump 服务中的 5 部分核心代码：</p><ul>
<li>数据采集插件定义。</li>
<li>初始化数据采集插件。</li>
<li>健康检查。</li>
<li>启动 Loop 周期性消费 Redis 数据。</li>
<li>优雅关停数据采集服务。</li>
</ul><h3>初始化服务：数据采集插件定义</h3><p>数据采集组件设计的核心是插件化，这里我<strong>将需要上报的系统抽象成一个个的 pump</strong>，那么如何定义 pump 接口呢？接口定义需要参考实际的采集需求，通常来说，至少需要下面这几个函数。</p><ul>
<li><strong>New：</strong>创建一个 pump。</li>
<li><strong>Init：</strong>初始化一个 pump，例如，可以在 Init 中创建下游系统的网络连接。</li>
<li><strong>WriteData：</strong>往下游系统写入数据。为了提高性能，最好支持批量写入。</li>
<li><strong>SetFilters：</strong>设置是否过滤某条数据，这也是一个非常常见的需求，因为不是所有的数据都是需要的。</li>
<li><strong>SetTimeout：</strong>设置超时时间。我就在开发过程中遇到过一个坑，连接 Kafka 超时，导致整个采集程序超时。所以这里需要有超时处理，通过超时处理，可以保证整个采集框架正常运行。</li>
</ul><p>我之前开发过公有云的网关服务，网关服务需要把网关的请求数据转存到 MongoDB 中。我们的网关服务曾经遇到一个比较大的坑：有些用户会通过网关上传非常大的文件（百 M 级别），这些数据转存到 MongoDB 中，快速消耗了 MongoDB 的存储空间（500G 存储空间）。为了避免这个问题，在转存数据时，需要过滤掉一些比较详细的数据，所以 iam-pump 添加了 SetOmitDetailedRecording 来过滤掉详细的数据。</p><p>所以，最后 iam-pump 的插件接口定义为 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/pumps/pump.go#L15-L26">internal/pump/pumps/pump.go</a> ：</p><pre><code class="language-go">type Pump interface {
	GetName() string
	New() Pump
	Init(interface{}) error
	WriteData(context.Context, []interface{}) error
	SetFilters(analytics.AnalyticsFilters)
	GetFilters() analytics.AnalyticsFilters
	SetTimeout(timeout int)
	GetTimeout() int
	SetOmitDetailedRecording(bool)
	GetOmitDetailedRecording() bool
}
</code></pre><p>你在实际开发中，如果有更多的需求，可以在 Pump interface 定义中继续添加需要的处理函数。</p><h3>初始化服务：初始化数据采集插件</h3><p>定义好插件之后，需要初始化插件。在 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L97-L124">initialize</a> 函数中初始化 pumps：</p><pre><code class="language-go">func (s *pumpServer) initialize() {
	pmps = make([]pumps.Pump, len(s.pumps))
	i := 0
	for key, pmp := range s.pumps {
		pumpTypeName := pmp.Type
		if pumpTypeName == "" {
			pumpTypeName = key
		}

		pmpType, err := pumps.GetPumpByName(pumpTypeName)
		if err != nil {
			log.Errorf("Pump load error (skipping): %s", err.Error())
		} else {
			pmpIns := pmpType.New()
			initErr := pmpIns.Init(pmp.Meta)
			if initErr != nil {
				log.Errorf("Pump init error (skipping): %s", initErr.Error())
			} else {
				log.Infof("Init Pump: %s", pmpIns.GetName())
				pmpIns.SetFilters(pmp.Filters)
				pmpIns.SetTimeout(pmp.Timeout)
				pmpIns.SetOmitDetailedRecording(pmp.OmitDetailedRecording)
				pmps[i] = pmpIns
			}
		}
		i++
	}
}
</code></pre><p>initialize 会创建、初始化，并调用 SetFilters、SetTimeout、SetOmitDetailedRecording 来设置这些 pump。Filters、Timeout、OmitDetailedRecording 等信息在 pump 的配置文件中指定。</p><p>这里有个技巧你也可以注意下：pump 配置文件支持通用的配置，也支持自定义的配置，配置结构为 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/options/options.go#L18-L24">PumpConfig</a> ：</p><pre><code class="language-go">type PumpConfig struct {
	Type                  string
	Filters               analytics.AnalyticsFilters
	Timeout               int
	OmitDetailedRecording bool
	Meta                  map[string]interface{}
}
</code></pre><p>pump 自定义的配置可以存放在 map 类型的变量 Meta 中。通用配置可以使配置共享，减少开发和维护工作量，自定义配置可以适配不同pump的差异化配置。</p><h3>初始化服务：健康检查</h3><p>因为 iam-pump 是一个非 API 服务，为了监控其运行状态，这里也设置了一个健康检查接口。iam-pump 组件通过调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server/server.go#L15-L25">server.ServeHealthCheck</a> 函数启动一个 HTTP 服务，ServeHealthCheck 函数代码如下：</p><pre><code class="language-go">func ServeHealthCheck(healthPath string, healthAddress string) {
	http.HandleFunc("/"+healthPath, func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-type", "application/json")
		w.WriteHeader(http.StatusOK)
		_, _ = w.Write([]byte(`{"status": "ok"}`))
	})

	if err := http.ListenAndServe(healthAddress, nil); err != nil {
		log.Fatalf("Error serving health check endpoint: %s", err.Error())
	}
}
</code></pre><p>该函数启动了一个 HTTP 服务，服务监听地址通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L7">health-check-address</a> 配置，健康检查路径通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L6">health-check-path</a> 配置。如果请求 <code>http://&lt;health-check-address&gt;/&lt;health-check-path&gt;</code>返回<code>{"status": "ok"}</code>，说明 iam-pump 可以正常工作。</p><p>这里的健康检查只是简单返回了一个字符串，实际开发中，可以封装更复杂的逻辑。比如，检查进程是否可以成功 ping 通数据库，进程内的工作进程是否处于 worker 状态等。</p><p>iam-pump 默认的健康检查请求地址为<code>http://127.0.0.1:7070/healthz</code> 。</p><h3>运行服务：启动 Loop 周期性消费 Redis 数据</h3><p>初始化 pumps 之后，就可以通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58-L95">Run</a> 函数启动消费逻辑了。在 Run 函数中，会定期（通过配置 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/configs/iam-pump.yaml#L5">purge-delay</a> 设置轮训时间）从 Redis 中获取所有数据，经过 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L72">msgpack.Unmarshal</a> 解压后，传给 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L126">writeToPumps</a> 处理：</p><pre><code class="language-go">func (s preparedPumpServer) Run(stopCh &lt;-chan struct{}) error {
	ticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)
	defer ticker.Stop()

	for {
		select {
		case &lt;-ticker.C:
			analyticsValues := s.analyticsStore.GetAndDeleteSet(storage.AnalyticsKeyName)
			if len(analyticsValues) &gt; 0 {
				// Convert to something clean
				keys := make([]interface{}, len(analyticsValues))

				for i, v := range analyticsValues {
					decoded := analytics.AnalyticsRecord{}
					err := msgpack.Unmarshal([]byte(v.(string)), &amp;decoded)
					log.Debugf("Decoded Record: %v", decoded)
					if err != nil {
						log.Errorf("Couldn't unmarshal analytics data: %s", err.Error())
					} else {
						if s.omitDetails {
							decoded.Policies = ""
							decoded.Deciders = ""
						}
						keys[i] = interface{}(decoded)
					}
				}

				// Send to pumps
				writeToPumps(keys, s.secInterval)
			}
		// exit consumption cycle when receive SIGINT and SIGTERM signal
		case &lt;-stopCh:
			log.Info("stop purge loop")

			return nil
		}
	}
}
</code></pre><p>writeToPumps 函数通过调用 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L165-L213">execPumpWriting</a> 函数，异步调用 pump 的 WriteData 函数写入数据。execPumpWriting 函数中有一些设计技巧，你可以注意下这两个：</p><ul>
<li>将一些通用的处理，例如 Filters、Timeout、OmitDetailedRecording 放在 pump 之外处理，这样可以减少 pump 中代码的重复性。</li>
<li>优雅关停。通过如下代码实现优雅关停功能：</li>
</ul><pre><code class="language-go">select {
    case &lt;-stopCh:
        log.Info("stop purge loop")
        return
    default:
}
</code></pre><p>上面的代码需要放在 writeToPumps 之后，这样可以确保所有数据都成功写入 pumps 之后，再停止采集逻辑。</p><h3>关停服务：优雅关停数据采集服务</h3><p>在关停服务时，为了确保正在处理的数据被成功存储，还需要提供优雅关停功能。iam-pump 通过 channel 传递 SIGINT 和 SIGTERM 信号，当消费逻辑收到这两个信号后，会退出消费循环，见 <a href="https://github.com/marmotedu/iam/blob/v1.0.6/internal/pump/server.go#L58">Run</a> 函数。代码如下：</p><pre><code class="language-plain">func (s preparedPumpServer) Run(stopCh &lt;-chan struct{}) error {&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; ticker := time.NewTicker(time.Duration(s.secInterval) * time.Second)&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; defer ticker.Stop()&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; for {&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; select {&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; case &lt;-ticker.C:&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 消费逻辑
         ...
        // exit consumption cycle when receive SIGINT and SIGTERM signal
&nbsp; &nbsp; &nbsp; &nbsp; case &lt;-stopCh:&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; log.Info("stop purge loop")&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp;&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return nil
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
}

</code></pre><h2>总结</h2><p>这一讲，我主要介绍了如何将数据采集需求转化成一个数据采集模型，并从这个模型出发，设计出一个可扩展、高性能的数据采集服务，并通过 iam-pump 组件来落地该采集模型。</p><p>最后，我还想给你一个建议：在开发中，你也可以将一些功能抽象成一些通用的模型，并为该模型实现基本框架（引擎），然后将一些需要定制化的部分插件化。通过这种方式，可以设计出一个高扩展的服务，使得服务不仅能够满足现在的需求，还能够满足未来的需求。</p><h2>课后练习</h2><ol>
<li>思考下，如何设计一个数据上报和数据采集应用，设计时有哪些点需要注意？</li>
<li>动手练习下，启动 iam-authz-server 和 iam-pump 服务，验证整个流程。</li>
</ol><p>欢迎你在留言区与我交流讨论，我们下一讲见。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/7a/d2/4ba67c0c.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Sch0ng</span>
  </div>
  <div class="_2_QraFYR_0">数据采集服务分数据上报和数据采集，先做拆分再有针对性达成目标性能。<br>把功能抽象成模型，再把实现封装成独立的模块，应用依赖模型的接口，不依赖具体的实现。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 到位！</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-08-16 23:22:53</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/63/84/f45c4af9.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Vackine</span>
  </div>
  <div class="_2_QraFYR_0">pump如果中途退出了，会记录已经消费的位置么？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这里暂时不支持。<br><br>老哥，可以尝试将redis切换成kafka，kafka可以记录消费位置</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-08-07 17:44:33</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKXjfJWVQGDHmDEI73VQO4dgTzaK5LLz2ax9XUF4FCPy1Oib8aQLibFzpcsiavVVbAQlG4pbrfibdwaYA/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Geek_63505f</span>
  </div>
  <div class="_2_QraFYR_0">老师这句话是什么意思 viper.SetEnvKeyReplacer(strings.NewReplacer(&quot;.&quot;, &quot;_&quot;, &quot;-&quot;, &quot;_&quot;)) <br>    strings.NewReplacer里面不应该是(&quot;-&quot;,&quot;_&quot;)这样吗？前面那两个字符多出来是干嘛用的？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 将 . 也转换为_</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-01-22 20:59:02</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/87/64/3882d90d.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>yandongxiao</span>
  </div>
  <div class="_2_QraFYR_0">总结：<br>数据采集服务常见问题：不够通用化；采集服务延迟高、性能差、启停服务时会有数据丢失。<br>数据采集服务一般需要完成：数据上报 和 数据处理。它们一般不是同一个进程内。<br>数据上报：对数据压缩、支持批量上报、超时上报、优雅关停（停止接收新请求，完成服务中的请求）<br>数据处理：数据处理完毕后，还需要进行上报。将上报的模块做成插件化，非常重要。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-12-04 13:15:15</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/60/a1/8f003697.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>静心</span>
  </div>
  <div class="_2_QraFYR_0">这个插件化的pump模型抽象的真好，感觉这个pump项目完全可以用到生产了。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这个模型就是源自亿级QPS的生产项目，完全可以用到生产环境中。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-10-29 13:43:49</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/53/db/858337e3.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Ethan Liu</span>
  </div>
  <div class="_2_QraFYR_0">应用产生的数据放到日志中,再由数据上报服务读取至bufferd channel吗? <br>同步上报方式指的是rpc吗?</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 同步上报指的是：调用上报接口，并阻塞直到上报接口返回。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2021-09-09 20:34:55</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/5f/c2/997e298b.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>来咯</span>
  </div>
  <div class="_2_QraFYR_0">ensureConnection   redis 重新连接 失败 应该需要sleep吧 不然日志写爆  CPU 也占满了</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 没问题的</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-05-27 16:56:51</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/b5/e6/c67f12bd.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>左耳朵东</span>
  </div>
  <div class="_2_QraFYR_0"><br>func (r *Analytics) Start() {<br>    analytics = r<br>    r.store.Connect()<br><br>    &#47;&#47; start worker pool<br>    atomic.SwapUint32(&amp;r.shouldStop, 0)<br>    for i := 0; i &lt; r.poolSize; i++ {<br>        r.poolWg.Add(1)<br>        go r.recordWorker()<br>    }<br><br>    &#47;&#47; stop analytics workers<br>    go r.Stop()<br>}<br><br>倒数第二行代码 go r.Stop()，这里把 recordsChan 马上又关闭了？那后面还怎么给这个 channel 发消息？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这里是个bug哈，master分支有纠正过来，这里我让编辑改下</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-03-14 20:35:49</div>
  </div>
</div>
</div>
</li>
</ul>