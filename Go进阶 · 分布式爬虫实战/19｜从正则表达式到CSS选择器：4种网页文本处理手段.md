<audio title="19｜从正则表达式到CSS选择器：4种网页文本处理手段" src="https://static001.geekbang.org/resource/audio/yy/42/yy8b60efe5d80ef0yy383e0f53e08342.mp3" controls="controls"></audio> 
<p>你好，我是郑建勋。</p><p>在上一节课程中，我们了解了Go Modules依赖管理的使用方法和原理，这有助于我们在后期管理项目的复杂依赖。我之所以提前介绍依赖管理，是因为新项目一开始一般就会通过go mod init初始化当前项目的module名。</p><p>我们之前也看到了如何在Go中通过简单的函数调用获取网页中的数据。然而单单获取服务器返回的文本数据是远远不够的，信息和知识就隐藏在这些杂乱的数据之中。因此，我们需要有比较强的文本解析能力，将有用的信息提取出来。这节课，我们就来看看如何通过Go标准库、正则表达式、XPath以及CSS选择器对复杂文本进行解析。</p><p>现在，让我们在任意位置新建一个文件：</p><pre><code class="language-plain">&gt;  mkdir crawler
</code></pre><p>再新建一个入口文件：</p><pre><code class="language-plain">&gt; cd crawler
&gt; touch main.go
</code></pre><h2><strong>初始化Git仓库</strong></h2><p>我先在GitHub上创建了一个Git仓库，名字叫crawler。接着，我在本地新建了一个README文件，并建立了本地仓库和远程仓库之间的关联（你需要将下面的仓库地址替换为自己的）：</p><pre><code class="language-plain">echo "# crawler" &gt;&gt; README.md
git init
git add README.md
git commit -m "first commit"
git branch -M 'main'
git remote add origin git@github.com:dreamerjackson/crawler.git
git push -u origin 'main'
</code></pre><!-- [[[read_end]]] --><p>接下来，我们要初始化项目的go.mod文件，module名一般为远程Git仓库的名字：</p><pre><code class="language-plain">go mod init  github.com/dreamerjackson/crawler
</code></pre><p>后续我会将项目的源码放置到 <a href="https://github.com/dreamerjackson/crawler">GitHub</a> 中，欢迎你积极提交PR，大家一起进步。</p><p>下一步，我们创建一个 <code>.gitignore</code> 文件，<code>.gitignore</code> 文件的内容不会被Git追踪。当有一些编辑器的配置文件或其他文件不想提交到Git仓库时，可以将文件路径放入 <code>.gitignore</code> 文件。</p><pre><code class="language-plain">echo .idea  &gt;&gt; .gitignore
</code></pre><h2><strong>抓取一个简单的网页</strong></h2><p>假设我们希望获取一些最新的新闻资讯，但是我们却不可能时刻守在电脑旁刷新网页，这就是爬虫大显身手的地方了。我们以知名的<a href="https://www.thepaper.cn/">澎湃新闻</a>为例，获取其首页的新闻内容。</p><p>一开始我选取澎湃新闻这个网站，是因为澎湃新闻的首页不需要登录，也没有严厉的反扒机制。这能够减轻你刚开始学习爬虫的心理负担，聚焦于这节课传授的知识。</p><p>获取新闻首页HTML文本的代码如下所示。</p><pre><code class="language-plain">package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
)

func main() {
	url := "https://www.thepaper.cn/"
	resp, err := http.Get(url)

	if err != nil {
		fmt.Println("fetch url error:%v", err)
		return
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		fmt.Printf("Error status code:%v", resp.StatusCode)
	  return
	}

	body, err := ioutil.ReadAll(resp.Body)

	if err != nil {
		fmt.Println("read content failed:%v", err)
		return
	}

	fmt.Println("body:", string(body))
}
</code></pre><p>这段代码做了比较完备的错误检查。不管是http.Get访问网站报错、服务器返回的状态码不是200，还是读取返回的数据有误，都会打印错误到控制台，并立即返回。ioutil.ReadAll会读取返回数据的字节数组。然后将字节数组强转为字符串类型，最后输出结果。</p><p>在我们当前这个案例中，输出的文本是HTML格式的。HTML又被称为超文本标记语言。其中，超文本指的是包含具有指向其他文本链接的文本 。通过链接，单个网站内或网站之间就连接了起来。</p><p>标记指的是通过通常是成对出现的标签来标识文本的属性和结构。例如，<code>&lt;h1&gt;xxx&lt;/h1&gt;</code> 标识元素的样式是一级标题，<code>&lt;h2&gt;xxx&lt;/h2&gt;</code> 标识元素的样式是二级标题 。而 <code>&lt;img&gt;</code> 标识当前元素是一张图片。其他的标签还有<code>&lt;title&gt;, &lt;body&gt;, &lt;header&gt;, &lt;footer&gt;, &lt;article&gt;, &lt;section&gt;, &lt;p&gt;, &lt;div&gt;, &lt;span&gt; </code> …</p><p>HTML定义了元素的含义和结构。不过随着CSS文件的出现，HTML在文本样式上的功能逐渐弱化了。标签和标签里的属性（例如<code>&lt;div class="news_li" id="cont19144401" &gt;</code>  ）一般是作为CSS选择器的钩子出现的。</p><p>我们在浏览器上看到的网页，其实是将HTML文件、CSS样式文件进行了渲染，同时，JavaScript文件还可以让网站完成一些动态的效果，例如实时的内容更新，交互式的内容等。</p><p>我们先通过Linux管道的方式将输出的文本保存到new.html文件中：</p><pre><code class="language-plain">go run main.go &gt; new.html
</code></pre><p>用浏览器打开之后会看到，当前的页面和真实的页面相比，还原度是比较高的。当然我们无法用这种方式100%还原网页，因为缺失了必要的文件，而且有一些数据是通过JavaScript动态获取的。</p><p><img src="https://static001.geekbang.org/resource/image/2b/8d/2ba3ffd626699df88186d81f0f1ffc8d.png?wh=1920x979" alt="图片"></p><p>不过，就我们当下的目标而言，获取到的信息已经足够了。</p><p>在项目开发过程中，我会用Git在关键的地方打上tag，方便你之后查找当前的代码。上述代码位于v0.0.1分支中。</p><pre><code class="language-plain">git commit -am "print resp"
git tag -a v0.0.1 -m "print resp"
git push origin v0.0.1
</code></pre><p>接下来让我们看看如何处理服务器返回的HTML文本。</p><h2><strong>strings</strong></h2><p>Go语言提供了strings标准库用于字符处理函数。如下所示，在标准库strings包中，包含字符查找、分割、大小写转换、修剪（trim）、计算字符出现次数等数十个函数。</p><pre><code class="language-plain">// 判断字符串s 是否包含substr 字符串
func Contains(s, substr string) bool
// 判断字符串s 是否包含chars 字符串中的任一字符
func ContainsAny(s, chars string) bool
// 判断字符串s 是否包含符文数r
func ContainsRune(s string, r rune) bool
// 将字符串s 以空白字符分割，返回一个切片
func Fields(s string) []string
// 将字符串s 以满足f(r)==true 的字符分割，返回一个切片
func FieldsFunc(s string, f func(rune) bool) []string
// 将字符串s 以sep 为分隔符进行分割，分割后字符末尾去掉sep
func Split(s, sep string) []string
</code></pre><p>在标准库strconv包中，还包含很多字符串与其他类型进行转换的函数：</p><pre><code class="language-plain">// 字符串转换为十进制整数
func Atoi(s string) (int, error)
// 字符串转换为某一进制的整数，例如八进制、十六进制
func ParseInt(s string, base int, bitSize int) (i int64, err error)
// 整数转换为字符串
func Itoa(i int) string
// 某一进制的整数转换为字符串，例如八进制整数转换为字符串
func FormatInt(i int64, base int) string
</code></pre><p>让我们用strings包实战一下。</p><p>在HTML文本中，超链接一般放置在 <code>&lt;a&gt;</code> 标签中，因此，统计 <code>&lt;a&gt;</code> 标签的数量就能大致了解当前页面中链接的总数：</p><pre><code class="language-plain">// tag v0.0.3
func main() {
	url := "https://www.thepaper.cn/"
	resp, err := http.Get(url)

	if err != nil {
		fmt.Println("fetch url error:%v", err)
		return
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		fmt.Printf("Error status code:%v", resp.StatusCode)
	}

	body, err := ioutil.ReadAll(resp.Body)

	if err != nil {
		fmt.Println("read content failed:%v", err)
		return
	}

	numLinks := strings.Count(string(body), "&lt;a")
	fmt.Printf("homepage has %d links!\n", numLinks)

}
</code></pre><p>运行上面这段代码，输出的结果显示有300余个链接。</p><pre><code class="language-plain">homepage has 303 links!
</code></pre><p>strings包中另一个有用的函数是 <code>Contains</code>。如果你想了解当前首页是否存在疫情相关的新闻，可以使用下面这段代码：</p><pre><code class="language-plain">	...
	exist := strings.Contains(string(body), "疫情")
	fmt.Printf("是否存在疫情:%v\n", exist)
</code></pre><p>我们知道，字符串的本质其实是字节数组，bytes标准库提供的API具有和strings库类似的功能，你可以直接查看<a href="https://pkg.go.dev/bytes">标准库的文档</a>。</p><pre><code class="language-plain">func Compare(a, b []byte) int
func Contains(b, subslice []byte) bool
func Count(s, sep []byte) int
func Index(s, sep []byte) int
...
</code></pre><p>下面这段使用bytes标准库的代码和上面使用strings库的代码在功能上是等价的：</p><pre><code class="language-plain">numLinks := bytes.Count(body, []byte("&lt;a"))
fmt.Printf("homepage has %d links!\n", numLinks)

exist := bytes.Contains(body, []byte("疫情"))
fmt.Printf("是否存在疫情:%v\n", exist)
</code></pre><h3>字符编码</h3><p>服务器在网络中将HTML文本以二进制的形式传输到客户端。在之前的例子中，ioutil.ReadAll函数得到的结果是字节数组，我们将它强制转换为了人类可读的字符串。在Go语言中，字符串是默认通过UTF-8的形式编码的。</p><p>虽然目前大多数网站都使用UTF-8编码，但其实服务器发送过来的HTML文本可能拥有很多编码形式，例如ASCII、GB2312、UTF-8、UTF-16。一些国内的网站就会采用GB2312的编码方式。不过，如果编码的形式与解码的形式不同，可能会出现乱码的情况。</p><p><img src="https://static001.geekbang.org/resource/image/d4/fc/d44590a784edb522426676402e6d45fc.png?wh=1920x328" alt="图片"></p><p>为了让请求网页的功能具备通用性，我们需要考虑编码问题。在这之前，我们要先将请求网页的功能用Fetch函数封装起来，用函数给一连串的复合操作定义一个名字，将其作为一个操作单元，实现代码的复用和功能抽象。要实现编码的通用性，我们使用官方处理字符集的库：</p><pre><code class="language-plain">go get golang.org/x/net/html/charset
go get golang.org/x/text/encoding
</code></pre><p>Fetch函数的代码如下所示，其获取网页的内容，检测网页的字符编码并将文本统一转换为UTF-8格式。</p><pre><code class="language-plain">// tag v0.0.4
func Fetch(url string) ([]byte, error) {

	resp, err := http.Get(url)

	if err != nil {
		panic(err)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		fmt.Printf("Error status code:%d", resp.StatusCode)
	}
	bodyReader := bufio.NewReader(resp.Body)
	e := DeterminEncoding(bodyReader)
	utf8Reader := transform.NewReader(bodyReader, e.NewDecoder())
	return ioutil.ReadAll(utf8Reader)
}

func DeterminEncoding(r *bufio.Reader) encoding.Encoding {

	bytes, err := r.Peek(1024)

	if err != nil {
		fmt.Println("fetch error:%v", err)
		return unicode.UTF8
	}

	e, _, _ := charset.DetermineEncoding(bytes, "")
	return e
}
</code></pre><p>在这里，我们单独封装了DeterminEncoding函数来检测并返回当前HTML文本的编码格式。如果返回的HTML文本小于1024字节，我们认为当前HTML文本有问题，直接返回默认的UTF-8编码就好了。DeterminEncoding中核心的charset.DetermineEncoding函数用于检测并返回对应HTML文本的编码。关于charset.DetermineEncoding函数检测字符编码的算法，感兴趣的同学可以查看<a href="https://html.spec.whatwg.org/multipage/parsing.html#determining-the-character-encoding">这篇文章</a>。</p><p>最后，transform.NewReader 用于将HTML文本从特定编码转换为UTF-8编码，从而方便后续的处理。</p><p>不过呢，strings、bytes标准库里对字符串的处理都是比较常规的，有时候我们需要对文本进行更复杂的处理。例如，想爬取一个图书网站不同图书对应的作者、出版社、页数、定价等信息，这些信息都包含在HTML特殊的标签结构中，并且不同书籍对应的这些信息都不太一样。</p><p>要实现这种灵活的功能，利用strings、bytes标准库都是很难做到的。这就要用到一个更强大的文本处理方法了：正则表达式。</p><h2>正则表达式</h2><p><strong>正则表达式是一种描述文本内容组成规律的表示方式，它可以描述或者匹配符合相应规则的字符串。</strong>在文本编辑器、命令行工具、高级程序语言中，正则表达式被广泛地用来校验数据的有效性、搜索或替换特定模式的字符串。</p><p>由于历史原因，正则表达式分为了两个流派，分别是 POSIX 流派和 PCRE 流派。其中，POSIX 流派有两个标准，分别是 BRE 标准和 ERE 标准。不同的流派和标准对应了不同的特性与工具，一些工具可能对标准做了相应的扩展。这就让一些没有系统学习过正则表达式的同学，对一些正则的使用和现象感到困惑了。</p><p>目前，Linux和Mac在原生集成GUN套件（例如grep命令）时，遵循了POSIX标准，并弱化了GNU BRE 和 GNU ERE之间的区别。</p><p><strong>GNU BRE 和 GNU ERE 的差别主要体现在一些语法字符是否需要转义上。</strong>如下所示，grep 属于GNU BRE标准，对于字符串"addf"，要想能够匹配字母d 重复1-3次的情形，需要对"{"进行转义：</p><pre><code class="language-plain">&gt; echo  "addf" | grep  'd\{1,3\}'
</code></pre><p>GNU ERE标准不需要对"{"进行转义。要使用GNU ERE标准，需要在 Linux 的 grep 中添加 -E 运行参数。</p><pre><code class="language-plain">&gt; echo  "addf" | grep -E 'd{1,3}'
</code></pre><p>另一种当前更加流行的流派或标准是PCRE。</p><p>PCRE标准是由perl这门语言衍生而来的，现阶段的大部分高级编程语言都使用了PCRE标准。在Go语言中，正则表达式标准库也是默认使用了PCRE标准，不过Go同时也支持POSIX标准。</p><p>要使用PCRE标准，可以在grep中添加-P 运行参数。如下所示。ERE标准不支持用 <code>\d</code> 表示数字，但是PCRE标准是支持的。</p><pre><code class="language-plain"># 使用 ERE 标准
&gt; echo  "11d23a" | grep -E '[[:digit:]]+' 

# 使用 PCRE 标准
&gt; echo  "11d23a" | grep -P '\d+'
</code></pre><p>除此之外，PCRE 标准还有一些强大的功能，你可以搜索“Perl regular expressions”或查看<a href="https://perldoc.perl.org/perlretut">这篇文档</a>。</p><p>在这里，让我们用正则表达式实战获取一下澎湃新闻首页卡片中的新闻。</p><p><img src="https://static001.geekbang.org/resource/image/1e/37/1ec37cc7db001e68280e5bb322e26537.png?wh=1920x1407" alt="图片"></p><p>我们在之前已经通过v0.0.1中的代码获取到了首页的内容。现在让我们来看一看HTML中这些卡片在结构上的共性。下面是我列出的两个卡片的内容，我省去了一些不必要的内容。</p><pre><code class="language-plain">    &lt;div class="news_li" id="cont19144401" contType="0"&gt;
        ...
        &lt;h2&gt;
            &lt;a href="newsDetail_forward_19144401" id="clk19144401" target="_blank"&gt;在养老院停止探视的日子里，父亲不认识我了&lt;/a&gt;
        &lt;/h2&gt;
        ...
	&lt;/div&gt;

    &lt;div class="news_li" id="cont19145751" contType="0"&gt;
        ...
        &lt;h2&gt;
            &lt;a href="newsDetail_forward_19145751" id="clk19145751" target="_blank"&gt;美国考虑向乌克兰提供战斗机，美参与俄乌冲突程度或将扩大&lt;/a&gt;
        &lt;/h2&gt;
        ...
	&lt;/div&gt;

</code></pre><p>可以看到，文章的标题位于 <code>&lt;a&gt;</code> 标签中，可以跳转。外部包裹了 <code>&lt;h2&gt;</code> 标签以及属性class为news_li的 <code>&lt;div&gt;</code> 标签。知道这些信息后，我们就可以用正则表达式来获取卡片新闻中的标题了：</p><pre><code class="language-plain">// tag v0.0.5
var headerRe = regexp.MustCompile(`&lt;div class="news_li"[\s\S]*?&lt;h2&gt;[\s\S]*?&lt;a.*?target="_blank"&gt;([\s\S]*?)&lt;/a&gt;`)

func main() {
	url := "https://www.thepaper.cn/"
	body, err := Fetch(url)

	if err != nil {
		fmt.Println("read content failed:%v", err)
		return
	}
	matches := headerRe.FindAllSubmatch(body, -1)
	for _, m := range matches {
		fmt.Println("fetch card news:", string(m[1]))
	}
}
</code></pre><p>借助 regexp 标准库，regexp.MustCompile函数会在编译时提前解析好PCRE标准的正则表达式内容，这可以在一定程度上加速程序的运行。headerRe.FindAllSubmatch 则可以查找满足正则表达式条件的所有字符串。</p><p>接下来让我们分析一下这串正则表达式：</p><pre><code class="language-plain">&lt;div class="news_li"[\s\S]*?&lt;h2&gt;[\s\S]*?&lt;a.*?target="_blank"&gt;([\s\S]*?)&lt;/a&gt;
</code></pre><p>在这个规则中，我们要找到以字符串 <code>&lt;div class="news_li"</code> 开头，且内部包含 <code>&lt;h2&gt;</code> 和 <code>&lt;a.*?target="_blank"&gt;</code> 的字符串。其中，<code>[\s\S]*?</code> 是这段表达式的精髓，<code>[\s\S]</code> 指代的是任意字符串。</p><p>有些同学可能会好奇，为什么不使用 <code>.</code> 通配符呢? 原因在于，<code>.</code>通配符无法匹配换行符，而HTML文本中会经常出现换行符。<code>*</code> 代表将前面任意字符匹配0次或者无数次。<code>？</code>代表非贪婪匹配，这意味着我们的正则表达式引擎只要找到第一次出现 <code>&lt;h2&gt;</code> 标签的地方，就认定匹配成功。如果不指定 <code>？</code>，贪婪匹配会一路查找，直到找到最后一个 <code>&lt;h2&gt;</code> 标签为止，这当然不是我们想要的结果。</p><p>在 <code>&lt;a&gt;</code> 标签中，我们加了一个括号 <code>()</code>，这是用来分组的，因为当我们用正则完整匹配到这一串字符串后，希望将括号中对应的字符串提取出来。</p><p>headerRe.FindAllSubmatch 是一个三维字节数组 <code>[][][]byte</code>。它的第一层包含的是所有满足正则条件的字符串。第二层对每一个满足条件的字符串做了分组。其中，数组的第0号元素是满足当前正则表达式的这一串完整的字符串。而第1号元素代表括号中特定的字符串，在我们这个例子中对应的是 <code>&lt;a&gt;</code> 标签括号中的文字，即新闻标题。第三层就是字符串实际对应的字节数组。</p><p>运行代码，会打印出首页卡片中所有的新闻（注意，新闻内容在随时变化）：</p><pre><code class="language-plain">fetch card news: C919六架试飞机完成全部试飞任务，取证工作正式进入收官阶段
fetch card news: 上海高考本科各批次录取控制分数线公布，本科控分线400分
fetch card news: 甘肃一煤矿企业发生山体坍塌事故：已致3死13伤，1人失联
fetch card news: 澎湃八周年探索未停歇：2022外滩新媒体峰会汇聚融合发展新动能
fetch card news: 央广网评20家单位拒收现金被罚：货币数字化不等于摒弃现金
...
</code></pre><p>正则表达式虽然灵活强大，但是也不是没有成本的。正如一句老话说的那样：</p><blockquote>
<p>如果你有一个问题，你想到可以用正则来解决，那么你就有两个问题了。</p>
</blockquote><blockquote>
<p>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</p>
</blockquote><p>为了解决一个复杂的问题，我们其实引入了正则表达式这个同样复杂的工具。另外，由于回溯的原因，复杂的正则表达式可能会比较消耗CPU资源。幸运的是，由于HTML是结构化的数据，我们有了一些更好的解决办法。让我们更进一步，来看看更加高效地查找HTML中数据的方式：<strong>XPath(XML Path Language.)。</strong></p><h2>Xpath</h2><p>XPath 定义了一种遍历 XML 文档中节点层次结构，并返回匹配元素的灵活方法。而XML是一种可扩展标记语言，是表示结构化信息的一种规范。例如，微软办公软件Words在2007之后的版本的底层数据就是通过XML文件描述的。HTML虽然不是严格意义的XML，但是它的结构和XML类似。</p><p>Go标准库没有提供对XPath的支持，但是<a href="https://github.com/antchfx/htmlquery">第三方库</a>提供了在HTML中通过XPath匹配XML节点的引擎。我们之前获取卡片新闻的代码可以用 <a href="http://github.com/antchfx/htmlquery">htmlquery</a> 改写成下面的样子：</p><pre><code class="language-plain">// tag v0.0.6
func main() {
	url := "https://www.thepaper.cn/"
	body, err := Fetch(url)

	if err != nil {
		fmt.Println("read content failed:%v", err)
		return
	}
	doc, err := htmlquery.Parse(bytes.NewReader(body))
	if err != nil {
		fmt.Println("htmlquery.Parse failed:%v", err)
	}
	nodes := htmlquery.Find(doc, `//div[@class="news_li"]/h2/a[@target="_blank"]`)

	for _, node := range nodes {
		fmt.Println("fetch card ", node.FirstChild.Data)
	}
}
</code></pre><p>其中，htmlquery.Parse用于解析HTML文本，htmlquery.Find则会通过XPath语法查找符合条件的节点。在这个例子中，XPath规则为：</p><pre><code class="language-plain">//div[@class="news_li"]/h2/a[@target="_blank"]
</code></pre><p>这串规则代表查找target属性为_blank的a标签，并且a节点的父节点为h2标签，h2标签的父节点为 class属性为news_li的div标签。</p><p>和正则表达式相比，结构化查询语言XPath的语法更加简洁明了，检索字符串变得更容易了。但是XPath并不是专门为HTML设计的，接下来我们再介绍一下专门为HTML设计，使用更广泛，更简单的CSS选择器。</p><h2>CSS选择器</h2><p>CSS（层叠式样式表）是一种定义HTML 文档中元素样式的语言。在 CSS 文件中，我们可以定义一个或多个HTML中的标签的路径，并指定这些标签的样式。在CSS中，定义标签路径的方法被称为CSS选择器。</p><p>CSS 选择器考虑到了我们在搜索 HTML 文档时常用的属性。我们前面在XPath例子的中使用的 div[@class=“news_li”]，在CSS选择器中可以简单地表示为 div.news_li。这是一种更加简单的表示方法。关于CSS选择器的语法可以查看<a href="https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Selectors">这篇文章</a>。</p><p>官方标准库中并不支持CSS选择器，我们在这里使用社区中知名的第三方库(<code>github.com/PuerkitoBio/goquery</code> )，获取卡片新闻的代码如下：</p><pre><code class="language-plain">// tag v0.0.9
func main() {
	url := "https://www.thepaper.cn/"
	body, err := Fetch(url)

	if err != nil {
		fmt.Println("read content failed:%v", err)
		return
	}

	// 加载HTML文档
	doc, err := goquery.NewDocumentFromReader(bytes.NewReader(body))
	if err != nil {
		fmt.Println("read content failed:%v", err)
	}

	doc.Find("div.news_li h2 a[target=_blank]").Each(func(i int, s *goquery.Selection) {
		// 获取匹配标签中的文本
		title := s.Text()
		fmt.Printf("Review %d: %s\n", i, title)
	})
}
</code></pre><p>这里，goquery.NewDocumentFromReader 用于加载HTML文档，doc.Find可以根据CSS标签选择器的语法查找匹配的标签，并遍历打印出a标签中的文本。</p><h2></h2><h2>总结</h2><p>好了，这节课就讲到这里。</p><p>这节课，我们借助一个简单的新闻网站，讲解了如何应对网页的不同编码问题，我们还了解了HTML文本的多种处理方式。HTML文本的处理可以借助标准库的strings、strconv、bytes等库，也可以借助更通用更强大的正则表达式。</p><p>不过，由于正则表达式通常比较复杂而且性能低下，在实际运用过程中，我们一般采用XPath与CSS选择器进行结构化查询。比较这两种查询方法，会发现XPath是为XML文档设计的，而CSS选择器是为HTML文档专门设计的，更加简单，也更主流。我们在后面的课程中还将灵活使用各种技术来查找指定的字符串。</p><h2>课后题</h2><p>最后，我也给你留一道思考题。</p><p>在类似如下的日志文件中，包含了很多订单号的信息，即order_id后面的一串数字。</p><pre><code class="language-plain">2022-11-22  name=versionReport||order_id=3732978217343693673||trace_id=XXX
2022-11-22  name=versionReport||order_id=3732978217343693674||trace_id=XXX
</code></pre><p>我们可以用什么方式，将order_id后面的订单ID都像下面这样打印出来？（提示：用grep就可以做到）</p><pre><code class="language-plain">3732978217343693673
3732978217343693674
</code></pre><p>欢迎你在留言区与我交流讨论，我们下节课再见！</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>0mfg</span>
  </div>
  <div class="_2_QraFYR_0">澎湃新闻首页应该是改版了，原来的例子抓不到内容，按照老师的思路抓到现在推荐卡片里的新闻标题，交作业了<br>package main<br><br>import (<br>	&quot;bufio&quot;<br>	&quot;fmt&quot;<br>	&quot;io&#47;ioutil&quot;<br>	&quot;net&#47;http&quot;<br>	&quot;regexp&quot;<br><br>	&quot;golang.org&#47;x&#47;net&#47;html&#47;charset&quot;<br>	&quot;golang.org&#47;x&#47;text&#47;encoding&quot;<br>	&quot;golang.org&#47;x&#47;text&#47;encoding&#47;unicode&quot;<br>	&quot;golang.org&#47;x&#47;text&#47;transform&quot;<br>)<br>var headerRe = regexp.MustCompile(`&lt;div class=&quot;small_cardcontent__BTALp&quot;[\s\S]*?&lt;h2&gt;([\s\S]*?)&lt;&#47;h2&gt;`)<br><br>func main() {<br>	url := &quot;https:&#47;&#47;www.thepaper.cn&#47;&quot;<br><br>	pageBytes, err:= Fetch(url)<br><br>	if err!= nil {<br>		fmt.Printf(&quot;read content failed %v&quot;, err)<br>		return<br>	}<br><br>	matches := headerRe.FindAllSubmatch(pageBytes, -1)<br><br>	for _, m := range matches {<br>		fmt.Println(&quot;fetch card news:&quot;, string(m[1]))<br>	}<br>}<br><br>func Fetch(url string) ([]byte, error) {<br>	resp, err := http.Get(url)<br>	if err != nil {<br>		panic(err)<br>	}<br>	defer resp.Body.Close()<br><br>	if resp.StatusCode != http.StatusOK {<br>		fmt.Printf(&quot;Error status code: %v&quot;, resp.StatusCode)<br>	}<br>	bodyReader := bufio.NewReader(resp.Body)<br>	e := DerterminEncoding(bodyReader)   &#47;&#47;utf-8<br>	utf8Reader := transform.NewReader(bodyReader, e.NewDecoder())<br>	return ioutil.ReadAll(utf8Reader)<br>}<br><br>func DerterminEncoding(r *bufio.Reader) encoding.Encoding {<br>	bytes, err := r.Peek(1024)<br><br>	if err != nil {<br>		fmt.Printf(&quot;fetch error: %v&quot;, err)<br>		return unicode.UTF8<br>	}<br><br>	e, _, _ := charset.DetermineEncoding(bytes, &quot;&quot;)<br>	return  e<br>}<br><br>运行结果，fetch card news: 长二丁火箭70次发射发发成功，将171颗卫星送入预定轨道<br>fetch card news: 日本主帅森保一道歉：对不起支持我们的球迷，全力备战西班牙<br>fetch card news: 豪宅数万“天价电费”何来？台湾地区电价调涨背后的能源困局<br>fetch card news: 因白俄罗斯外长马克伊去世，俄外长推迟访问白俄罗斯<br></div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: good<br></p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-27 22:33:35</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/75/00/618b20da.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>徐海浪</span>
  </div>
  <div class="_2_QraFYR_0">grep -oP &#39;order_id=\d+&#39;|grep -oP &#39;\d+&#39;</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: Good</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-22 15:10:46</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>0mfg</span>
  </div>
  <div class="_2_QraFYR_0">思考题，mac上通过grep -oE &#39;order_id=\d+&#39; | grep -oE &#39;\d+&#39;  可以提取orderid</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: good<br></p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-27 23:51:54</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>0mfg</span>
  </div>
  <div class="_2_QraFYR_0">勘误，“下面这段使用 bytes 标准库的代码和上面使用 strings 库的代码在功能上是等价的”，该处实例代码应该是这样吧<br>numLinks := bytes.Count(body, []byte(&quot;&lt;a&quot;))<br>fmt.Printf(&quot;homepage has %d links&quot;, numLinks)<br><br>exist := bytes.Contains(body, []byte(&quot;疫情&quot;))<br>fmt.Println(exist)</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-27 12:05:03</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/2b/28/22/ebc770dc.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>哈哈哈哈哈</span>
  </div>
  <div class="_2_QraFYR_0">项目代码放哪里了？之前留的找不着了</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: https:&#47;&#47;github.com&#47;dreamerjackson&#47;crawler,注意看文中指明的tag分支</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-26 22:57:18</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIlnTfD7ZMqT6vC6a7NCMySyrO5M2znWDFUYWrA3OeHmuNiaDjpcia4hutyauX74U9UqicT3IV2jo4ew/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Geek_d09597</span>
  </div>
  <div class="_2_QraFYR_0">更新之后的：<br><br>正则：var headerRe = regexp.MustCompile(`&lt;div class=&quot;small_cardcontent__BTALp&quot;[\s\S]*?&lt;h2&gt;([\s\S]*?)&lt;&#47;h2&gt;`)<br><br>Xpath: nodes := htmlquery.Find(doc, `&#47;&#47;div[@class=&quot;small_cardcontent__BTALp&quot;]&#47;&#47;h2`)<br><br>CSS选择器:  doc.Find(&quot;div.small_cardcontent__BTALp h2&quot;)<br></div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-17 21:34:08</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>0mfg</span>
  </div>
  <div class="_2_QraFYR_0">勘误， fmt.Println(&quot;fetch url error:%v&quot;, err)  应该为fmt.Printf(&quot;fetch url err:%v\n&quot;, err)吧</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，后面不用fmt.Println了，用log</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-27 10:56:17</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/ce/6d/0c15c18a.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>徐曙辉</span>
  </div>
  <div class="_2_QraFYR_0">第一反应是<br>arr := strings.Split(data,&quot;||&quot;)<br>fmtPrintln(arr[1][9:])<br></div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-22 09:12:41</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/0c/e1/f663213e.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>拾掇拾掇</span>
  </div>
  <div class="_2_QraFYR_0">wow，等到了代码阶段了。。。哈哈</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-22 08:02:24</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/27/ed/86/6923277b.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>烟消云散</span>
  </div>
  <div class="_2_QraFYR_0">目前，Linux 和 Mac 在原生集成 GUN 套件。应该是GNU吧</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-22 06:43:44</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/9d/a4/e481ae48.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>lesserror</span>
  </div>
  <div class="_2_QraFYR_0">老师，澎湃新闻的首页改版了，代码需要调整了。不然运行后没结果。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 哈哈，没啥的，交的是方法</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-28 13:37:14</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/13/9a/0a/6c74e932.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>光</span>
  </div>
  <div class="_2_QraFYR_0">问下最后这单个 return 含义是啥。<br>if err != nil {   <br> fmt.Println(&quot;fetch url error:%v&quot;, err)    <br> return  <br>}</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 指的是函数立即返回</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-25 16:10:02</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/17/55/e7/86ae89f0.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Jack</span>
  </div>
  <div class="_2_QraFYR_0">正则表达式可以安排起来了</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-11-22 09:43:16</div>
  </div>
</div>
</div>
</li>
</ul>