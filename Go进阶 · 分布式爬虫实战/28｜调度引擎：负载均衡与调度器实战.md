<audio title="28｜调度引擎：负载均衡与调度器实战" src="https://static001.geekbang.org/resource/audio/60/cb/60165a2606f0191cc80f23a4a8a2aacb.mp3" controls="controls"></audio> 
<p>你好，我是郑建勋。</p><p>在上一节课程中，我们实战了广度优先搜索算法，不过我们对网站的爬取都是在一个协程中进行的。在真实的实践场景中，我们常常需要爬取多个初始网站，我们希望能够同时爬取这些网站。这就需要合理调度和组织爬虫任务了。因此，这节课的重点就是实战任务调度的高并发模型，使资源得到充分的利用。</p><h2>实战调度引擎</h2><p>首先，我们新建一个文件夹engine用于存储调度引擎的代码，核心的调度逻辑位于ScheduleEngine.Run中。这部分的完整代码位于 <a href="https://github.com/dreamerjackson/crawler">tag v0.1.4</a>，你可以对照代码进行查看。</p><p>调度引擎主要目标是完成下面几个功能：</p><ol>
<li>创建调度程序，接收任务并将任务存储起来；</li>
<li>执行调度任务，通过一定的调度算法将任务调度到合适的worker中执行；</li>
<li>创建指定数量的worker，完成实际任务的处理；</li>
<li>创建数据处理协程，对爬取到的数据进行进一步处理。</li>
</ol><pre><code class="language-plain">func (s *ScheduleEngine) Run() {
	requestCh := make(chan *collect.Request)
	workerCh := make(chan *collect.Request)
	out := make(chan collect.ParseResult)
	s.requestCh = requestCh
	s.workerCh = workerCh
	s.out = out
	go s.Schedule()
}
</code></pre><!-- [[[read_end]]] --><p>Run方法首先初始化了三个通道。其中，requestCh负责接收请求，workerCh负责分配任务给worker，out负责处理爬取后的数据，完成下一步的存储操作。schedule函数会创建调度程序，负责的是调度的核心逻辑。</p><p>第一步我们来看看schedule函数如何接收任务并完成任务的调度。</p><p>schedule函数如下所示，其中，requestCh通道接收来自外界的请求，并将请求存储到reqQueue队列中。workerCh通道负责传送任务，后面每一个worker将获取该通道的内容，并执行对应的操作。</p><p>在这里，我们使用了for语句，让调度器循环往复地获取外界的爬虫任务，并将任务分发到worker中。如果任务队列reqQueue大于0，意味着有爬虫任务，这时我们获取队列中第一个任务，并将其剔除出队列。最后ch &lt;- req 会将任务发送到workerCh通道中，等待worker接收。</p><pre><code class="language-plain">func (s *Schedule) Schedule() {
	var reqQueue = s.Seeds
	go func() {
		for {
			var req *collect.Request
			var ch chan *collect.Request

			if len(reqQueue) &gt; 0 {
				req = reqQueue[0]
				reqQueue = reqQueue[1:]
				ch = s.workerCh
			}
			select {
			case r := &lt;-s.requestCh:
				reqQueue = append(reqQueue, r)

			case ch &lt;- req:
			}
		}
	}()
}
</code></pre><p>通道还有一个特性，就是我们往nil通道中写入数据会陷入到堵塞的状态。因此，如果reqQueue为空，这时req和ch都是nil，当前协程就会陷入到堵塞的状态，直到接收到新的请求才会被唤醒。</p><p>我们可以用一个例子来验证这一特性：</p><pre><code class="language-plain">func main() {
	var ch chan *int
	go func() {
		&lt;-ch
	}()
	select {
	case ch &lt;- nil:
		fmt.Println("it's time")
	}
}
</code></pre><p>在这个例子中，运行后会出现死锁，因为当前程序全部陷入到了无限堵塞的状态。</p><pre><code class="language-plain">fatal error: all goroutines are asleep - deadlock!
</code></pre><p>调度引擎除了启动schedule函数，还需要安排多个实际干活的worker程序。</p><p>下一步，让我们创建指定数量的worker，完成实际任务的处理。其中WorkCount为执行任务的数量，可以灵活地去配置。</p><pre><code class="language-plain">func (s *ScheduleEngine) Run() {
	...
	go s.Schedule()
	for i := 0; i &lt; s.WorkCount; i++ {
		go s.CreateWork()
	}
}
</code></pre><p>这里的 CreateWork 创建出实际处理任务的函数，它又细分为下面几个步骤：</p><ul>
<li>←s.workerCh接收到调度器分配的任务；</li>
<li>s.fetcher.Get 访问服务器，r.ParseFunc 解析服务器返回的数据；</li>
<li>s.out ← result 将返回的数据发送到out通道中，方便后续的处理。</li>
</ul><pre><code class="language-plain">func (s *Schedule) CreateWork() {
	for {
		r := &lt;-s.workerCh
		body, err := s.Fetcher.Get(r)
		if err != nil {
			s.Logger.Error("can't fetch ",
				zap.Error(err),
			)
			continue
		}
		result := r.ParseFunc(body, r)
		s.out &lt;- result
	}
}
</code></pre><p>最后一步，我们需要单独安排一个函数来处理爬取并解析后的数据结构，完整的函数如下：</p><pre><code class="language-plain">func (s *Schedule) HandleResult() {
	for {
		select {
		case result := &lt;-s.out:
			for _, req := range result.Requesrts {
				s.requestCh &lt;- req
			}
			for _, item := range result.Items {
				// todo: store
				s.Logger.Sugar().Info("get result", item)
			}
		}
	}
}
</code></pre><p>在HandleResult函数中，&lt;-s.out接收所有worker解析后的数据，其中要进一步爬取的Requests列表将全部发送回s.requestCh通道，而result.Items里包含了我们实际希望得到的结果，所以我们先用日志把结果打印出来。</p><p>最后，让我们用之前介绍的爬取豆瓣小组的例子来验证调度器的功能。</p><p>在main函数中，生成初始网址列表作为种子任务。构建engine.Schedule，设置worker的数量，采集器Fetcher和日志Logger，并调用s.Run()运行调度器。</p><pre><code class="language-plain"> func main(){
		var seeds []*collect.Request
		for i := 0; i &lt;= 0; i += 25 {
			str := fmt.Sprintf("&lt;https://www.douban.com/group/szsh/discussion?start=%d&gt;", i)
			seeds = append(seeds, &amp;collect.Request{
				Url:       str,
				WaitTime:  1 * time.Second,
				Cookie:    "xxx",
				ParseFunc: doubangroup.ParseURL,
			})
		}
	
		var f collect.Fetcher = &amp;collect.BrowserFetch{
			Timeout: 3000 * time.Millisecond,
			Logger:  logger,
			Proxy:   p,
		}
	
		s := engine.Schedule{
			WorkCount: 5,
			Logger:    logger,
			Fetcher:   f,
			Seeds:     seeds,
		}
		s.Run()
}

</code></pre><p>输出结果为：</p><pre><code class="language-plain">{"level":"INFO","ts":"2022-10-19T00:55:54.281+0800","caller":"engine/schedule.go:78","msg":"get result: &lt;https://www.douban.com/group/topic/276978032/&gt;"}
{"level":"INFO","ts":"2022-10-19T00:55:54.355+0800","caller":"engine/schedule.go:78","msg":"get result: &lt;https://www.douban.com/group/topic/276973871/&gt;"}
</code></pre><h2>函数式选项模式</h2><p>在上面的例子中，我们初始化engine.Schedule时将一系列的参数传递到了结构体当中。在实践中可能会有几十个参数等着我们赋值，从面向对象的角度来看，不同参数的灵活组合可能会带来不同的调度器类型。在实践中为了方便使用，开发者可能会创建非常多的 API 来满足不同场景的需要，如下所示：</p><pre><code class="language-plain">// 基本调度器
func NewBaseSchedule() *Schedule {
	return &amp;Schedule{
		WorkCount: 1,
		Fetcher：baseFetch,
	}
}
// 多worker调度器
func NewMultiWorkSchedule(workCount int) *Schedule {
	return &amp;Schedule{
		WorkCount: workCount,
		Fetcher：baseFetch,
	}
}

// 代理调度器
func NewProxySchedule(proxy string) *Schedule {
	return &amp;Schedule{
		WorkCount: 1,
		Fetcher：proxyFetch(proxy),
	}
}
</code></pre><p>随着参数的不断增多，这种API会变得越来越多，这就增加了开发者的心理负担。</p><p>另一种使用方式就是传递一个统一的Config配置结构，如下所示。这种方式只需要创建单个API，但是需要在内部对所有的变量进行判断，繁琐且不优雅。对于使用者来说，也很难确定自己需要使用哪一个字段。</p><pre><code class="language-plain">type Config struct {
	WorkCount int
	Fetcher   collect.Fetcher
	Logger    *zap.Logger
	Seeds     []*collect.Request
}

func NewSchedule(c *Config) *Schedule {
	var s = &amp;Schedule{}
	if c.Seeds != nil {
		s.Seeds = c.Seeds
	}
	if c.Fetcher != nil {
		s.Fetcher = c.Fetcher
	}

	if c.Logger != nil {
		s.Logger = c.Logger
	}
	...
	return s
}
</code></pre><p>那么有没有方法可以更加优雅地处理这种多参数配置问题呢？</p><p>Rob Pike 在2014年的<a href="https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html">一篇博客中</a>提到了一种优雅的处理方法叫做<strong>函数式选项模式(Functional Options)。</strong>这种模式展示了闭包函数的有趣用途，目前在很多开源库中都能看到它的身影，我们项目中使用的日志库 Zap 也使用了这种模式。下面我以上面schedule的配置为例来说明函数式选项模式（完整代码请查看<a href="https://github.com/dreamerjackson/crawler">tag v0.1.5</a>）。</p><p><strong>第一步，</strong>我们要对schedule结构进行改造，把可以配置的参数放入到<code>options</code> 结构中：</p><pre><code class="language-plain">type Schedule struct {
	requestCh chan *collect.Request
	workerCh  chan *collect.Request
	out       chan collect.ParseResult
	options
}

type options struct {
	WorkCount int
	Fetcher   collect.Fetcher
	Logger    *zap.Logger
	Seeds     []*collect.Request
}
</code></pre><p><strong>第二步，</strong>我们需要书写一系列的闭包函数，这些函数的返回值是一个参数为 <code>options</code> 的函数：</p><pre><code class="language-plain">
type Option func(opts *options)

func WithLogger(logger *zap.Logger) Option {
	return func(opts *options) {
		opts.Logger = logger
	}
}
func WithFetcher(fetcher collect.Fetcher) Option {
	return func(opts *options) {
		opts.Fetcher = fetcher
	}
}

func WithWorkCount(workCount int) Option {
	return func(opts *options) {
		opts.WorkCount = workCount
	}
}

func WithSeeds(seed []*collect.Request) Option {
	return func(opts *options) {
		opts.Seeds = seed
	}
}
</code></pre><p><strong>第三步，</strong>创建一个生成schedule的新函数，函数参数为Option的可变参数列表。defaultOptions为默认的Option，代表默认的参数列表，然后循环遍历可变函数参数列表并执行。</p><pre><code class="language-plain">func NewSchedule(opts ...Option) *Schedule {
	options := defaultOptions
	for _, opt := range opts {
		opt(&amp;options)
	}
	s := &amp;Schedule{}
	s.options = options
	return s
}
</code></pre><p><strong>第四步，</strong>在main函数中调用NewSchedule。让我们来看看函数式选项模式的效果：</p><pre><code class="language-plain">func main(){
	s := engine.NewSchedule(
			engine.WithFetcher(f),
			engine.WithLogger(logger),
			engine.WithWorkCount(5),
			engine.WithSeeds(seeds),
		)
	s.Run()
}
</code></pre><p>从这个例子中，我们可以看到函数式选项模式的好处：</p><ul>
<li>API 具有可扩展性，高度可配置化，新增参数不会破坏现有代码；</li>
<li>参数列表非常简洁，并且可以使用默认的参数；</li>
<li>option函数使参数的含义非常清晰，易于开发者理解和使用；</li>
<li>如果将 options 结构中的参数设置为小写，还可以限制这些参数的权限，防止这些参数在package 外部使用。</li>
</ul><p>刚才，我们实战了 fan-in 和 fan-out 高并发模型，并深度使用了通道和select的机制。接下来让我们更进一步，看一下实现通道和select机制的原理，掌握这种高并发模型的底层图像。</p><h2>通道的底层原理</h2><p>通道的实现并没有想象中复杂。它利用互斥锁实现了并发安全，只不过Go运行时为我们屏蔽了底层的细节。<strong>通道包括两种类型，一种是无缓冲的通道，另一种是带缓冲区的通道。</strong>通道的结构如下：</p><p><img src="https://static001.geekbang.org/resource/image/1d/2d/1d3df16f6b81e75537442a0a226de12d.jpg?wh=1920x1743" alt="图片"></p><p>可以看到，通道中包含了数据的类型、大小、数量，堵塞协程队列，以及用于缓存区的诸多字段。</p><p>我们先来看看无缓冲区的通道是怎么实现的。</p><h3>无缓冲区的通道</h3><p>通道需要有多个协程分别完成读和写的功能，这样才能保证数据传输是顺畅的。对于无缓冲区的通道来说，如果有一个协程正在将数据写入通道，但是当前没有协程读取数据，那么写入协程将立即陷入到休眠状态。写入协程堵塞之前协程会被封装到sudog结构中，并存储到写入的堵塞队列sendq中，之后协程陷入休眠。</p><p>之前我们介绍过，协程的堵塞是位于用户态的，协程切换时，运行时会保存当前协程的状态、并调用 <code>gopark</code> 函数切换到g0完成新一轮的调度。如果之后有协程读取数据，那么读取协程会立即读取sendq队列中第一个等待的协程，并将该协程对应的元素拷贝到读取协程中，同时调用 <code>goready</code> 唤醒写入协程，将写入协程放入到可运行队列中等待被调度器调度。</p><p><img src="https://static001.geekbang.org/resource/image/95/df/951ea2060624460486cd7c19yy2c52df.jpg?wh=1920x1242" alt="图片"></p><h3>带缓冲区的通道</h3><p>而对于带缓冲区的通道来说，假设缓存队列的数量为N，那么如果写入的数据量不大于N，写入协程就不会陷入到休眠状态，所有数据都会存储在缓冲队列中。</p><p>缓冲队列可以在一定程度上削峰填谷，加快处理速度。但是如果写入速度始终大于读取数据，那么缓冲区迟早也有写满的时候，到时候仍然会陷入堵塞，只是延迟了问题的暴露并带来内存的浪费。因此缓冲区的容量不可以过大，我们可以根据实际情况给出一个经验值。例如上面的爬虫案例中，我们就可以给接收任务的requestCh通道加上缓存区，先将缓存区设置为500，这样就不会频繁堵塞住调度器了。</p><p>对于有缓存的通道，存储在 buf 中的数据虽然是线性的数组，但是这些数组和序号recvx、recvq 模拟了一个环形队列。recvx 可以定位到 buf 是从哪个位置读取的通道中的元素，而 sendx 则能够找到写入时放入 buf 的位置，这样做主要是为了再次利用已经使用过的空间。从 recvx 到 sendx 的距离qcount就是通道队列中的元素数量。</p><p><img src="https://static001.geekbang.org/resource/image/44/c9/44d5ac405f5997b198747c6b6acaacc9.jpg?wh=1920x1013" alt="图片"></p><h2>Select 机制的底层原理</h2><p>在前面的实战案例中，我们还看到了大量channel与select结合使用的场景。</p><p>受到通道特性的限制，如果单个通道被堵塞，协程就无法继续执行了。那有没有一种机制可以像网络中的多路复用一样，监听多个通道，使后续处理协程能够及时地运行？</p><p>其实就和网络中把select用于Socket的多路复用机制一样，Go中也可以用select语句实现这样的多路复用机制。select语句中的每一个case都对应着一个待处理的读取或写入通道。举个简单实用的例子，下面的程序如果800毫秒之后也接受不到通道c中的数据，定时器time.After就会接收到数据，从而打印timeout。</p><pre><code class="language-plain">select {
	case &lt;-c:
		fmt.Println("random 01")
	case &lt;-time.After(800 * time.Millisecond):
		fmt.Println("timeout")
	}
</code></pre><p>借助select可以实现许多有表现力的设计，那select是如何工作的呢？</p><p>Select底层调用了 <code>selectgo</code> 函数，它的工作可以分为三个部分：</p><ul>
<li>第一部分涉及到遍历。<code>selectgo</code> 首先循环查找当前准备就绪的通道，如果能够找到，则正常进行后续处理。在具体的实现方式上，由于 select内部的 <code>scases</code> 数组存储了所有需要管理的通道，所以很容易想到循环遍历 <code>scases</code> ，最终找到可用的通道。不过这可能导致一个问题，那就是如果前面的通道始终有数据，后面的通道将永远得不到执行的机会。为了解决这一问题，Go语言为select加入了随机性，会利用洗牌算法随机打散数组顺序，保证了所有通道都有执行的机会。</li>
<li>第二部分涉及到协程的休眠。如果select找不到准备就绪的通道，这时和单个协程的堵塞一样，它会将当前协程放入到所有通道的等待队列中，并陷入到休眠状态。</li>
<li>第三部分涉及到协程的唤醒。如果有任意一个通道准备就绪，当前的协程将会被唤醒，并到准备就绪的case处继续执行。 要注意的一点是，最后 <code>selectgo</code> 会将sudog结构体从其他通道的等待队列中移出，因为当前协程已经能够正常运行，不再需要被其他通道唤醒了。</li>
</ul><h2>总结</h2><p>这节课，我们用fan-in、fan-out并发模式实战了爬虫的任务调度器。在实战中，我们频繁使用了通道与select结合的方式，还深入底层看到了通道与select的原理。最后我们还学习了函数选项模式在构建API时的优势。在后面的项目中，我们还会频繁地用到这种特性。</p><h2>课后题</h2><p>在我们的课程中，schedule函数其实有一个bug，您能看出来吗？你觉得可以用什么方式找出这样的Bug？</p><p>欢迎你在留言区与我交流讨论，我们下节课见！</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83ep075ibtmxMf3eOYlBJ96CE9TEelLUwePaLqp8M75gWHEcM3za0voylA0oe9y3NiaboPB891rypRt7w/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>shuff1e</span>
  </div>
  <div class="_2_QraFYR_0">bug应该是，会丢失发给worker的任务。<br><br>case r := &lt;-s.requestCh:的情况下，如果req不是nil，应该把req再添加到reqQueue头部</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，后面有修复</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-15 08:54:16</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Realm</span>
  </div>
  <div class="_2_QraFYR_0">                          <br>                       Seeds<br>                           |<br>                           |              req                     ParseFunc(req)      HandleResult()<br>requestCh----&gt; reqQueue -----&gt; workerCh ----------&gt; out-----------&gt; result:<br>^                                                                                                                - item ==&gt; 存储<br>|                                                                                                                 - req |<br>|---------------&lt;----------------------&lt;---------------------&lt;------|</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-13 21:10:31</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI8qibAw4lRCic1pbnA6yzQU3UqtQm3NqV1bUJ5EiaUnJ24V1yf4rtY7n2Wx7ZVvTemqq5a61ERWrrHA/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Alex</span>
  </div>
  <div class="_2_QraFYR_0">有个小问题请教一下老师， 这个Seeds 是slice， 我觉得在取出任务的时候会有并发问题 如果没有请老师指教下 </div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 目前只有初始化会写，运行时都是读，所以不会有并发问题。  随着课程的深入，运行时可以添加资源，到时会有并发冲突的考虑</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-12 03:36:55</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/54/21/8c13a2b4.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>周龙亭</span>
  </div>
  <div class="_2_QraFYR_0">func (s *Schedule) Schedule() {<br>	var reqQueue = s.Seeds<br>	go func() {<br>		for {<br>			var req *collect.Request<br>			var ch chan *collect.Request<br><br>			if len(reqQueue) &gt; 0 {<br>				req = reqQueue[0]<br>				ch = s.workerCh<br>			}<br>			select {<br>			case r := &lt;-s.requestCh:<br>				reqQueue = append(reqQueue, r)<br><br>			case ch &lt;- req:<br>				reqQueue = reqQueue[1:]<br>			}<br>		}<br>	}()<br>}</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-25 22:29:13</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/54/21/8c13a2b4.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>周龙亭</span>
  </div>
  <div class="_2_QraFYR_0">修复下Schedule方法的bug：<br><br>func (s *Schedule) schedule() {<br>	go func() {<br>		for r := range s.requestCh {<br>			s.reqQueueCond.L.Lock()<br>			s.reqQueue = append(s.reqQueue, r)<br>			s.reqQueueCond.Signal()<br>			s.reqQueueCond.L.Unlock()<br>		}<br>	}()<br><br>	go func() {<br>		for {<br>			s.reqQueueCond.L.Lock()<br>			for len(s.reqQueue) == 0 {<br>				s.reqQueueCond.Wait()<br>			}<br><br>			var movedReqQueue = s.reqQueue<br>			s.reqQueue = nil<br><br>			s.reqQueueCond.L.Unlock()<br><br>			for _, r := range movedReqQueue {<br>				s.workerCh &lt;- r<br>			}<br>		}<br><br>	}()<br>}</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-25 22:13:13</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/15/32/fe/c2179924.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>mantra</span>
  </div>
  <div class="_2_QraFYR_0">本文档中的代码链接 tag v0.1.4 （之前的文档，也一样）对应的 URL 都是主库的地址（https:&#47;&#47;github.com&#47;dreamerjackson&#47;crawler），这是故意的吗？正确的应该是 https:&#47;&#47;github.com&#47;dreamerjackson&#47;crawler&#47;archive&#47;refs&#47;tags&#47;v0.1.4.tar.gz</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 我所有的项目链接都放置的主库的地址，tag的地址就稍微点击一下吧</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-13 13:01:26</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>7oty</span>
  </div>
  <div class="_2_QraFYR_0">如何控制某个爬虫任务的启动，停止和任务的实时运行状态？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 后面文章会有介绍</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-20 22:56:11</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/16/18/4f/9e4d5591.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>翡翠虎</span>
  </div>
  <div class="_2_QraFYR_0">如果任务推送到worker，但又还没实施，这时候那台服务器停机了，或者进程退出了，任务会不会丢？怎么处理任务还没执行就丢了的这种情况呢？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 随着课程深入会看到，我们的任务是存储在etcd中的，所以不会丢失</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-20 03:58:56</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Realm</span>
  </div>
  <div class="_2_QraFYR_0">```<br>func (s *ScheduleEngine) Schedule() {<br>	var reqQueue = s.Seeds<br>	go func() {<br>		for {<br>			var req *collect.Request<br>			&#47;&#47;var ch chan *collect.Request<br>			ch := make(chan *collect.Request)<br>```<br>使用make创建ch，这样ch就不是nil了，即使reqQueue为空的时候，case ch &lt;- req:就不是往nil通道中写数据了。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-14 11:00:03</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/62/8e/985cbc25.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>老猫</span>
  </div>
  <div class="_2_QraFYR_0">&#47;&#47; s.requestCh = make(chan *collect.Request,100)<br>&#47;&#47; s.workerCh = make(chan *collect.Request,500)<br>func (s *ScheduleEngine) Schedule() {<br>	var reqQueue = s.Seeds<br>	go func() {<br>		for _, req := range reqQueue {<br>			s.workerCh &lt;- req<br>		}<br>		for {<br>			select {<br>			case r := &lt;-s.requestCh:<br>				s.workerCh &lt;- r<br>			}<br>		}<br>	}()<br>}</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-13 23:28:06</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/0c/e1/f663213e.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>拾掇拾掇</span>
  </div>
  <div class="_2_QraFYR_0">开启go run 的datarace参数吗？</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-13 22:17:15</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src=""
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Geek_a9ea01</span>
  </div>
  <div class="_2_QraFYR_0">for { var req *collect.Request var ch chan *collect.Request if len(reqQueue) &gt; 0 { req = reqQueue[0] reqQueue = reqQueue[1:] ch = s.workerCh } select { case r := &lt;-s.requestCh: reqQueue = append(reqQueue, r) case ch &lt;- req: } }<br>有个问题：<br>如果ch堵塞了  这时候又有requestCh请求上来；会不会导致ch数据丢失？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 这个是已知的问题，我在后面的课程中做了修复</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-13 17:45:51</div>
  </div>
</div>
</div>
</li>
</ul>