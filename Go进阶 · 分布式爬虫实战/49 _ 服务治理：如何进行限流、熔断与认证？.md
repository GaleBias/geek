<audio title="49 _ 服务治理：如何进行限流、熔断与认证？" src="https://static001.geekbang.org/resource/audio/bd/1c/bd701ef0e0612f1ee4bd26370fac0d1c.mp3" controls="controls"></audio> 
<p>你好，我是郑建勋。</p><p>在之前我们已经完成了Master与Worker的核心功能。在大规模微服务集群中，为了保证微服务集群正常运行，还需要添加许多重要的功能，包括限流、熔断、认证与鉴权。这节课，就让我们来看看如何实现这些功能。</p><h2>限流</h2><p>限流指的是对给定时间内可能发生的事件的频率进行限制。一旦请求达到规定的上限，此后这段时间内的请求都将被丢弃。</p><p>限流对于公共 API 非常重要，它有下面几个优势。</p><ul>
<li>提高服务的可用性和可靠性，并有助于防御或缓解一些常见的攻击（DoS攻击、 DDoS攻击、暴力破解、撞库攻击、网页爬取等）。</li>
<li>可用于成本控制，防止实验或错误配置的资源导致的意外账单（尤其适用于云厂商会按次计费这种情况）。</li>
<li>允许多个用户公平共享服务。<br>
限流有多种算法，之前我们已经实现了令牌桶算法，其他的算法还有固定窗口算法、滑动日志算法、漏桶算法等，每种算法都有其优点和缺点。我们来回顾一下最经典的几种限流算法，方便你根据需要选择理想的限流方案。</li>
</ul><h3>固定窗口算法</h3><p>固定窗口算法（Fixed Window Algorithm）指的是，限制固定时间窗口内请求的处理个数。例如每小时只允许处理 1000 个请求，或每分钟只允许处理 10 个请求。每个传入请求都会增加窗口的计数器，并且计数器会在一段时间后重置。如果计数器超过了阈值，后面的请求将会被丢弃，直到计数器被重置为止。</p><!-- [[[read_end]]] --><p>固定窗口算法很容易实现，并且在限制请求速率方面做得很好。但是随着限制的重置，该算法会出现临界问题。也就是说，如果流量都集中在两个窗口的交界处，那么突发流量会是设置上限的两倍。</p><p>举个例子，我们设置每小时只能处理 1000 个请求。如果这 1000 个请求都刚好位于第一个小时的最后一分钟，而之后的1000个请求又刚好出现在下一个小时的第一分钟，就会导致在这短短的2分钟内，服务需要承受2000个请求，使服务不堪重负，示例代码如下。</p><pre><code class="language-plain">// FixedWindowLimiter 固定窗口限流器
type FixedWindowLimiter struct {
	limit    int           // 窗口请求上限
	window   time.Duration // 窗口时间大小
	counter  int           // 计数器
	lastTime time.Time     // 上一次请求的时间
	mutex    sync.Mutex    // 避免并发问题
}

func NewFixedWindowLimiter(limit int, window time.Duration) *FixedWindowLimiter {
	return &amp;FixedWindowLimiter{
		limit:    limit,
		window:   window,
		lastTime: time.Now(),
	}
}

func (l *FixedWindowLimiter) TryAcquire() error {
	l.mutex.Lock()
	defer l.mutex.Unlock()
	// 获取当前时间
	now := time.Now()
	// 如果当前窗口失效，计数器清0，开启新的窗口
	if now.Sub(l.lastTime) &gt; l.window {
		l.counter = 0
		l.lastTime = now
	}
	// 若到达窗口请求上限，请求失败
	if l.counter &gt;= l.limit {
		return errors.New("reach max limit")
	}
	// 若没到窗口请求上限，计数器+1，请求成功
	l.counter++
	return nil
}
</code></pre><h3>滑动日志算法</h3><p>还有一种常见的限流算法是滑动日志算法（Sliding Log）。它会记录下所有的请求时间点，系统会将这些日志存储在按照时间先后来排序的集合中。新请求到来时，会先判断指定时间范围内的请求数量是否超过阈值，超出阈值的请求会被丢弃。</p><p>这种方式避免了固定窗口算法容易遇到的请求突变问题，限流比较准确。不过因为它要记录下每次请求的时间点，所以会额外消耗内存与CPU。下面的代码给出了滑动日志算法的示例，在该示例中，我们可以指定多个限速策略，例如策略A在1分钟内允许处理100个请求，并且策略B在1小时内允许处理1000个请求。</p><pre><code class="language-plain">// ViolationStrategyError 违背策略错误
type ViolationStrategyError struct {
	Limit  int           // 窗口请求上限
	Window time.Duration // 窗口时间大小
}

func (e *ViolationStrategyError) Error() string {
	return fmt.Sprintf("violation strategy that limit = %d and window = %d", e.Limit, e.Window)
}

// SlidingLogLimiterStrategy 滑动日志限流器的策略
type SlidingLogLimiterStrategy struct {
	limit        int   // 窗口请求上限
	window       int64 // 窗口时间大小
	smallWindows int64 // 小窗口数量
}

func NewSlidingLogLimiterStrategy(limit int, window time.Duration) *SlidingLogLimiterStrategy {
	return &amp;SlidingLogLimiterStrategy{
		limit:  limit,
		window: int64(window),
	}
}

// SlidingLogLimiter 滑动日志限流器
type SlidingLogLimiter struct {
	strategies  []*SlidingLogLimiterStrategy // 滑动日志限流器策略列表
	smallWindow int64                        // 小窗口时间大小
	counters    map[int64]int                // 小窗口计数器
	mutex       sync.Mutex                   // 避免并发问题
}

func NewSlidingLogLimiter(smallWindow time.Duration, strategies ...*SlidingLogLimiterStrategy) (*SlidingLogLimiter, error) {
	// 复制策略避免被修改
	strategies = append(make([]*SlidingLogLimiterStrategy, 0, len(strategies)), strategies...)

	// 不能不设置策略
	if len(strategies) == 0 {
		return nil, errors.New("must be set strategies")
	}

	// 排序策略，窗口时间大的排前面，相同窗口上限大的排前面
	sort.Slice(strategies, func(i, j int) bool {
		a, b := strategies[i], strategies[j]
		if a.window == b.window {
			return a.limit &gt; b.limit
		}
		return a.window &gt; b.window
	})
	fmt.Println(strategies[0], strategies[1])

	for i, strategy := range strategies {
		// 随着窗口时间变小，窗口上限也应该变小
		if i &gt; 0 {
			if strategy.limit &gt;= strategies[i-1].limit {
				return nil, errors.New("the smaller window should be the smaller limit")
			}
		}
		// 窗口时间必须能够被小窗口时间整除
		if strategy.window%int64(smallWindow) != 0 {
			return nil, errors.New("window cannot be split by integers")
		}
		strategy.smallWindows = strategy.window / int64(smallWindow)
	}

	return &amp;SlidingLogLimiter{
		strategies:  strategies,
		smallWindow: int64(smallWindow),
		counters:    make(map[int64]int),
	}, nil
}

func (l *SlidingLogLimiter) TryAcquire() error {
	l.mutex.Lock()
	defer l.mutex.Unlock()

	// 获取当前小窗口值
	currentSmallWindow := time.Now().UnixNano() / l.smallWindow * l.smallWindow
	// 获取每个策略的起始小窗口值
	startSmallWindows := make([]int64, len(l.strategies))
	for i, strategy := range l.strategies {
		startSmallWindows[i] = currentSmallWindow - l.smallWindow*(strategy.smallWindows-1)
	}

	// 计算每个策略当前窗口的请求总数
	counts := make([]int, len(l.strategies))
	for smallWindow, counter := range l.counters {
		if smallWindow &lt; startSmallWindows[0] {
			delete(l.counters, smallWindow)
			continue
		}
		for i := range l.strategies {
			if smallWindow &gt;= startSmallWindows[i] {
				counts[i] += counter
			}
		}
	}

	// 若到达对应策略窗口请求上限，请求失败，返回违背的策略
	for i, strategy := range l.strategies {
		if counts[i] &gt;= strategy.limit {
			return &amp;ViolationStrategyError{
				Limit:  strategy.limit,
				Window: time.Duration(strategy.window),
			}
		}
	}

	// 若没到窗口请求上限，当前小窗口计数器+1，请求成功
	l.counters[currentSmallWindow]++
	return nil
}
</code></pre><h3><strong>滑动窗口算法</strong></h3><p>滑动窗口算法（Sliding Window）是一种混合方法，它有着固定窗口算法的低处理成本，并且和滑动日志算法一样，表征了在连续的时间范围内的请求量。</p><p>和固定窗口算法一样，滑动窗口算法会为每个固定窗口设置一个计数器。接下来，它会根据当前时间戳计算前一个窗口请求率的加权值，以平滑突发流量。例如，如果当前窗口经过了25%的时间，则当前窗口的计数权重为25%，而前一个窗口的计数加权为75%。</p><p>滑动窗口算法需要统计的数据量比滑动日志算法少很多，并且在大型分布式集群中仍然具有较强的扩展性。</p><p>滑动窗口算法的示例代码如下。在这段实例代码中，我们将一个固定窗口切割为了许多小窗口。举一个例子，假设我们把一个固定窗口分为了10个小窗口，计数就按照时间分布在这些小窗口中。假设当前窗口的时间过去了20%，那么当前窗口的计数权重为20%，而前一个窗口的计数加权为80%。在计数时，只要将当前固定窗口的两个小窗口与上一个窗口的最后8个小窗口的数量加起来，并将该数量与阈值做对比即可。</p><pre><code class="language-plain">
// SlidingWindowLimiter 滑动窗口限流器
type SlidingWindowLimiter struct {
	limit        int           // 窗口请求上限
	window       int64         // 窗口时间大小
	smallWindow  int64         // 小窗口时间大小
	smallWindows int64         // 小窗口数量
	counters     map[int64]int // 小窗口计数器
	mutex        sync.Mutex    // 避免并发问题
}

func NewSlidingWindowLimiter(limit int, window, smallWindow time.Duration) (*SlidingWindowLimiter, error) {
	// 窗口时间必须能够被小窗口时间整除
	if window%smallWindow != 0 {
		return nil, errors.New("window cannot be split by integers")
	}

	return &amp;SlidingWindowLimiter{
		limit:        limit,
		window:       int64(window),
		smallWindow:  int64(smallWindow),
		smallWindows: int64(window / smallWindow),
		counters:     make(map[int64]int),
	}, nil
}

func (l *SlidingWindowLimiter) TryAcquire() bool {
	l.mutex.Lock()
	defer l.mutex.Unlock()

	// 获取当前小窗口值
	currentSmallWindow := time.Now().UnixNano() / l.smallWindow * l.smallWindow
	// 获取起始小窗口值
	startSmallWindow := currentSmallWindow - l.smallWindow*(l.smallWindows-1)

	// 计算当前窗口的请求总数
	var count int
	for smallWindow, counter := range l.counters {
		if smallWindow &lt; startSmallWindow {
			delete(l.counters, smallWindow)
		} else {
			count += counter
		}
	}

	// 若到达窗口请求上限，请求失败
	if count &gt;= l.limit {
		return false
	}
	// 若没到窗口请求上限，当前小窗口计数器+1，请求成功
	l.counters[currentSmallWindow]++
	return true
}
</code></pre><h3><strong>漏桶算法</strong></h3><p>漏桶算法（Leaky Bucket）利用队列提供了一种简单、直观的方法来限制请求的速率。</p><p>每一个请求都像一滴水，请求发出之后会先被放到一个队列（漏桶）中，桶底有一个孔，不断地漏出水滴。这就好像消费者不断地在消费队列中的内容，消费的速率（漏出的速度）等于限流阈值。漏桶有大小之分，它对应的是队列的容量，如果请求的速率大于了消费的速率，请求会被暂存在桶中。当请求堆积到超过指定容量时，就像是水溢出了一样，会触发拒绝策略。</p><p>漏桶算法中的消费处理总是能以恒定的速度进行，这可以很好地保护自身系统不被突如其来的流量冲垮。但是，突发流量可能会使旧请求填满队列，导致最近的请求得不到处理。此外，它也不能保证请求一定会在某个时间段内得到处理。漏桶算法的示例代码如下。</p><pre><code class="language-plain">// LeakyBucketLimiter 漏桶限流器
type LeakyBucketLimiter struct {
	peakLevel       int        // 最高水位
	currentLevel    int        // 当前水位
	currentVelocity int        // 水流速度/秒
	lastTime        time.Time  // 上次放水时间
	mutex           sync.Mutex // 避免并发问题
}

func NewLeakyBucketLimiter(peakLevel, currentVelocity int) *LeakyBucketLimiter {
	return &amp;LeakyBucketLimiter{
		peakLevel:       peakLevel,
		currentVelocity: currentVelocity,
		lastTime:        time.Now(),
	}
}

func (l *LeakyBucketLimiter) TryAcquire() bool {
	l.mutex.Lock()
	defer l.mutex.Unlock()

	// 尝试放水
	now := time.Now()
	// 距离上次放水的时间
	interval := now.Sub(l.lastTime)
	if interval &gt;= time.Second {
		// 当前水位-距离上次放水的时间(秒)*水流速度
		l.currentLevel = maxInt(0, l.currentLevel-int(interval/time.Second)*l.currentVelocity)
		l.lastTime = now
	}

	// 若到达最高水位，请求失败
	if l.currentLevel &gt;= l.peakLevel {
		return false
	}
	// 若没有到达最高水位，当前水位+1，请求成功
	l.currentLevel++
	return true
}

func maxInt(a, b int) int {
	if a &gt; b {
		return a
	}
	return b
}
</code></pre><h3>用 go-micro 实现限流</h3><p>除了常见的限流算法，我们还可以使用go-micro框架来实现限流。这也是使用微服务框架的又一好处，因为框架中通常有配套的限流功能。在go-micro的插件库中封装了 <a href="http://github.com/juju/ratelimit">github.com/juju/ratelimit</a> 和 <a href="http://go.uber.org/ratelimit">go.uber.org/ratelimit</a> 两个限流库，分别提供了限流的令牌桶算法和漏桶算法。而且它们既可以在go-micro的客户端中也可以在服务器中使用。</p><p>要在 go-micro GRPC API 中使用限流功能，首先要导入 <a href="https://github.com/go-micro/plugins/tree/main/v4/wrapper/ratelimiter">go-micro 限流的插件库</a>，同时导入与其配套的第三方限流库：<a href="http://github.com/juju/ratelimit">github.com/juju/ratelimit</a>。如下所示，ratelimit.NewBucketWithRate可以设置令牌桶的参数。其中，第一个参数表示的是速度，在下面的例子中，第一个参数为0.5，表示每秒钟放入的令牌个数为0.5个。第二个参数为桶的大小。</p><pre><code class="language-plain">import (
	ratePlugin "github.com/go-micro/plugins/v4/wrapper/ratelimiter/ratelimit"
	"github.com/juju/ratelimit"
)
func RunGRPCServer(m *master.Master, logger *zap.Logger, reg registry.Registry, cfg ServerConfig) {
	b := ratelimit.NewBucketWithRate(0.5, 1)
	service := micro.NewService(
		...
		micro.WrapHandler(ratePlugin.NewHandlerWrapper(b, false))
	)
</code></pre><p>micro.WrapHandler包装了go-micro的Server端设置的限流中间件。ratePlugin.NewHandlerWrapper的第一个参数为之前设置的令牌桶，第二个参数可以指定当请求速率超过阈值时，是否堵塞住。此处为false，表示不堵塞并立即返回错误。<br>
这个中间件的原理也很简单，它在进行实际的GRPC方法之前先调用了限流函数。</p><pre><code class="language-plain">func NewHandlerWrapper(b *ratelimit.Bucket, wait bool) server.HandlerWrapper {
	fn := limit(b, wait, "go.micro.server")

	return func(h server.HandlerFunc) server.HandlerFunc {
		return func(ctx context.Context, req server.Request, rsp interface{}) error {
			if err := fn(); err != nil {
				return err
			}
			return h(ctx, req, rsp)
		}
	}
}
</code></pre><p>接下来我们检验一下服务限流的效果。</p><p>启动Master服务，并快速地调用两次服务。如下所示，会发现第二次调用时，服务返回429状态码，并提示处理的请求太多。等待一秒后再次调用，发现又可以正常运行了，这就说明限流功能是正常的。</p><pre><code class="language-plain">» curl -H "content-type: application/json" -d '{"id":"zjx","name": "douban_book_list"}' &lt;http://localhost:8082/crawler/resource&gt;         
{"code":2, "message":"no worker nodes", "details":[]}

» curl -H "content-type: application/json" -d '{"id":"zjx","name": "douban_book_list"}' &lt;http://localhost:8082/crawler/resource&gt;   
{"code":2, "message":"{\\"id\\":\\"go.micro.server\\",\\"code\\":429,\\"detail\\":\\"too many request\\",\\"status\\":\\"Too Many Requests\\"}", "details":[{"@type":"type.googleapis.com/errors.Error", "id":"go.micro.server", "code":429, "detail":"too many request", "status":"Too Many Requests"}]}
</code></pre><h2>熔断器</h2><p>实现了限流之后，我们再来看看熔断。我们是通过熔断器来实现熔断的。熔断器是当依赖的下游服务异常时，负责在一段时间内禁止访问依赖服务的一种系统组件，它可以防止有问题的依赖服务拖垮自身系统。熔断器有下面三个状态。</p><ul>
<li>熔断器关闭状态，表明当前服务可以正常访问下游的依赖服务。</li>
<li>熔断器打开状态，表明当前下游的依赖服务有问题，将被禁止访问。</li>
<li>熔断器半开状态，当前阶段会尝试让一部分请求访问下游依赖服务，如果能够正常访问，则会进入熔断器关闭状态。如果仍然无法正常访问，则会维持熔断器打开状态。</li>
</ul><p><img src="https://static001.geekbang.org/resource/image/31/32/31d56857de16aaa260636e659d181632.jpg?wh=1920x860" alt="图片"></p><p>社区中已经有一些非常优秀的开源熔断组件了，例如&nbsp;<a href="https://github.com/afex/hystrix-go/">hystrix-go</a>、<a href="https://github.com/sony/gobreaker">gobreaker</a>、<a href="https://github.com/alibaba/Sentinel">Sentinel</a>。Micro 也提供了对上述熔断组件进行了简单封装的插件，包括&nbsp;<a href="https://github.com/go-micro/plugins/tree/main/v4/wrapper/breaker/hystrix">hystrix 插件</a>和 <a href="https://github.com/go-micro/plugins/tree/main/v4/wrapper/breaker/gobreaker">gobreaker 插件</a>。</p><h3>go-mico实现熔断器</h3><p>我们来看一看如何在go-micro中使用熔断器。方法非常简单，调用micro.WrapClient用于注入GRPC client的中间件，在这里我们使用了<a href="https://github.com/go-micro/plugins/tree/main/v4/wrapper/breaker/hystrix">hystrix 插件</a>控制熔断器的行为。</p><pre><code class="language-plain">import (
	"github.com/go-micro/plugins/v4/wrapper/breaker/c"
)

func RunGRPCServer(m *master.Master, logger *zap.Logger, reg registry.Registry, cfg ServerConfig) {
	service := micro.NewService(
		...
		micro.WrapClient(hystrix.NewClientWrapper()),
	)
}
</code></pre><p>之后，所有从此micro client发出的服务调用都会受到熔断插件的限制和保护。当失败次数超过阈值时，调用方会立即接收到熔断错误。熔断器的配置参数位于<code>hystrix-go</code>  库中，默认的 5 个重要配置如下所示。</p><pre><code class="language-plain">	DefaultTimeout = 1000
	DefaultMaxConcurrent = 10
	DefaultVolumeThreshold = 20
	DefaultSleepWindow = 5000
	DefaultErrorPercentThreshold = 50
</code></pre><p>其中，<code>DefaultTimeout</code> 为请求的超时时间，<code>DefaultMaxConcurrent</code> 为最大的并发数量。<br>
<code>DefaultVolumeThreshold</code> 为触发断路器的最小数量，如果没有触发断路器的最小数量，就不用熔断，这避免了低峰期的干扰。例如，如果当前只有一个请求，并且访问失败了，那么当前的失败率就是100%，这种情况下立即熔断服务是不合理的。</p><p><code>DefaultSleepWindow</code>为断路器打开状态时，它会告诉我们需要等待多长时间再次检测当前链路的状态。<code>DefaultErrorPercentThreshold</code>为失败率的阈值，当失败率超过该阈值时，将触发熔断。</p><p>在go-micro当中，对熔断配置的维度是接口级别的，这一点可以从<a href="https://github.com/micro/go-plugins/tree/master/wrapper/breaker/hystrix">hystrix 插件</a>库中查看到，hystrix.DoC 的第二个参数就是熔断的维度。例如，当我们调用 Master 添加资源的接口，熔断的维度为：go.micro.server.master.CrawlerMaster.AddResource。</p><pre><code class="language-plain">func (cw *clientWrapper) Call(ctx context.Context, req client.Request, rsp interface{}, opts ...client.CallOption) error {
	var err error
	herr := hystrix.DoC(ctx, req.Service()+"."+req.Endpoint(), func(c context.Context) error {
		err = cw.Client.Call(c, req, rsp, opts...)
		if cw.filter != nil {
			if cw.filter(ctx, err) {
				return nil
			}
		}
		return err
	}, cw.fallback)
	if herr != nil {
		return herr
	}
	// return original error
	return err
}
</code></pre><p>我们可以调用插件库封装的<code>hystrix. ConfigureCommand</code>函数修改某一个接口的熔断配置，如下所示。也可以调用<code>hystrix.ConfigureDefault</code> 函数修改所有接口的默认熔断参数。</p><pre><code class="language-plain">hystrix.ConfigureCommand("go.micro.server.master.CrawlerMaster.AddResource", hystrix.CommandConfig{
		Timeout:                10000,
		MaxConcurrentRequests:  100,
		RequestVolumeThreshold: 10,
		SleepWindow:            6000,
		ErrorPercentThreshold:  30,
	})
</code></pre><h2>认证与鉴权</h2><p>在访问微服务集群的过程中，我们还时常需要进行用户的认证（Authentication）与鉴权（Authorization）。</p><p>认证的目的是检查用户的身份是否合法，防止匿名用户访问等。而鉴权是为了检查用户是否有权限操作请求的资源。</p><p>认证通常是访问服务的第一步，我们比较常见的方式是通过用户名和密码来验证用户的有效性。不过，使用用户名和密码是比较繁琐耗时的：在服务端我们通常需要考虑用密文来存储密码，还需要操作数据库。</p><p>因此从性能和安全性的角度考虑，在实践中，当我们第一次完成身份验证之后，服务器会为我们发送一个凭证，即一个Token。之后，客户端访问服务器时都需要带上这一个Token。只要Token合法且在有效期内，就可以快速地完成验证了。Token的有效期通常比较短，这样即便黑客在以后获取了Token，该Token也已经变得无效了。而利用Token进行身份认证落在实践中，我们最常用的就是JWT。</p><p>JWT（Json Web Token）是基于 JSON 的开放标准（RFC 7519）定义的一种紧凑、独立的格式，使用它可以在各方之间安全地传输信息。JWT可以使用对称加密算法（HMAC算法）或者非对称加密算法（RSA，ECDSA）进行签名。一般我们会更多使用非对称加密算法，因为它更安全且能够验证信息的完整性。JWT可以用于下面几种场景。</p><ul>
<li>
<p>单点登录（SSO）<br>
SSO是一种身份验证解决方案，可以让用户通过一次性用户身份验证登录多个应用程序和网站。JWT可以实现单点登录是因为JWT的开销很小，并且能够轻松跨域使用。</p>
</li>
<li>
<p>信息交换<br>
JWT是一种在各方之间安全传输信息的好方法。因为 JWT 可以使用公钥/私钥对签名进行验证，你可以确定发送者的真实身份。此外，由于签名中包含了具体的内容，因此你还可以验证内容是否被篡改。</p>
</li>
</ul><p>我们再来看下JWT的组成。JWT由 Header、Payload、Signature 三个对象组成，正如下面这个演示网站一样，左边为编码后的信息，右边为编码前的三个对象。每个对象都是一个 JSON 结构体。</p><p>第一个对象是 Header，它包含 alg 和 typ 两个字段，alg 表示签名的算法，typ 表示类型（ JWT）。</p><p>第二对象是 Payload，它表示载荷，包含用户名、过期时间等信息，可以自定义添加字段。</p><p>第三个对象是签名。它首先将 Header、Payload 使用 base64 url 编码，然后将编码后的字符串用"."连接在一起，最后用我们选择的算法进行签名。</p><p><img src="https://static001.geekbang.org/resource/image/27/b2/275b69yya01a13f67d212e1e62d838b2.png?wh=1920x1039" alt="图片"></p><p>从这里我们可以看出，JWT中包含了服务器认证需要的所有信息，在服务器中只需要有对应的私钥进行解密，就可以知道信息的完整性，用户的有效性，还可以额外地传递一些其他信息。</p><p>在实践中，认证一般分为下面三步。</p><ol>
<li>客户端使用用户名和密码访问服务器的登录接口。</li>
<li>当服务器认证成功后，生成JWT。</li>
<li>客户端在之后的请求中，都带上JWT，由服务器对Token进行验证。</li>
</ol><p>第一步和第二步可能是在单独的授权服务中做的，而第三步则需要对应的服务提供Token的校验支持。</p><p>go-micro中也提供了对于JWT的支持，可以轻松地生成并校验JWT。说到这儿，你很容易想到中间件，没错，我们可以通过一个中间件来提供对JWT的校验。下面是我生成的一个校验JWT token的中间件。</p><pre><code class="language-plain">func NewAuthWrapper(service micro.Service) server.HandlerWrapper {
	return func(h server.HandlerFunc) server.HandlerFunc {
		return func(ctx context.Context, req server.Request, rsp interface{}) error {
			// Fetch metadata from context (request headers).
			md, b := metadata.FromContext(ctx)
			if !b {
				return errors.New("no metadata found")
			}

			// Get auth header.
			authHeader, ok := md["Authorization"]
			if !ok || !strings.HasPrefix(authHeader, auth.BearerScheme) {
				return errors.New("no auth token provided")
			}

			// Extract auth token.
			token := strings.TrimPrefix(authHeader, auth.BearerScheme)

			// Extract account from token.
			a := service.Options().Auth
			_, err := a.Inspect(token)
			if err != nil {
				return errors.New("auth token invalid")
			}

			return h(ctx, req, rsp)
		}
	}
}
</code></pre><p>其中，service.Options().Auth是 go-micro 提供的认证与鉴权的接口。</p><pre><code class="language-plain">type Auth interface {
	// Init the auth
	Init(opts ...Option)
	// Options set for auth
	Options() Options
	// Generate a new account
	Generate(id string, opts ...GenerateOption) (*Account, error)
	// Inspect a token
	Inspect(token string) (*Account, error)
	// Token generated using refresh token or credentials
	Token(opts ...TokenOption) (*Token, error)
	// String returns the name of the implementation
	String() string
} 
</code></pre><p>而要使用JWT插件功能，需要导入go-micro的jwt插件库，并设置之前处理JWT的中间件即可。</p><pre><code class="language-plain">import (
	_ "github.com/go-micro/plugins/v4/auth/jwt"
)

var (
	name    = "helloworld"
	version = "latest"
)

func main() {

	// Create service
	srv := micro.NewService(...)

	srv.Init(
		micro.Name(name),
		micro.Version(version),
		micro.WrapHandler(NewAuthWrapper(srv)),
	)
</code></pre><p>go-micro还提供基于JWT的一些基本的授权能力，限制用户访问的路由、服务和资源。这些能力比较简单，这里就不再讨论了。</p><h2>总结</h2><p>总结一下，这节课，我们实践了保证大规模微服务集群正常运行需要具备的重要功能，即限流、熔断与认证。</p><p>限流指的是限制给定时间内事件发生的频率，这能够保证外部的请求始终位于服务器能够承载的范围内。这节课我们介绍了几种经典的限流算法和原理，它们各有特点，需要根据实际业务场景进行选择。</p><p>熔断类似于断路器，当发现依赖服务异常时，它可以在一段时间内禁止访问依赖服务，防止依赖服务拖垮自身或者返回错误的数据。</p><p>而认证与鉴权用于检查访问者的身份与权限，精准对访问者进行权限的控制，防止越权的操作。</p><p>这几种能力保证了微服务集群的正常运行，是大规模微服务集群中必不可少的治理手段。我们还分别讲解了如何用go-micro框架来实现这些能力。go-micro微服务框架有着丰富的插件库，能够帮助我们快速实现这些治理功能，让开发者更关注于开发核心的业务逻辑。</p><h2>课后题</h2><p>最后，还是给你留一道思考题。</p><p>常见的权限控制方式有哪些？kubernetes与etcd为什么都选择了RBAC进行权限控制？</p><p>欢迎你给我留言交流讨论，我们下节课见。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/15/32/fe/c2179924.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>mantra</span>
  </div>
  <div class="_2_QraFYR_0">文档中给的各类插件地址都不对。比如，“hystrix 插件”的地址正确的是 https:&#47;&#47;github.com&#47;go-micro&#47;plugins&#47;tree&#47;main&#47;v4&#47;wrapper&#47;breaker&#47;hystrix 而不是 https:&#47;&#47;github.com&#47;micro&#47;go-plugins&#47;tree&#47;master&#47;wrapper&#47;breaker&#47;hystrix。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 👍🏻尽快会修复</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-02 08:57:45</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Realm</span>
  </div>
  <div class="_2_QraFYR_0">在Kubernetes中，授权有：<br>- ABAC（基于属性的访问控制）、<br>- RBAC（基于角色的访问控制）、<br>- Webhook、<br>- Node、<br>- AlwaysDeny（一直拒绝）和<br>- AlwaysAllow（一直允许）<br>这6种模式。<br><br>从1.6版本起，Kubernetes 默认启用RBAC访问控制策略。从1.8开始，RBAC已作为稳定的功能。通过设置–authorization-mode=RBAC，启用RABC。所以RBAC也就成了一种默认选用的授权模式。<br><br>RBAC三要素：用户、角色、权限。<br>用户与角色关联，根据规则赋予角色相关的权限，整体比较灵活，扩展性和可维护性较高。<br><br>etcd估计也是这个原因.</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-07 15:28:38</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1a/3a/de/ed40f1bb.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>胡军</span>
  </div>
  <div class="_2_QraFYR_0">希望能在每个算法介绍中给个示意图，纯文字版不如图片直观易理解🙄</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 👌</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-06 08:30:09</div>
  </div>
</div>
</div>
</li>
</ul>