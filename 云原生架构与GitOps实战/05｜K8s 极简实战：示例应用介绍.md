<audio title="05｜K8s 极简实战：示例应用介绍" src="https://static001.geekbang.org/resource/audio/6c/63/6cce92bbdc1ff9849a11e0b98682ab63.mp3" controls="controls"></audio> 
<p>你好，我是王炜。</p><p>上一章，我们以一个 Python 应用为例，学习了将应用迁移到云原生架构下的完整过程，也就是从容器化、部署到 K8s、弹性伸缩最后到 GitOps 的全过程。在实战的过程中，我没有太多地介绍概念，而是让你直接上手感受 K8s 和 GitOps 的强大之处。</p><p>这一章，我会设计一个更加接近真实业务的示例应用。这个应用会涵盖你在工作中常用的 K8s 对象，包括 Deployment、Service、Ingress、HPA、Namespace、ConfigMap 等。在将这个应用部署到 K8s 的过程中，我们会逐渐深入到每个 K8s 对象中。</p><p>这节课，我们先来了解一下这个示例应用。</p><p>在开始学习之前，你需要做好以下准备：</p><ul>
<li>准备一台电脑（首选 Linux 或 macOS，Windows 也适用，注意操作差异）；</li>
<li><a href="https://docs.docker.com/engine/install/">安装 Docker</a>；</li>
<li><a href="https://kubernetes.io/docs/tasks/tools/">安装 Kubectl</a>；</li>
<li><a href="https://kind.sigs.k8s.io/docs/user/quick-start/#installation">安装 Kind</a>。</li>
</ul><h2>架构介绍</h2><h3>应用架构</h3><p>我设计的这个示例应用是一套微服务架构的应用，你可以在 GitHub 上获取<a href="https://github.com/lyzhang1999/kubernetes-example">源码</a>，源码目录结构如下：</p><pre><code class="language-powershell">$ ls
backend&nbsp; deploy&nbsp; &nbsp;frontend
</code></pre><p>在这里，backend 目录为后端源码，frontend 目录为前端源码，deploy 目录是应用的 K8s Manifest，前后端都已经包含构建镜像所需的 Dockerfile。</p><!-- [[[read_end]]] --><p>示例应用由三个服务组成：</p><ol>
<li>前端；</li>
<li>后端；</li>
<li>数据库。</li>
</ol><p>其中，前端采用 React 编写，它也是应用对外提供服务的入口；后端由 Python 编写；数据库采用流行的 Postgres。应用整体架构如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/e4/e0/e47ayy03e7a3a6429c6c5b404133ede0.jpg?wh=1920x1074" alt="图片"></p><p>前端实现了三个功能，分别是存储输入的内容，列出输入内容记录以及删除所有的记录。这三个功能分别对应了后端的三个接口，也就是 /add, /fetch 和 /delete，最后数据会被存储在 Postgres 数据库中。</p><p>示例应用的前端界面如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/4d/af/4d24857b5b97a1c8e7629198c8f379af.png?wh=1920x1172" alt="图片"></p><h3>K8s 部署架构</h3><p>为了方便你把示例应用直接部署到 K8s 集群内，我已经写好了 K8s Manifest 文件，你可以在 <a href="https://github.com/lyzhang1999/kubernetes-example/tree/main/deploy">GitHub</a> 找到这些清单文件。应用的 K8s 部署架构图如下：</p><p><img src="https://static001.geekbang.org/resource/image/f1/56/f1e65380bb2342676024341b034f0e56.jpg?wh=1920x1001" alt="图片"></p><p>在这张架构图中，Ingress 是应用的入口，Ingress 会根据请求路径将流量分流至前后端的 Service 中，然后 Service 将请求转发给前后端 Pod 进行业务逻辑处理，后端的工作负载 Deployment 配置了 HPA 自动横向扩容。同时，Postgres 也是以 Deployment 的方式部署到集群内的。最后，所有资源都部署在 K8s 的 example 命名空间（Namespace）下。</p><p>在熟悉了应用架构之后，接下来我们就把它部署到 K8s 集群内。</p><h2>部署应用</h2><h3>创建新的 K8s 集群</h3><p>我们还是以部署到本地 Kind 集群为例，为了避免资源冲突，需要先把第一章实验过程创建的 Kind 集群删掉。你可以用 kind delete cluster 来删除集群：</p><pre><code class="language-powershell">$ kind delete cluster
</code></pre><p>然后，重新创建一个 K8s 集群，将下面的内容保存为 config.yaml：</p><pre><code class="language-yaml">kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
</code></pre><p>接下来，使用 kind create cluster 重新创建集群：</p><pre><code class="language-yaml">❯ kind create cluster --config config.yaml
Creating cluster "kind" ...
 ✓ Ensuring node image (kindest/node:v1.23.4) 🖼
 ✓ Preparing nodes 📦  
 ✓ Writing configuration 📜 
 ✓ Starting control-plane 🕹️ 
 ✓ Installing CNI 🔌 
 ✓ Installing StorageClass 💾 
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind
</code></pre><p>由于示例应用使用了 Ingress，所以我们需要为 Kind 部署 Ingress，你可以使用 kubectl apply -f 来部署 Ingress-Nginx：</p><pre><code class="language-powershell">$ kubectl create -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/resource/main/ingress-nginx/ingress-nginx.yaml
namespace/ingress-nginx created
serviceaccount/ingress-nginx created
serviceaccount/ingress-nginx-admission created
......
</code></pre><p>最后，再部署 Metric Server，以便开启 HPA 功能：</p><pre><code class="language-powershell">$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/resource/main/metrics/metrics.yaml
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
......
</code></pre><p><strong>准备好新的 K8s 集群后，就可以开始部署示例应用了。</strong></p><h3>部署示例应用</h3><p>我们把示例应用所有的资源都部署在一个新的命名空间下，新的命名空间命名为 example。我们首先需要创建该命名空间，你可以使用 kubectl create namespace 来创建命名空间：</p><pre><code class="language-powershell">$ kubectl create namespace example
namespace/example created
</code></pre><p>然后，创建 Postgres 数据库，同样使用 kubectl apply 来创建：</p><pre><code class="language-powershell">$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/kubernetes-example/main/deploy/database.yaml -n example
configmap/pg-init-script created
deployment.apps/postgres created
service/pg-service created
</code></pre><p>在上面这段代码中，-n 参数代表指定命名空间，也就是 example 命名空间，<strong>注意，后续创建资源时都需要指定这个命名空间。</strong></p><p>然后再分别创建前后端 Deployment 工作负载和 Service：</p><pre><code class="language-powershell">$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/kubernetes-example/main/deploy/frontend.yaml -n example
deployment.apps/frontend created
service/frontend-service created

$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/kubernetes-example/main/deploy/backend.yaml -n example
deployment.apps/backend created
service/backend-service created
</code></pre><p>接下来，为应用创建 Ingress 和 HPA 策略：</p><pre><code class="language-powershell">$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/kubernetes-example/main/deploy/ingress.yaml -n example
ingress.networking.k8s.io/frontend-ingress created

$ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/lyzhang1999/kubernetes-example/main/deploy/hpa.yaml -n example
horizontalpodautoscaler.autoscaling/backend created
</code></pre><p>其实，除了可以按照上面的引导单独创建示例应用的每一个 K8s 对象以外，我们还可以使用另一种方法，那就是把这个 Git 仓库克隆到本地，然后使用 kubectl apply <strong>一次性将所有示例应用的对象</strong>部署到集群内：</p><pre><code class="language-yaml">$ git clone https://ghproxy.com/https://github.com/lyzhang1999/kubernetes-example &amp;&amp; cd kubernetes-example
Cloning into 'kubernetes-example'...
......
Resolving deltas: 100% (28/28), done.

$ kubectl apply -f deploy -n example
deployment.apps/backend created
service/backend-service created
configmap/pg-init-script created
......
</code></pre><p>这里的 -f 参数除了可以指定文件外，还可以指定目录，kubectl 将会检查目录下所有可用的 Manifest，然后把它部署到 K8s 集群。-n 参数代表将所有 Manifest 部署到 example 命名空间。</p><p>最后，我们可以使用 kubectl wait 来检查所有资源是不是已经处于 Ready 状态了：</p><pre><code class="language-powershell">$ kubectl wait --for=condition=Ready pods --all -n example
pod/backend-9b677898b-n5lsm condition met
pod/frontend-f948bdc85-q6x9f condition met
pod/postgres-7745b57d5d-f4trt condition met
</code></pre><p><strong>到这里，示例应用就部署完了。</strong></p><p>打开浏览器访问 127.0.0.1，你应该能看到示例应用的前端界面，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/4d/07/4dae13ff82229226916b7b767d6a5007.png?wh=1920x1190" alt="图片"></p><p>你可以尝试在输出框中输入内容，如果点击 Add 按钮，下方的列表内会出现你输入的内容，点击 Clear 所有内容被清空，这就说明应用已经可以正常工作了。</p><h2>K8s 对象解析</h2><p>在这个示例应用中，我们创建了一个新的命名空间来部署所有资源，这个命名空间是 example。</p><p>此外，示例应用涉及到的资源比较多，为了更清楚地梳理它们之间的逻辑关系，我给你简单地总结一下。</p><p>首先，你可以使用 kubectl get all 来查看某个命名空间下的所有资源：</p><pre><code class="language-powershell">❯ kubectl get all -n example
NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; READY&nbsp; &nbsp;STATUS&nbsp; &nbsp; RESTARTS&nbsp; &nbsp;AGE
pod/backend-648ff85f48-8qgjg&nbsp; &nbsp; 1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 29s
pod/backend-648ff85f48-f845h&nbsp; &nbsp; 1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 51s
pod/frontend-7b55cc5c67-4svjz&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 14s
pod/frontend-7b55cc5c67-9cx57&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 14s
pod/postgres-7745b57d5d-f4trt&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 44m

NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TYPE&nbsp; &nbsp; &nbsp; &nbsp; CLUSTER-IP&nbsp; &nbsp; &nbsp; EXTERNAL-IP&nbsp; &nbsp;PORT(S)&nbsp; &nbsp; AGE
service/backend-service&nbsp; &nbsp; ClusterIP&nbsp; &nbsp;10.96.244.140&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 5000/TCP&nbsp; &nbsp;42m
service/frontend-service&nbsp; &nbsp;ClusterIP&nbsp; &nbsp;10.96.85.54&nbsp; &nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 3000/TCP&nbsp; &nbsp;43m
service/pg-service&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ClusterIP&nbsp; &nbsp;10.96.166.74&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 5432/TCP&nbsp; &nbsp;44m

NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;READY&nbsp; &nbsp;UP-TO-DATE&nbsp; &nbsp;AVAILABLE&nbsp; &nbsp;AGE
deployment.apps/backend&nbsp; &nbsp; 2/2&nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;42m
deployment.apps/frontend&nbsp; &nbsp;2/2&nbsp; &nbsp; &nbsp;4&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;43m
deployment.apps/postgres&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;44m

NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DESIRED&nbsp; &nbsp;CURRENT&nbsp; &nbsp;READY&nbsp; &nbsp;AGE
replicaset.apps/backend-648ff85f48&nbsp; &nbsp; 2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp;51s
replicaset.apps/frontend-7b55cc5c67&nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp;54s
replicaset.apps/postgres-7745b57d5d&nbsp; &nbsp;1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1&nbsp; &nbsp; &nbsp; &nbsp;44m

NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;REFERENCE&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TARGETS&nbsp; &nbsp; MINPODS&nbsp; &nbsp;MAXPODS&nbsp; &nbsp;REPLICAS&nbsp; &nbsp;AGE
horizontalpodautoscaler.autoscaling/backend&nbsp; &nbsp; Deployment/backend&nbsp; &nbsp; 0%/50%&nbsp; &nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10&nbsp; &nbsp; &nbsp; &nbsp; 2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 8m17s
horizontalpodautoscaler.autoscaling/frontend&nbsp; &nbsp;Deployment/frontend&nbsp; &nbsp;51%/80%&nbsp; &nbsp;2&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10&nbsp; &nbsp; &nbsp; &nbsp; 10&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;8m17s
</code></pre><p>-n 参数表示指定一个命名空间，从返回结果可以看出，示例应用一共创建了 5 个 Pod、3 个 Service、3 个 Deployment、3 个 Replicaset、2 个 HPA，是不是对有些概念有点陌生呢？别担心，我们还会在接下来的课程中详细介绍。</p><h2>总结</h2><p>在这节课，我为你准备了一个示例应用，并引导你创建了一个新的本地 Kind 集群，还完成了部署的操作。此外，我们还介绍了应用整体的架构设计，包括业务架构和 K8s 部署架构。</p><p>示例应用主要从真实项目出发，在我们这个应用里出现的大多数 K8s 对象，你也会在实际工作中用到它们，掌握它们有助于你把真实的应用迁移到 K8s。在接下来的课程里，我会从这个示例应用出发，为你详细介绍这里出现的每一个 K8s 对象类型，为未来的 GitOps 课程打下坚实的基础。</p><h2>思考题</h2><p>最后，给你留一道思考题吧。</p><p>请你尝试在示例应用中添加一些数据，然后使用 kubectl delete pod 删除 Postgres 的 Pod，删除后 K8s 将会重新创建 Pod，请你观察一下之前保存的数据还存在吗？为什么？</p><p>欢迎你给我留言交流讨论，你也可以把这节课分享给更多的朋友一起阅读。我们下节课见。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/23/52/66/3e4d4846.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>includestdio.h</span>
  </div>
  <div class="_2_QraFYR_0">“首先，你可以使用 kubect get all 来查看某个命名空间下的所有资源” 。命令写错了，kubectl<br><br>删除 Postgres Pod 后，添加的数据不存在。原因：写入的数据位于容器的可写层，不commit不保存，delete 后，重新拉起的 Pod 基于原始容器镜像创建，仅存在原始的只读层数据。需要保存数据的话，可以提前通过 volume 等做好持久化方案，把容器和数据解耦</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 感谢指正。<br>回答非常正确！</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 11:24:28</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/ff/28/040f6f01.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Y</span>
  </div>
  <div class="_2_QraFYR_0">继续追剧</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 😄</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 12:52:45</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>GAC·DU</span>
  </div>
  <div class="_2_QraFYR_0">前端添加的数据会被删除，因为没有挂盘存储。生产环境用那种存储框架？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 在生产环境下有很多存储方案，比如：<br>1. https:&#47;&#47;github.com&#47;rook&#47;rook<br>2. https:&#47;&#47;github.com&#47;ceph&#47;ceph<br>3. https:&#47;&#47;github.com&#47;longhorn&#47;longhorn<br><br>如果你用的是云厂商的托管 K8s 集群，云厂商一般会直接提供现成的存储方案，比如结合自家云盘的存储，不需要自建。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 11:35:13</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1d/80/93/dde3d5f0.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>熊悟空的凶</span>
  </div>
  <div class="_2_QraFYR_0">老师你好  麻烦问下  您画图工具用什么画的 挺好的</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: Draw.io</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-29 10:30:03</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/17/e9/26/afc08398.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Amosヾ</span>
  </div>
  <div class="_2_QraFYR_0">图里不是5个pod吗</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 感谢指正。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 09:45:43</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/33/27/e5a74107.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Da Vinci</span>
  </div>
  <div class="_2_QraFYR_0">部署完ingress，访问404，是有什么不对吗，老师<br></div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 检查一下 ingress-nginx pod 是不是 running 状态。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-04-23 17:56:12</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKIRSxInCiclMszZ21FptlHSHBB2icQSdIbRX2BYdiaEfdicsWxLzqB7h01jhibpLOAu9Hd8SfbZxHBaQg/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>渣渣辉</span>
  </div>
  <div class="_2_QraFYR_0">老师你好，我通过下载github项目进行部署。但是当我访问前端的时候出现了502 BadGateway错误。然后查看pod的时候发现前端的pod重启了。并且在重启成功后再次访问还是出现了502的错误。我用的是m1芯片的macbook。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 方便贴一下 pod 的日志信息吗</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-04-13 10:29:59</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/a2/fb/94af9cf1.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Alex</span>
  </div>
  <div class="_2_QraFYR_0">针对无法拉取镜像的情况，建议修改下KIND内集群的镜像源到国内阿里的镜像源上<br>kind: Cluster<br>apiVersion: kind.x-k8s.io&#47;v1alpha4<br>nodes:<br>- role: control-plane<br>  kubeadmConfigPatches:<br>  - |<br>    kind: InitConfiguration<br>    imageRepository: registry.aliyuncs.com&#47;google_containers<br>    nodeRegistration:<br>      kubeletExtraArgs:<br>        node-labels: &quot;ingress-ready=true&quot;<br>  extraPortMappings:<br>  - containerPort: 80<br>    hostPort: 80<br>    protocol: TCP<br>  - containerPort: 443<br>    hostPort: 443<br>    protocol: TCP</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 👍🏻感谢分享</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-04-12 10:41:55</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/a5/6d/a4de2acf.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>Lee</span>
  </div>
  <div class="_2_QraFYR_0">老师，请教一下，运行一下命令，发生错误：<br>kubectl apply -f https:&#47;&#47;ghproxy.com&#47;https:&#47;&#47;raw.githubusercontent.com&#47;lyzhang1999&#47;kubernetes-example&#47;main&#47;deploy&#47;ingress.yaml -n example<br><br>Error from server (InternalError): error when creating &quot;deploy&#47;ingress.yaml&quot;: Internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: failed to call webhook: Post &quot;https:&#47;&#47;ingress-nginx-controller-admission.ingress-nginx.svc:443&#47;networking&#47;v1&#47;ingresses?timeout=10s&quot;: dial tcp 10.96.57.158:443: connect: connection refused</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: Ingress-nginx 部署失败了，检查一下镜像的拉取情况。如果是因为网络原因，可以开通一台云厂商的香港虚拟机或者托管的 K8s 集群来实验。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-04-03 16:24:29</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/e6/54/86056001.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>小马🐎</span>
  </div>
  <div class="_2_QraFYR_0">容器pod的状态只有一个running 其他的都是contaninerCreating 怎么搞？》</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 网络原因，可以尝试开通云厂商香港集群来实验。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-03-23 18:05:55</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/e6/54/86056001.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>小马🐎</span>
  </div>
  <div class="_2_QraFYR_0">Error from server (InternalError): error when creating &quot;https:&#47;&#47;ghproxy.com&#47;https:&#47;&#47;raw.githubusercontent.com&#47;lyzhang1999&#47;kubernetes-example&#47;main&#47;deploy&#47;ingress.yaml&quot;: Internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: failed to call webhook: Post &quot;https:&#47;&#47;ingress-nginx-controller-admission.ingress-nginx.svc:443&#47;networking&#47;v1&#47;ingresses?timeout=10s&quot;: dial tcp 10.96.16.113:443: connect: connection refused    <br><br>这个是什么原因呀？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: ingress-nginx 没有部署成功，检查工作负载。一般是镜像没拉取成功，你可以开通一台云厂商的香港集群来实验。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-03-23 15:11:16</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erUYW4duhqyicJEAOaEAbtSiaz22iaUmV1Mh1SJGcwRgicyZC16Rk3fJFvwXuhZJP6lqjLKCH13TEvrGg/132"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>陈敏</span>
  </div>
  <div class="_2_QraFYR_0">老师你好，请问一下，生产上数据库上云的话有什么最佳实践可以推荐呢</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 云数据库已经很成熟了，在迁移过程主要是要做数据同步和流量切换，从私有部署的数据库实例迁移到云数据库可能会导致短时间的停机。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-03-07 11:01:05</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1a/5f/af/a2a7c866.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>toranx11</span>
  </div>
  <div class="_2_QraFYR_0">最新的前端镜像（lyzhang1999&#47;frontend:latest）是有问题吗？frontend pod 一直CrashLoopBackOff：<br><br>Starting the development server...<br><br>node:events:491<br>      throw er; &#47;&#47; Unhandled &#39;error&#39; event<br>      ^<br><br>Error: EMFILE: too many open files, watch &#39;&#47;frontend&#47;public&#39;<br>    at FSWatcher.&lt;computed&gt; (node:internal&#47;fs&#47;watchers:244:19)<br>    at Object.watch (node:fs:2301:34)<br>    at createFsWatchInstance (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:38:15)<br>    at setFsWatchListener (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:81:15)<br>    at FSWatcher.NodeFsHandler._watchWithNodeFs (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:233:14)<br>    at FSWatcher.NodeFsHandler._handleDir (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:429:19)<br>    at FSWatcher.&lt;anonymous&gt; (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:477:19)<br>    at FSWatcher.&lt;anonymous&gt; (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:482:16)<br>    at FSReqCallback.oncomplete (node:fs:207:5)<br>Emitted &#39;error&#39; event on FSWatcher instance at:<br>    at FSWatcher._handleError (&#47;frontend&#47;node_modules&#47;chokidar&#47;index.js:260:10)<br>    at createFsWatchInstance (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:40:5)<br>    at setFsWatchListener (&#47;frontend&#47;node_modules&#47;chokidar&#47;lib&#47;nodefs-handler.js:81:15)<br>    [... lines matching original stack trace ...]<br>    at FSReqCallback.oncomplete (node:fs:207:5) {<br>  errno: -24,<br>  syscall: &#39;watch&#39;,<br>  code: &#39;EMFILE&#39;,<br>  path: &#39;&#47;frontend&#47;public&#39;,<br>  filename: &#39;&#47;frontend&#47;public&#39;<br>}</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 镜像是正常的，“too many open files”似乎是宿主机的配置导致的，查看这个文档排查：https:&#47;&#47;kind.sigs.k8s.io&#47;docs&#47;user&#47;known-issues&#47;#pod-errors-due-to-too-many-open-files。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-28 12:20:48</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/2c/00/b7/a39ab3e5.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>阿星</span>
  </div>
  <div class="_2_QraFYR_0">CentOS 8.2 下，按照引导都安装好了，但是执行<br>kubectl apply -f .&#47;deploy&#47;ingress.yaml -n example 时报错了：<br><br>error when creating &quot;deploy&#47;ingress.yaml&quot;: Internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: failed to call webhook: Post &quot;https:&#47;&#47;ingress-nginx-controller-admission.ingress-nginx.svc:443&#47;networking&#47;v1&#47;ingresses?timeout=10s&quot;: dial tcp 10.96.136.247:443: connect: connection refused</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 检查一下 Ingress-nginx 是不是没安装成功？</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-02-04 09:22:51</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/12/32/a8/d5bf5445.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>郑海成</span>
  </div>
  <div class="_2_QraFYR_0">删除pod后，添加的数据不存在了。pod没有挂载持久化存储，kubernetes 存储按照生命周期分为: 容器文件系统存储、临时存储、持久化存储。容器文件系统存储与pod内容器生命周期一致，容器删除后销毁；临时存储与pod生命周期一致，pod删除后销毁；持久化存储是外部的网络存储或者hostpath，会一直保留。示例中使用容器文件系统存储，删除pod就被销毁</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 非常正确👍🏻</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-13 08:56:41</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/a9/c6/30b29c22.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>那风在极客</span>
  </div>
  <div class="_2_QraFYR_0">提示 unable to recognize &quot;hpa.yaml&quot;: no matches for kind &quot;HorizontalPodAutoscaler&quot; in version &quot;autoscaling&#47;v2&quot;，是我的 k8s 版本低了吗，我的 k8s 实验版本是 v1.22.2</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，需要 1.23 以上的版本。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-10 17:34:04</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/2a/d1/34/03dc9e03.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>李多</span>
  </div>
  <div class="_2_QraFYR_0">老师，frontend的资源配额数值是不是有问题，我这里一直提示OOM错误：<br><br>pod&#47;backend-6f756f886f-8ncv8    1&#47;1     Running             0                   15m<br>pod&#47;backend-6f756f886f-k6c9x    1&#47;1     Running             0                   58m<br>pod&#47;frontend-7b55cc5c67-5r54z   1&#47;1     Terminating         0                   5m12s<br>pod&#47;frontend-7b55cc5c67-brl6q   1&#47;1     Running             2 (81s ago)         4m57s<br>pod&#47;frontend-7b55cc5c67-cwgtt   0&#47;1     OOMKilled           3 (&lt;invalid&gt; ago)   15m<br>pod&#47;frontend-7b55cc5c67-tktd9   1&#47;1     Running             2 (&lt;invalid&gt; ago)   5m12s<br>pod&#47;frontend-7b85d8fc8-5fj6t    0&#47;1     ContainerCreating   0                   8s<br>pod&#47;frontend-7b85d8fc8-8v2b7    1&#47;1     Running             0                   38s<br>pod&#47;frontend-7b85d8fc8-jnw4j    0&#47;1     ContainerCreating   0                   38s<br>pod&#47;frontend-7b85d8fc8-x9vv9    0&#47;1     ContainerCreating   0                   38s<br>pod&#47;postgres-7745b57d5d-hckqd   1&#47;1     Running             0                   58m<br><br>查看hpa对应的额度也超了：<br><br>horizontalpodautoscaler.autoscaling&#47;backend    Deployment&#47;backend    25%&#47;50%, 1%&#47;50%   2         10        2          5m46s<br>horizontalpodautoscaler.autoscaling&#47;frontend   Deployment&#47;frontend   200%&#47;80%          2         10        5          5m46s<br></div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 我更新了一版，你可以重新拉一下示例应用仓库，重新部署试试看。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-03 23:33:46</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/1d/80/93/dde3d5f0.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>熊悟空的凶</span>
  </div>
  <div class="_2_QraFYR_0">思考题： 删除命名空间下pg数据库后 数据不见了；实例都删了（理解是物理删除）； 数据肯定不应该在了 </div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 主要的原因是没有为 Pg Pod 配置持久化存储。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-29 11:18:28</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/8a/63/a5fda84d.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>烟火不坠</span>
  </div>
  <div class="_2_QraFYR_0">思考题：数据不在了，pg没有持久化存储，新pod基于yaml文件定义的镜像启动。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 正确，可以进一步尝试为 pg 增加持久化存储。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 22:04:33</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>一步</span>
  </div>
  <div class="_2_QraFYR_0">mac 部署完成之后，访问 127.0.0.1 :3000 无法访问，进入到容器内就可以访问，网络不通</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 部署 Ingress-Nginx 之后访问本地 127.0.0.1 就可以了，应用带有 Ingress 策略。另外注意创建 Kind 集群的时候需要按照文中的步骤暴露 80 端口。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-19 19:32:01</div>
  </div>
</div>
</div>
</li>
</ul>