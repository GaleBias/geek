<audio title="08｜K8s 极简实战（三）：如何解决服务发现问题？" src="https://static001.geekbang.org/resource/audio/2c/7f/2c2f05a23cf7bb27a3e4c87f3faa407f.mp3" controls="controls"></audio> 
<p>你好，我是王炜。</p><p>上一节课，我带你认识了 K8s 的几种工作负载，它们包括 Deployment、StatefulSet、DaemonSet、Job 和 CronJob。其中，Deployment 是我们在实际工作中最常用的一种工作负载类型。</p><p>现代业务应用发展至今，大部分系统都逐渐发展成为了大型的分布式微服务应用。每一个微服务各司其职，用户的一个请求往往需要由多个微服务之间相互调用才能够完成。当应用迁移到 K8s 时，我们一般会将业务系统中的每一个微服务以某种 K8s 工作负载的形式进行部署，比如最常见的 Deployment。也就是说，<strong>在 K8s 环境下，微服务之间的调用可以理解为是工作负载之间的调用。</strong></p><p><strong>换句话说，在 K8s 环境下，微服务之间的调用实际上是 Pod 之间的调用。</strong></p><p>要让 Pod 之间能够顺利相互调用，我们面临两个重要的挑战：</p><ul>
<li>Pod 之间如何找到对方？</li>
<li>Pod 在重启、更新、销毁的过程中，如何确保 Pod 之间的调用不受影响？</li>
</ul><p>这两个挑战实际上都可以归结为同一个问题，那就是<strong>服务发现</strong>。这节课，我们就来看看 K8s 原生的服务发现机制：<strong>Service</strong>。</p><p>我还是从示例应用出发，重点向你介绍 Service 到底是如何帮助我们解决这两个问题的。Service 在实际的业务场景中出现的频率非常高，在将应用迁移到 K8s 的过程中，你也一定会用到这个对象。所以，我希望你能多花点时间来学习这节课。</p><!-- [[[read_end]]] --><p>在开始实践之前，你需要确保已经按照本章的第一讲<a href="https://time.geekbang.org/column/article/614570">“示例应用介绍”</a>的引导在本地 Kind 集群部署了示例应用。</p><h2>Pod 之间如何通信？</h2><h3>IP 地址通信</h3><p>好了，接下来，请你回答一个问题。如果把 Pod 当做是运行业务进程的虚拟机，虚拟机之间要如何通信？</p><p>显然，如果虚拟机处于同一个 VPC 网络中，我们可以使用内网地址进行访问，如果不在同一个 VPC 网络下，我们则可以使用外网地址进行访问。</p><p>而在 K8s 里，每一个 Pod 就像虚拟机一样都拥有一个唯一的内网 IP 地址。通过 IP 地址，我们可以实现 Pod 之间的相互调用。</p><p>接下来，我们仍然以示例应用为例，进一步验证这个想法。</p><p>首先，我们获取示例应用后端服务 Pod 的 IP，它们位于 example 命名空间下，你可以使用 kubectl get pod -o wide 命令来获取：</p><pre><code class="language-yaml">$ kubectl get pods --selector=app=backend -n example -o wide
NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;READY&nbsp; &nbsp;STATUS&nbsp; &nbsp; RESTARTS&nbsp; &nbsp;AGE&nbsp; &nbsp;IP&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NODE&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NOMINATED NODE&nbsp; &nbsp;READINESS GATES
backend-595666f99c-6b92g&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 14m&nbsp; &nbsp;10.244.0.10&nbsp; &nbsp;kind-control-plane&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;none&gt;
backend-595666f99c-ppnc4&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 41s&nbsp; &nbsp;10.244.0.13&nbsp; &nbsp;kind-control-plane&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;none&gt;
</code></pre><p>从返回结果中，我们可以看到 Pod 的 IP 地址信息。为了验证 Pod 之间可以使用 IP 地址进行通信，我们尝试进入到前端服务的 Pod，然后通过 wget 来访问后端服务 Pod 的业务接口，以此来模拟前端服务请求后端服务的过程。你可以使用 kubectl exec 来获取前端 Pod 的容器终端：</p><pre><code class="language-yaml">$ kubectl exec -it $(kubectl get pods --selector=app=frontend -n example -o jsonpath="{.items[0].metadata.name}") -n example -- sh
/frontend # wget -O - http://10.244.0.10:5000/healthy
Connecting to 10.244.0.10:5000 (10.244.0.10:5000)
writing to stdout
{"healthy":true}
</code></pre><p>在上面的例子中，我们在前端容器里使用 wget 请求了 IP 为 10.244.0.10 的 Pod，也就是后端服务第一个 Pod backend-595666f99c-6b92g 的 healthy 接口。注意，因为在容器里 Python 程序监听了 5000 端口，所以我们在请求的 IP 地址后面增加了端口号。</p><p>可以看到，返回的 JSON 为 {“healthy”:true} ，说明前端的 Pod 已经成功向 IP 为 10.244.0.10 的后端 Pod 发起了请求。</p><p>你可能会问，既然 Pod 之间可以通过 IP 通信，那么我们是不是只需要在程序里面对需要调用的 Pod 的 IP 进行硬编码就可以了？<strong>然而并不是这样，我们接着往下看。</strong></p><p>现在，我们首先使用 exit 命令退出前端 Pod 的终端，返回宿主机终端：</p><pre><code class="language-yaml">/frontend # exit
</code></pre><p>然后，我们使用 kubectl delete pod 来删除第一个 Pod backend-595666f99c-6b92g：</p><pre><code class="language-yaml">$ kubectl delete pods backend-595666f99c-6b92g -n example
pod "backend-595666f99c-6b92g" deleted
</code></pre><p>接下来，重新获取后端服务的所有 Pod：</p><pre><code class="language-yaml">$ kubectl get pods --selector=app=backend -n example -o wide
NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;READY&nbsp; &nbsp;STATUS&nbsp; &nbsp; RESTARTS&nbsp; &nbsp;AGE&nbsp; &nbsp;IP&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NODE&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NOMINATED NODE&nbsp; &nbsp;READINESS GATES
backend-595666f99c-kfdmm&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 42s&nbsp; &nbsp;10.244.0.20&nbsp; &nbsp;kind-control-plane&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;none&gt;
backend-595666f99c-ppnc4&nbsp; &nbsp;1/1&nbsp; &nbsp; &nbsp;Running&nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 28m&nbsp; &nbsp;10.244.0.13&nbsp; &nbsp;kind-control-plane&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&lt;none&gt;
</code></pre><p>我们会发现，在删除了第一个 Pod backend-595666f99c-6b92g 之后，ReplicaSet 重新创建了一个 Pod，名字是 backend-595666f99c-kfdmm。同时，IP 地址由原来的 10.244.0.10 变成了 10.244.0.20。</p><p><strong>这说明 Pod 的 IP 是不稳定的，</strong>我们不能把 Pod IP 用作服务之间的调用地址。</p><p>那怎么才能解决这个问题呢？在解答这个问题之前，我想先请你回答一个问题：互联网域名除了好记、方便访问，还有什么功能？</p><p>对，就是 <strong>DNS 解析。</strong>我们知道，在访问一个域名的时候，DNS 服务器首先会解析 IP 地址，并且解析的 IP 地址我们是可以随时更换的。这么做的好处是，当我们做架构迁移尤其是当网关 IP 发生变化时，我们只需要用新的 IP 替换旧的 IP 地址就可以了。这样一来，用户永远只需要关注域名即可，不需要关注域名背后访问的是什么 IP 地址或哪台服务器。</p><p>再说回 K8s，那我们是不是也可以借鉴这种思想，在发出请求时不直接访问 Pod 的 IP，而是访问一个域名，然后将这个域名进一步解析成 Pod 的 IP，完成后续访问？答案是肯定的，它就是 K8s Service。</p><h2>Service：原生的服务发现机制</h2><p>为了解决 Pod IP 不稳定的问题，Service 将一组来自同一个 ReplicaSet 创建的 Pod 组合在一起，并提供 DNS 的访问能力。也就是说，Pod 之间可以通过 Service 域名来进行访问，这种访问方式的好处是，无论 Service 背后一组的 Pod 如何变化，对于其他服务来说都是透明的，服务只需要关注访问 Service 即可，不用关心这个服务是由哪个 Pod 提供的。</p><p>这种集群内部的 DNS 能力非常重要，它除了能为我们提供稳定的访问能力，还能够提供负载均衡和会话保持的能力。Service 的工作原理如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/46/5e/462a27fefc0f8a2b837b69c8420c4a5e.jpg?wh=1823x1230" alt="图片"></p><p>解释一下。Service 同样在集群内拥有唯一的 IP 地址，并且这个 IP 是稳定的。此外，Service 本身并没有直接提供服务发现的能力，它需要借助 Endpoints 来实现。Endpoints 记录了一组 Pod 的 IP 地址，Service 只需要查看自身所对应的 Endpoints 便能够找到具体的 Pod。</p><p>也就是说，无论 Pod 怎么变，Endpoints 都会实时更新它关联的 Pod IP，这样就实现了服务发现的功能。</p><p>借助 Service 的服务发现和稳定的 IP 地址能力，<strong>我们访问 Service IP 就相当于访问 Service 所关联的 Pod。</strong></p><h3><strong>示例应用：Service 示例</strong></h3><p>现在，我们回到示例应用。在<a href="https://time.geekbang.org/column/article/614570">“示例应用介绍”</a>中，我们已经把前后端的 Service 部署到了集群，这里我以示例应用的后端 Service 为例，为你进一步介绍 Service。</p><p>首先，让我们来一起看一下 Service Manifest 的内容：</p><pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: backend-service
  labels:
    app: backend
spec:
  type: ClusterIP
  sessionAffinity: None
  selector:
    app: backend
  ports:
  - port: 5000
    targetPort: 5000
</code></pre><p>这里我们重点关注 selector 字段，这是一个 Pod 选择器，这个字段表示通过 Label 匹配 Pod，也就意味着，只要是 Label 包含 app=backend 的 Pod ，都会被当成是 backend-service 的同一组逻辑 Pod。</p><p>还记得我们后端的 Deployment Manifest 吗？Deployment 定义的 Pod Label 和这里的 selector Label 是对应的。这样，backend-service 就能够通过 Label 标签来匹配 backend Deployment 创建的所有 Pod 副本了：</p><pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  ......
spec:
  ......
  template:
    metadata:
      labels:
        app: backend  # Pod Label 字段
</code></pre><p>现在，我们回到 Service ，在将 backend-service 应用到集群之后，我们可以得到一个 Service 对象。</p><p>在 Service Manifest 中，type 字段代表 Service 的类型，ClusterIP 是我们在业务场景里面最常见的类型。此外，还有 NodePort 和 LoadBalancer 类型，我们会在后面再详细介绍。</p><p>sessionAffinity 字段代表的含义是会话保持，如果设置为 True，那么 Service 在转发请求时不再使用负载均衡方式，而是会通过客户端 IP 会话亲和性的方式来将请求转发到之前访问的 Pod 上，通过这种方式来更好地适配一些要求保持会话的应用。</p><p>port 字段代表 Service 监听端口，targetPort 字段代表将请求转发到 Pod 时的目标端口。</p><h3>Endpoint 对象</h3><p>除了 Service 对象以外，我们还提到了 Endpoints 对象。当我们在 Service 里使用 Pod 选择器时，我们并不需要主动去创建 Endpoints 对象。在创建 Service 之后，K8s 会自动帮助我们创建 Endpoint。</p><p>你可以通过 kubectl get Endpoints 来获取示例应用的 Endpoints 对象：</p><pre><code class="language-yaml">$ kubectl get endpoints -n example
NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ENDPOINTS&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;AGE
backend-service&nbsp; &nbsp; 10.244.0.13:5000,10.244.0.20:5000&nbsp; &nbsp;12h
frontend-service&nbsp; &nbsp;10.244.0.16:3000,10.244.0.9:3000&nbsp; &nbsp; 12h
pg-service&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10.244.0.8:5432&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;12h
</code></pre><p>从返回结果我们可以发现，backend-service Endpoints 记录的 IP 正好是 backend Pod 的 IP 地址，Endpoint 记录了 Pod 对象以及 IP 地址，下面是 backend-service Endpoint 的 Manifest：</p><pre><code class="language-powershell">apiVersion: v1
kind: Endpoints
metadata:
&nbsp; name: backend-service
&nbsp; namespace: example
  ......
subsets:
&nbsp; - addresses:
&nbsp; &nbsp; &nbsp; - ip: 10.244.0.20
&nbsp; &nbsp; &nbsp; &nbsp; targetRef:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kind: Pod
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; namespace: example
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; name: backend-595666f99c-pdxbk
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ......
&nbsp; &nbsp; &nbsp; - ip: 10.244.0.13
&nbsp; &nbsp; &nbsp; &nbsp; targetRef:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; kind: Pod
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; namespace: example
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; name: backend-66b9754d65-jxpnb
          ......
&nbsp; &nbsp; ports:
&nbsp; &nbsp; &nbsp; - port: 5000
&nbsp; &nbsp; &nbsp; &nbsp; protocol: TCP
</code></pre><h3>Service IP</h3><p>现在，我们知道了 Service IP 是稳定的，并且它能为我们抽象一组 Pod 实现负载均衡。这就意味着我们只需要访问 Service IP 就可以找到对应的 Pod。所以接下来，我们来验证一下这个猜想。</p><p>首先，我们获取示例应用的后端 Service IP 地址：</p><pre><code class="language-yaml">$ kubectl get service -n example
NAME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TYPE&nbsp; &nbsp; &nbsp; &nbsp; CLUSTER-IP&nbsp; &nbsp; &nbsp; EXTERNAL-IP&nbsp; &nbsp;PORT(S)&nbsp; &nbsp; AGE
backend-service&nbsp; &nbsp; ClusterIP&nbsp; &nbsp;10.96.151.12&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 5000/TCP&nbsp; &nbsp;12h
frontend-service&nbsp; &nbsp;ClusterIP&nbsp; &nbsp;10.96.173.32&nbsp; &nbsp; &lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 3000/TCP&nbsp; &nbsp;12h
pg-service&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ClusterIP&nbsp; &nbsp;10.96.191.239&nbsp; &nbsp;&lt;none&gt;&nbsp; &nbsp; &nbsp; &nbsp; 5432/TCP&nbsp; &nbsp;12h
</code></pre><p>从返回结果我们可以得知，backend-service 的 IP 地址是：10.96.151.12，接下来我们尝试在前端 Pod 内部访问这个 IP。</p><p>首先，进入示例应用的前端 Pod 容器终端：</p><pre><code class="language-yaml">$ kubectl exec -it $(kubectl get pods --selector=app=frontend -n example -o jsonpath="{.items[0].metadata.name}") -n example -- sh
/frontend #
</code></pre><p>接下来，使用 wget 请求示例应用后端的 /host_name 接口，这个接口将会返回 Pod 的名称：</p><pre><code class="language-yaml">/frontend # while true; do wget -q -O- http://10.96.151.12:5000/host_name &amp;&amp; sleep 1; done
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-jxpnb"}
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-jxpnb"}
</code></pre><p>上面的代码会以 1 秒钟 1 次的频率请求后端 Pod /host_name 接口，并打印后端接口的返回内容。在这个请求里面，我们还指定了 Service 监听端口 5000，你可以使用 ctrl+c 中断循环请求。</p><p>从返回结果可以看出，对 Service IP 的请求被转发到了后端的每一个 Pod，Pod 名字交替出现，说明负载均衡也是正常工作的。</p><p>到这里，你可能认为 Service 的任务已经完成了，<strong>但其实这离能够实际使用还差最后一步</strong>。</p><h3>Service 域名</h3><p>因为，我们在写业务代码的时候是不知道被调用的 Service IP 的地址的，我们只有将 Service 部署到集群才能知道它。 此外，如果删除了 Service 重建，IP 地址也将会出现变化。最后，当我们将 K8s 对象从 A 集群迁移到 B 集群时，Service IP 也会产生变化。这些问题会让 Service IP 变得不可预测，最终使得我们在编码阶段没办法使用 Service。</p><p>这时候，我们就需要一个跟 IP 无直接关系的访问方式，那就是 <strong>Service 域名</strong>。</p><p>让我们回到这段 Service Manifest 内容：</p><pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: backend-service
  labels:
    app: backend
spec:
  type: ClusterIP
  selector:
    app: backend
  ports:
  - port: 5000
    targetPort: 5000
</code></pre><p>在这段 Service Manifest 内容里，我们将这个 Service 命名为了 backend-service，实际上这就是 <strong>Service 的域名</strong>。</p><p>在第 6 讲的跨命名空间通信的内容里我们提到，Service 在 K8s 集群内有自己独立的域名，完整的格式是：<code>{$service_name}.{$namespace}.svc.cluster.local</code>。在示例应用的例子中，backend-service 完整的域名是：<code>backend-service.example.svc.cluster.local</code>。接下来我们在<strong>前端 Pod 容器终端里</strong>验证这个猜想。</p><pre><code class="language-yaml">/frontend #while true; do wget -q -O- http://backend-service.example.svc.cluster.local:5000/host_name &amp;&amp; sleep 1; done
{"host_name":"backend-595666f99c-jxpnb"}
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-jxpnb"}
</code></pre><p>从返回结果我们会发现，访问 Service 域名和 Service 的 IP 效果是一样的，最终 backend 服务的 Pod 都能收到我们发起的请求，Pod 和 Service 的请求链路如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/b5/37/b5dafde9e032b496748cd97a408c7137.jpg?wh=1920x1504" alt="图片"></p><p>实际上，当请求发起方和目标 Service 在同一个命名空间下时，我们可以省略 namesapce.svc.cluster.local，也就是说，<strong>只需要请求 Service 的全称即 backend-service 就可以了</strong>，你可以在 frontend Pod 里面继续验证：</p><pre><code class="language-yaml">/frontend #while true; do wget -q -O- http://backend-service:5000/host_name &amp;&amp; sleep 1; done
{"host_name":"backend-595666f99c-jxpnb"}
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-pdxbk"}
{"host_name":"backend-595666f99c-jxpnb"}
</code></pre><p>Service 的这种特性可以为我们提供可预测且不变的请求 URL，无论 Pod 怎么变化，Service 总是能为我们提供服务发现和负载均衡机制。</p><p>总结来说，访问 Service 有下面这两种方式：</p><ul>
<li>如果请求方和被请求的 Service 处于同一个命名空间，那么请求 URL 就等于 Service 名称；</li>
<li>如果请求方和被请求的 Service 不在一个命名空间下，那么请求 URL 等于 <code>{$service_name}.{$namespace}.svc.cluster.local</code> 或 <code>{$service_name}.{$namespace}</code>。</li>
</ul><h2>Service 的类型</h2><p>在上面的例子中，我们创建的 Service 是最常用的 ClusterIP 类型，ClusterIP 类型会为 Service 创建一个 VIP，并且提供集群内访问的能力。</p><p>之前我也有提过，Service 的类型除了 ClusterIP 以外，还有 NodePort、ExternalName 和 Loadbalancer，下面我们分别介绍一下。</p><h3>NodePort</h3><p>NodePort 可以将 Service 暴露在 K8s 的每一个节点的端口上，通过这种方式，你可以使用节点 “IP+端口号”的形式来访问服务。</p><p>不过，由于这种暴露方式会侵入到节点，并且还需要配置的端口在节点上没有被占用，所以我并不推荐这种 Service 暴露方式，我们在实际工作中也一般不会使用这种方式。</p><h3>Loadbalancer</h3><p>Loadbalancer 是一种通过负载均衡器来暴露 Service 的方法，通过这种暴露方式，Service 会和云厂商的负载均衡器连接起来，使得 Service 可以通过负载均衡器提供的外网 IP 来进行访问。</p><p>对于业务服务，我不推荐你直接使用 Loadbalancer 来暴露服务。首先，因为 Loadbalancer 具备独立的 IP 地址，所以云厂商通常会按照“时长+流量”的方式计费，这会带来高昂的成本。其次，一个 K8s 集群内通常会有多个业务 Service 需要暴露，所以这种方式会开通多个负载均衡器实例，这是没有必要的。</p><p>在实际的业务中，我们通常会在集群内安装一个入口网关，例如 Ingress-nginx，它会自带一个 Loadbalancer 类型的 Service，然后由 Ingress-nginx 来统一接收外部请求，并将请求转发到集群内部。我们只需要配置域名或路径规则即可实现一个 Loadbalancer IP 暴露集群所有 Service 的效果。这种服务暴露方式后面还会详细介绍。</p><h3>ExternalName</h3><p>ClusterIP、NodePort 和 Loadbalancer 类型都是通过 Pod 选择器将 Service 和 Pod 关联起来，然后将请求转发到对应的 Pod 中的。而 ExternalName 类型非常特殊，它不通过 Pod 选择器关联 Pod ，而是将 Service 和另外一个域名关联起来。下面是一个 ExternalName 类型的Service Manifest 的例子：</p><pre><code class="language-powershell">apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: default
spec:
  type: ExternalName
  externalName: backend-service.example.svc.cluster.local
</code></pre><p>当将上面的 Service 应用到集群之后，在 default 命名空间下访问 <a href="http://backend-serivce:5000">http://backend-serivce:5000</a> 时，请求将会被转发到 example 命名空间下的 backend-service。我们会发现虽然目标 Service 和请求发起方不在同一个命名空间下，但可以通过这种方法屏蔽它们在不同命名空间的调用差异，使得两个服务看起来像是在同一个命名空间下。</p><p>此外，当我们需要通过 Service 名称的方式请求外部服务时，例如请求在集群外的数据库服务，也可以使用这种方法。</p><h2>总结</h2><p>在这节课中，我主要为你介绍了 K8s 环境下服务之间是如何进行调用的。通过 Pod IP 的方式调用服务存在一些无法解决的问题，例如 Pod IP 无法在编码阶段提前预知，Pod 更新镜像、驱逐和重新调度都会导致 Pod 重启，进而导致 IP 出现变化，通过 Service DNS 则可以完美地解决服务发现和服务间访问的问题。</p><p>通过本节课的实验，我们知道了在创建 Service 对象之后，同时也会创建 Endpoint 对象，它也是 Service 实现服务发现的关键。Service 同样拥有自己在集群内部的 IP 地址，在进行服务之间的调用时，我们推荐使用 Service。</p><p>在实际的业务场景中，Service 的域名写法一共有三种，当请求服务与被请求的 Service 在同一个命名空间下时，可以直接使用 Service 名称。当请求服务与被请求 Service 不在同一个命名空间下时，可以使用 Service 的全称 <code>{$service_name}.{$namespace}.svc.cluster.local</code> 或者 <code>{$service_name}.{$namespace}</code> 来请求。</p><p>最后，我们还简单介绍了服务暴露的一些知识点，这里你只要了解一下就可以了，后面还会有更详细的介绍。</p><h2>思考题</h2><p>最后，给你留一道思考题吧。</p><p>在一些场景下，我们需要通过以 Service 的方式来访问一个外部 IP 地址，例如从 K8s 集群内以 Service 的方式访问外部数据库 IP，请你尝试写出对应的 Service 和 Endpoint。</p><p>提示：Service 的类型为 clusterIP，clusterIP 字段值可以为 None，Endpoint 的 addresses 数组下需要一个包含数据库 IP 字段的数组。</p><p>欢迎你给我留言交流讨论，你也可以把这节课分享给更多的朋友一起阅读。我们下节课见。</p>
<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/14/54/21/0bac2254.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>橙汁</span>
  </div>
  <div class="_2_QraFYR_0">总会有不知道的东西，用了这么久k8s才知道ExternalName 这样搞数据库或其他服务就可以标准化了 牛逼牛逼</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，外部服务调用也可以通过 Service 访问。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-26 18:33:08</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/23/52/66/3e4d4846.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>includestdio.h</span>
  </div>
  <div class="_2_QraFYR_0">通过定义一个无选择符的 headless service ，并自行创建 ep ，通过 ep 将集群外部的数据库与内部的 svc 相关联<br><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: db<br>  namespace: example<br>spec:<br>  ports:<br>    - port: 3306<br>      targetPort: 3306<br>---<br>apiVersion: v1<br>kind: Endpoints<br>metadata:<br>  name: db<br>  namespace: example<br>subsets:<br>  - addresses:<br>      - ip: 10.244.0.1<br>      - ip: 10.244.0.2<br>      - ip: 10.244.0.3<br>    ports:<br>      - port: 3306<br>        protocol: TCP</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 非常详细，还提到了 headless service 的知识点！</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-27 09:53:49</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>一步</span>
  </div>
  <div class="_2_QraFYR_0">Service 和 Endpoints 是2种资源，创建之后是怎么进行关联的？ 根据2个 声明文件里面的 metadata.name 是否一致？</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-26 21:33:37</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/20/12/e4/57ade29a.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>dva</span>
  </div>
  <div class="_2_QraFYR_0">apiVersion: v1<br>kind: Service<br>metadata:<br>  name: mysql-svc<br>  namespace: example<br>spec:<br>  ports:<br>  - port: 3306<br>    targetPort: 3306<br>    protocol: TCP<br>    name: tcp<br>---<br>apiVersion: v1<br>kind: Endpoints<br>metadata:<br>  name: mysql-svc<br>  namespace: example<br>subsets:<br>  - addresses:<br>    - ip: 192.168.0.200<br>    ports:<br>    - port: 3306<br>      name: tcp<br><br># 在 K8S 中的容器使用 mysql-svc.example.svc.cluster.local:3306 就可以访问到 mysql 了。<br></div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 正确。</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-26 18:52:51</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/2a/d1/34/03dc9e03.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>李多</span>
  </div>
  <div class="_2_QraFYR_0">我也是，之前没注意过ExternalName。这样一来在一些微服务的配置中，就可以进一步把服务和使用的中间件解耦（将一些中间件服务地址直接用集群访问地址表示），在实际部署的时候通过ExternalName方式让微服务访问其他中间件。</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 是的，很好的思路👍🏻</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2023-01-08 10:31:53</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/11/8a/63/a5fda84d.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>烟火不坠</span>
  </div>
  <div class="_2_QraFYR_0">不知道我理解对了没，应该是这个意思吧。<br>---<br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: mysql<br>spec:<br>  ports:<br>  - port: 3306<br>    protocol: TCP<br>    targetPort: 3306<br>  type: ClusterIP<br><br>---<br>apiVersion: v1<br>kind: Endpoints<br>metadata:<br>  name: mysql<br>subsets:<br>- addresses:<br>  - ip: 192.168.0.xxx<br>  ports:<br>  - port: 3306<br>    protocol: TCP</div>
  <div class="_10o3OAxT_0">
    <p class="_3KxQPN3V_0">作者回复: 正确！</p>
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2022-12-26 17:47:35</div>
  </div>
</div>
</div>
</li>
</ul>